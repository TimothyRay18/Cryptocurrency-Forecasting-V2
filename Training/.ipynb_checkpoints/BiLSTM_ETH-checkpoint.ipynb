{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ef9d1-2655-483e-9f50-0badccf17d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Skripsi import Preprocessing\n",
    "from Skripsi import Evaluation\n",
    "from Skripsi import LSTMUnit\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl.workbook import Workbook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ed0706-d5c2-4868-beee-6933c00b0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>1196.18</td>\n",
       "      <td>1197.43</td>\n",
       "      <td>1193.60</td>\n",
       "      <td>1196.13</td>\n",
       "      <td>7.086714e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>1200.09</td>\n",
       "      <td>1201.11</td>\n",
       "      <td>1193.08</td>\n",
       "      <td>1196.19</td>\n",
       "      <td>1.143952e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>1202.33</td>\n",
       "      <td>1203.00</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>1200.10</td>\n",
       "      <td>4.643401e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>1202.66</td>\n",
       "      <td>1203.71</td>\n",
       "      <td>1202.30</td>\n",
       "      <td>1202.34</td>\n",
       "      <td>4.278879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>1199.59</td>\n",
       "      <td>1205.61</td>\n",
       "      <td>1199.42</td>\n",
       "      <td>1202.65</td>\n",
       "      <td>7.738029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>130.20</td>\n",
       "      <td>4.430067e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>130.20</td>\n",
       "      <td>6.473610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>130.85</td>\n",
       "      <td>9.940256e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>130.64</td>\n",
       "      <td>1.474278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>128.87</td>\n",
       "      <td>1.000930e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date     Open     High      Low    Close   Volume USDT\n",
       "0      2022-12-31 23:00:00  1196.18  1197.43  1193.60  1196.13  7.086714e+06\n",
       "1      2022-12-31 22:00:00  1200.09  1201.11  1193.08  1196.19  1.143952e+07\n",
       "2      2022-12-31 21:00:00  1202.33  1203.00  1199.83  1200.10  4.643401e+06\n",
       "3      2022-12-31 20:00:00  1202.66  1203.71  1202.30  1202.34  4.278879e+06\n",
       "4      2022-12-31 19:00:00  1199.59  1205.61  1199.42  1202.65  7.738029e+06\n",
       "...                    ...      ...      ...      ...      ...           ...\n",
       "26269  2020-01-01 04:00:00   130.21   130.74   130.15   130.20  4.430067e+05\n",
       "26270  2020-01-01 03:00:00   130.85   130.89   129.94   130.20  6.473610e+05\n",
       "26271  2020-01-01 02:00:00   130.63   130.98   130.35   130.85  9.940256e+05\n",
       "26272  2020-01-01 01:00:00   128.87   130.65   128.78   130.64  1.474278e+06\n",
       "26273  2020-01-01 00:00:00   129.16   129.19   128.68   128.87  1.000930e+06\n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_dfd = pd.read_csv('../Dataset/Binance_ETHUSDT_1h.csv')\n",
    "eth_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc368c1b-a82f-4dbf-85c4-f19ebff7a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>1196.18</td>\n",
       "      <td>1197.43</td>\n",
       "      <td>1193.60</td>\n",
       "      <td>1196.13</td>\n",
       "      <td>7.086714e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>1200.09</td>\n",
       "      <td>1201.11</td>\n",
       "      <td>1193.08</td>\n",
       "      <td>1196.19</td>\n",
       "      <td>1.143952e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>1202.33</td>\n",
       "      <td>1203.00</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>1200.10</td>\n",
       "      <td>4.643401e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>1202.66</td>\n",
       "      <td>1203.71</td>\n",
       "      <td>1202.30</td>\n",
       "      <td>1202.34</td>\n",
       "      <td>4.278879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>1199.59</td>\n",
       "      <td>1205.61</td>\n",
       "      <td>1199.42</td>\n",
       "      <td>1202.65</td>\n",
       "      <td>7.738029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>130.20</td>\n",
       "      <td>4.430067e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>130.20</td>\n",
       "      <td>6.473610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>130.85</td>\n",
       "      <td>9.940256e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>130.64</td>\n",
       "      <td>1.474278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>128.87</td>\n",
       "      <td>1.000930e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date     Open     High      Low    Close   Volume USDT\n",
       "0      2022-12-31 23:00:00  1196.18  1197.43  1193.60  1196.13  7.086714e+06\n",
       "1      2022-12-31 22:00:00  1200.09  1201.11  1193.08  1196.19  1.143952e+07\n",
       "2      2022-12-31 21:00:00  1202.33  1203.00  1199.83  1200.10  4.643401e+06\n",
       "3      2022-12-31 20:00:00  1202.66  1203.71  1202.30  1202.34  4.278879e+06\n",
       "4      2022-12-31 19:00:00  1199.59  1205.61  1199.42  1202.65  7.738029e+06\n",
       "...                    ...      ...      ...      ...      ...           ...\n",
       "26269  2020-01-01 04:00:00   130.21   130.74   130.15   130.20  4.430067e+05\n",
       "26270  2020-01-01 03:00:00   130.85   130.89   129.94   130.20  6.473610e+05\n",
       "26271  2020-01-01 02:00:00   130.63   130.98   130.35   130.85  9.940256e+05\n",
       "26272  2020-01-01 01:00:00   128.87   130.65   128.78   130.64  1.474278e+06\n",
       "26273  2020-01-01 00:00:00   129.16   129.19   128.68   128.87  1.000930e+06\n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup = Preprocessing.handle_duplicate(eth_dfd)\n",
    "df_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41062755-9cca-4348-91bc-e80d46b79c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>128.87</td>\n",
       "      <td>1.000930e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>130.64</td>\n",
       "      <td>1.474278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>130.85</td>\n",
       "      <td>9.940256e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>130.20</td>\n",
       "      <td>6.473610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>130.20</td>\n",
       "      <td>4.430067e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>1199.59</td>\n",
       "      <td>1205.61</td>\n",
       "      <td>1199.42</td>\n",
       "      <td>1202.65</td>\n",
       "      <td>7.738029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>1202.66</td>\n",
       "      <td>1203.71</td>\n",
       "      <td>1202.30</td>\n",
       "      <td>1202.34</td>\n",
       "      <td>4.278879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>1202.33</td>\n",
       "      <td>1203.00</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>1200.10</td>\n",
       "      <td>4.643401e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>1200.09</td>\n",
       "      <td>1201.11</td>\n",
       "      <td>1193.08</td>\n",
       "      <td>1196.19</td>\n",
       "      <td>1.143952e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>1196.18</td>\n",
       "      <td>1197.43</td>\n",
       "      <td>1193.60</td>\n",
       "      <td>1196.13</td>\n",
       "      <td>7.086714e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date     Open     High      Low    Close   Volume USDT\n",
       "0      2020-01-01 00:00:00   129.16   129.19   128.68   128.87  1.000930e+06\n",
       "1      2020-01-01 01:00:00   128.87   130.65   128.78   130.64  1.474278e+06\n",
       "2      2020-01-01 02:00:00   130.63   130.98   130.35   130.85  9.940256e+05\n",
       "3      2020-01-01 03:00:00   130.85   130.89   129.94   130.20  6.473610e+05\n",
       "4      2020-01-01 04:00:00   130.21   130.74   130.15   130.20  4.430067e+05\n",
       "...                    ...      ...      ...      ...      ...           ...\n",
       "26269  2022-12-31 19:00:00  1199.59  1205.61  1199.42  1202.65  7.738029e+06\n",
       "26270  2022-12-31 20:00:00  1202.66  1203.71  1202.30  1202.34  4.278879e+06\n",
       "26271  2022-12-31 21:00:00  1202.33  1203.00  1199.83  1200.10  4.643401e+06\n",
       "26272  2022-12-31 22:00:00  1200.09  1201.11  1193.08  1196.19  1.143952e+07\n",
       "26273  2022-12-31 23:00:00  1196.18  1197.43  1193.60  1196.13  7.086714e+06\n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Preprocessing.sort_df(df_no_dup)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483f3731-9efb-47c6-af9c-6eadc95287e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>128.87</td>\n",
       "      <td>1.000930e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>130.64</td>\n",
       "      <td>1.474278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>130.85</td>\n",
       "      <td>9.940256e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>130.20</td>\n",
       "      <td>6.473610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>130.20</td>\n",
       "      <td>4.430067e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>1199.59</td>\n",
       "      <td>1205.61</td>\n",
       "      <td>1199.42</td>\n",
       "      <td>1202.65</td>\n",
       "      <td>7.738029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>1202.66</td>\n",
       "      <td>1203.71</td>\n",
       "      <td>1202.30</td>\n",
       "      <td>1202.34</td>\n",
       "      <td>4.278879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>1202.33</td>\n",
       "      <td>1203.00</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>1200.10</td>\n",
       "      <td>4.643401e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>1200.09</td>\n",
       "      <td>1201.11</td>\n",
       "      <td>1193.08</td>\n",
       "      <td>1196.19</td>\n",
       "      <td>1.143952e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>1196.18</td>\n",
       "      <td>1197.43</td>\n",
       "      <td>1193.60</td>\n",
       "      <td>1196.13</td>\n",
       "      <td>7.086714e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date     Open     High      Low    Close   Volume USDT\n",
       "0      2020-01-01 00:00:00   129.16   129.19   128.68   128.87  1.000930e+06\n",
       "1      2020-01-01 01:00:00   128.87   130.65   128.78   130.64  1.474278e+06\n",
       "2      2020-01-01 02:00:00   130.63   130.98   130.35   130.85  9.940256e+05\n",
       "3      2020-01-01 03:00:00   130.85   130.89   129.94   130.20  6.473610e+05\n",
       "4      2020-01-01 04:00:00   130.21   130.74   130.15   130.20  4.430067e+05\n",
       "...                    ...      ...      ...      ...      ...           ...\n",
       "26269  2022-12-31 19:00:00  1199.59  1205.61  1199.42  1202.65  7.738029e+06\n",
       "26270  2022-12-31 20:00:00  1202.66  1203.71  1202.30  1202.34  4.278879e+06\n",
       "26271  2022-12-31 21:00:00  1202.33  1203.00  1199.83  1200.10  4.643401e+06\n",
       "26272  2022-12-31 22:00:00  1200.09  1201.11  1193.08  1196.19  1.143952e+07\n",
       "26273  2022-12-31 23:00:00  1196.18  1197.43  1193.60  1196.13  7.086714e+06\n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss = Preprocessing.handle_missing_value(df)\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140ecfee-f8cf-45f6-b3c6-49e8e7458101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00687306, 0.00493458, 0.00899058, 0.00085515, 0.00678935],\n",
       "       [0.00681201, 0.00524115, 0.00901165, 0.00125955, 0.00716197],\n",
       "       [0.00718251, 0.00531045, 0.00934237, 0.00084925, 0.00720618],\n",
       "       ...,\n",
       "       [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718],\n",
       "       [0.2323116 , 0.23001863, 0.23320743, 0.00977339, 0.23148404],\n",
       "       [0.23148852, 0.22924589, 0.23331697, 0.00605456, 0.2314714 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, scaler = Preprocessing.minmax_scale(miss)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42a7847-70b8-4487-a874-67e370666724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00687306, 0.00493458, 0.00899058, 0.00085515, 0.00678935],\n",
       "       [0.00681201, 0.00524115, 0.00901165, 0.00125955, 0.00716197],\n",
       "       [0.00718251, 0.00531045, 0.00934237, 0.00084925, 0.00720618],\n",
       "       ...,\n",
       "       [0.36569953, 0.36527651, 0.3650033 , 0.03678181, 0.36294049],\n",
       "       [0.36293557, 0.3619231 , 0.35881859, 0.0818867 , 0.35696376],\n",
       "       [0.35696347, 0.35758067, 0.3546814 , 0.09563107, 0.35310278]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = Preprocessing.splitting_data(x)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e525a6-83d0-4c8b-9875-33e0e15480ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35310067, 0.35162768, 0.34770043, 0.15036013, 0.34664396],\n",
       "       [0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "       [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "       ...,\n",
       "       [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718],\n",
       "       [0.2323116 , 0.23001863, 0.23320743, 0.00977339, 0.23148404],\n",
       "       [0.23148852, 0.22924589, 0.23331697, 0.00605456, 0.2314714 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08213717-a303-4c9e-97bb-280204035109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = Preprocessing.create_dataset(train,50)\n",
    "test_X, test_y = Preprocessing.create_dataset(test,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff76bd7-16f2-4bf2-8a64-f1f6a1194661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6.87306202e-03, 4.93458007e-03, 8.99058180e-03, 8.55147771e-04,\n",
       "         6.78934504e-03],\n",
       "        [6.81201491e-03, 5.24115398e-03, 9.01164689e-03, 1.25955490e-03,\n",
       "         7.16196956e-03],\n",
       "        [7.18250769e-03, 5.31044808e-03, 9.34236885e-03, 8.49249206e-04,\n",
       "         7.20617925e-03],\n",
       "        ...,\n",
       "        [6.50046417e-03, 4.57551062e-03, 8.61772965e-03, 3.23769695e-04,\n",
       "         6.43566753e-03],\n",
       "        [6.45836272e-03, 4.60070848e-03, 8.59877106e-03, 7.93625707e-04,\n",
       "         6.41040486e-03],\n",
       "        [6.43310185e-03, 4.51041616e-03, 8.40075919e-03, 1.31781688e-03,\n",
       "         6.19356686e-03]],\n",
       "\n",
       "       [[6.81201491e-03, 5.24115398e-03, 9.01164689e-03, 1.25955490e-03,\n",
       "         7.16196956e-03],\n",
       "        [7.18250769e-03, 5.31044808e-03, 9.34236885e-03, 8.49249206e-04,\n",
       "         7.20617925e-03],\n",
       "        [7.22881929e-03, 5.29154969e-03, 9.25600197e-03, 5.53075059e-04,\n",
       "         7.06933974e-03],\n",
       "        ...,\n",
       "        [6.45836272e-03, 4.60070848e-03, 8.59877106e-03, 7.93625707e-04,\n",
       "         6.41040486e-03],\n",
       "        [6.43310185e-03, 4.51041616e-03, 8.40075919e-03, 1.31781688e-03,\n",
       "         6.19356686e-03],\n",
       "        [6.21627937e-03, 4.49151777e-03, 8.40497220e-03, 1.55298811e-03,\n",
       "         6.37882651e-03]],\n",
       "\n",
       "       [[7.18250769e-03, 5.31044808e-03, 9.34236885e-03, 8.49249206e-04,\n",
       "         7.20617925e-03],\n",
       "        [7.22881929e-03, 5.29154969e-03, 9.25600197e-03, 5.53075059e-04,\n",
       "         7.06933974e-03],\n",
       "        [7.09409464e-03, 5.26005237e-03, 9.30023867e-03, 3.78484257e-04,\n",
       "         7.06933974e-03],\n",
       "        ...,\n",
       "        [6.43310185e-03, 4.51041616e-03, 8.40075919e-03, 1.31781688e-03,\n",
       "         6.19356686e-03],\n",
       "        [6.21627937e-03, 4.49151777e-03, 8.40497220e-03, 1.55298811e-03,\n",
       "         6.37882651e-03],\n",
       "        [6.40573590e-03, 4.49781724e-03, 8.56296040e-03, 6.80494098e-04,\n",
       "         6.37251084e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.92878118e-01, 3.92202524e-01, 3.92975634e-01, 2.09867864e-02,\n",
       "         3.94453579e-01],\n",
       "        [3.94448503e-01, 3.94946990e-01, 3.96683090e-01, 1.80458603e-02,\n",
       "         3.97245105e-01],\n",
       "        [3.97237724e-01, 3.95224166e-01, 3.98762215e-01, 3.90364506e-02,\n",
       "         3.97099844e-01],\n",
       "        ...,\n",
       "        [3.71650566e-01, 3.69093990e-01, 3.66560007e-01, 7.42819321e-02,\n",
       "         3.64190994e-01],\n",
       "        [3.64185979e-01, 3.63388776e-01, 3.63627746e-01, 5.48781980e-02,\n",
       "         3.64380464e-01],\n",
       "        [3.64377541e-01, 3.66276030e-01, 3.66642161e-01, 4.81229054e-02,\n",
       "         3.65702545e-01]],\n",
       "\n",
       "       [[3.94448503e-01, 3.94946990e-01, 3.96683090e-01, 1.80458603e-02,\n",
       "         3.97245105e-01],\n",
       "        [3.97237724e-01, 3.95224166e-01, 3.98762215e-01, 3.90364506e-02,\n",
       "         3.97099844e-01],\n",
       "        [3.97094579e-01, 3.95671428e-01, 3.98147114e-01, 3.99885724e-02,\n",
       "         3.96369332e-01],\n",
       "        ...,\n",
       "        [3.64185979e-01, 3.63388776e-01, 3.63627746e-01, 5.48781980e-02,\n",
       "         3.64380464e-01],\n",
       "        [3.64377541e-01, 3.66276030e-01, 3.66642161e-01, 4.81229054e-02,\n",
       "         3.65702545e-01],\n",
       "        [3.65699526e-01, 3.65276515e-01, 3.65003297e-01, 3.67818089e-02,\n",
       "         3.62940492e-01]],\n",
       "\n",
       "       [[3.97237724e-01, 3.95224166e-01, 3.98762215e-01, 3.90364506e-02,\n",
       "         3.97099844e-01],\n",
       "        [3.97094579e-01, 3.95671428e-01, 3.98147114e-01, 3.99885724e-02,\n",
       "         3.96369332e-01],\n",
       "        [3.96362014e-01, 3.94993186e-01, 3.97447753e-01, 2.39590438e-02,\n",
       "         3.95430402e-01],\n",
       "        ...,\n",
       "        [3.64377541e-01, 3.66276030e-01, 3.66642161e-01, 4.81229054e-02,\n",
       "         3.65702545e-01],\n",
       "        [3.65699526e-01, 3.65276515e-01, 3.65003297e-01, 3.67818089e-02,\n",
       "         3.62940492e-01],\n",
       "        [3.62935566e-01, 3.61923100e-01, 3.58818585e-01, 8.18867004e-02,\n",
       "         3.56963763e-01]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efa14c4-f85e-47c3-bc04-7f0d029d3a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00637883, 0.00637251, 0.00687987, ..., 0.36294049, 0.35696376,\n",
       "       0.35310278])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51dc56af-5903-45ab-a70b-556fb3f3d97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.35310067, 0.35162768, 0.34770043, 0.15036013, 0.34664396],\n",
       "        [0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "        [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        ...,\n",
       "        [0.35695716, 0.3549118 , 0.35827089, 0.02554312, 0.35642272],\n",
       "        [0.35642247, 0.35363301, 0.35533021, 0.0359709 , 0.35359541],\n",
       "        [0.35359115, 0.35089064, 0.35262123, 0.05488511, 0.3519828 ]],\n",
       "\n",
       "       [[0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "        [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        [0.35186288, 0.35105233, 0.34876   , 0.06304256, 0.34708184],\n",
       "        ...,\n",
       "        [0.35642247, 0.35363301, 0.35533021, 0.0359709 , 0.35359541],\n",
       "        [0.35359115, 0.35089064, 0.35262123, 0.05488511, 0.3519828 ],\n",
       "        [0.35197866, 0.35126441, 0.35368502, 0.01896836, 0.35364383]],\n",
       "\n",
       "       [[0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        [0.35186288, 0.35105233, 0.34876   , 0.06304256, 0.34708184],\n",
       "        [0.34708226, 0.34721595, 0.34265955, 0.10696327, 0.34520188],\n",
       "        ...,\n",
       "        [0.35359115, 0.35089064, 0.35262123, 0.05488511, 0.3519828 ],\n",
       "        [0.35197866, 0.35126441, 0.35368502, 0.01896836, 0.35364383],\n",
       "        [0.35364167, 0.35142399, 0.35460557, 0.01667411, 0.3533912 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.23236423, 0.23020551, 0.23384781, 0.00805634, 0.23195771],\n",
       "        [0.23196426, 0.22960706, 0.23287039, 0.01628271, 0.23152403],\n",
       "        [0.23153062, 0.2291766 , 0.23343072, 0.00687752, 0.23125457],\n",
       "        ...,\n",
       "        [0.23245685, 0.22999343, 0.23450504, 0.00350383, 0.23220192],\n",
       "        [0.23220635, 0.23096355, 0.23454296, 0.00661101, 0.23284401],\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875]],\n",
       "\n",
       "       [[0.23196426, 0.22960706, 0.23287039, 0.01628271, 0.23152403],\n",
       "        [0.23153062, 0.2291766 , 0.23343072, 0.00687752, 0.23125457],\n",
       "        [0.23126328, 0.23039239, 0.23344547, 0.01020951, 0.23182508],\n",
       "        ...,\n",
       "        [0.23220635, 0.23096355, 0.23454296, 0.00661101, 0.23284401],\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875],\n",
       "        [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718]],\n",
       "\n",
       "       [[0.23153062, 0.2291766 , 0.23343072, 0.00687752, 0.23125457],\n",
       "        [0.23126328, 0.23039239, 0.23344547, 0.01020951, 0.23182508],\n",
       "        [0.23183164, 0.23066327, 0.23405004, 0.01194032, 0.23238928],\n",
       "        ...,\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875],\n",
       "        [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718],\n",
       "        [0.2323116 , 0.23001863, 0.23320743, 0.00977339, 0.23148404]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98152d5-e8c5-4645-90ea-876a042b25e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35364383, 0.3533912 , 0.35539537, ..., 0.23230718, 0.23148404,\n",
       "       0.2314714 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80df0f9-fe70-44f0-bef3-b779d95da0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20969, 50, 5) (20969,) (5205, 50, 5) (5205,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43011a-1b18-4fef-b638-d84109a5347b",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6e3c5f-f40b-427b-bbf6-715de9fbfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 25, 50),\n",
       " (32, 25, 60),\n",
       " (32, 25, 100),\n",
       " (32, 50, 50),\n",
       " (32, 50, 60),\n",
       " (32, 50, 100),\n",
       " (32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100),\n",
       " (64, 25, 50),\n",
       " (64, 25, 60),\n",
       " (64, 25, 100),\n",
       " (64, 50, 50),\n",
       " (64, 50, 60),\n",
       " (64, 50, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100),\n",
       " (128, 25, 50),\n",
       " (128, 25, 60),\n",
       " (128, 25, 100),\n",
       " (128, 50, 50),\n",
       " (128, 50, 60),\n",
       " (128, 50, 100),\n",
       " (128, 100, 50),\n",
       " (128, 100, 60),\n",
       " (128, 100, 100)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = []\n",
    "batch = [32, 64, 128]\n",
    "epoch = [25, 50, 100]\n",
    "neuron = [50, 60, 100]\n",
    "for j in batch:\n",
    "    for k in epoch:\n",
    "        for l in neuron:\n",
    "            hyperparams.append((j,k,l))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c52fc162-d986-4cb9-9893-7619681dfc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 25, 50),\n",
       " (32, 25, 60),\n",
       " (32, 25, 100),\n",
       " (32, 50, 50),\n",
       " (32, 50, 60),\n",
       " (32, 50, 100),\n",
       " (32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam1 = hyperparams[:9]\n",
    "hyperparam2 = hyperparams[9:18]\n",
    "hyperparam3 = hyperparams[18:27]\n",
    "hyperparam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d42226bd-8cc7-4f34-bb16-195c46f1e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 25, 50),\n",
       " (64, 25, 60),\n",
       " (64, 25, 100),\n",
       " (64, 50, 50),\n",
       " (64, 50, 60),\n",
       " (64, 50, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed77be16-ab42-4b03-b115-2019aff75427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(128, 25, 50),\n",
       " (128, 25, 60),\n",
       " (128, 25, 100),\n",
       " (128, 50, 50),\n",
       " (128, 50, 60),\n",
       " (128, 50, 100),\n",
       " (128, 100, 50),\n",
       " (128, 100, 60),\n",
       " (128, 100, 100)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ffd8dc1-5eb8-4d7e-aba2-cab78df020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 08:54:07.111888: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-05 08:54:07.112423: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-04-05 08:54:07.343455: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-04-05 08:54:08.499858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 08:54:08.673083: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 08:54:08.699035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 08:54:10.371798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 08:54:10.387555: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 08:54:30.123115: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 08:54:30.173893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 08:54:30.182867: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 26s - loss: 5.0877e-04 - val_loss: 5.1180e-04 - 26s/epoch - 39ms/step\n",
      "Epoch 2/25\n",
      "656/656 - 20s - loss: 7.4332e-04 - val_loss: 7.4094e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 3/25\n",
      "656/656 - 20s - loss: 0.0010 - val_loss: 0.0016 - 20s/epoch - 31ms/step\n",
      "Epoch 4/25\n",
      "656/656 - 20s - loss: 0.0011 - val_loss: 0.0015 - 20s/epoch - 31ms/step\n",
      "Epoch 5/25\n",
      "656/656 - 20s - loss: 0.0011 - val_loss: 0.0010 - 20s/epoch - 31ms/step\n",
      "Epoch 6/25\n",
      "656/656 - 20s - loss: 9.0236e-04 - val_loss: 7.1868e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 7/25\n",
      "656/656 - 20s - loss: 7.5390e-04 - val_loss: 5.2246e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 8/25\n",
      "656/656 - 21s - loss: 6.4137e-04 - val_loss: 3.9089e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 9/25\n",
      "656/656 - 20s - loss: 5.3582e-04 - val_loss: 3.0599e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 10/25\n",
      "656/656 - 20s - loss: 4.5503e-04 - val_loss: 2.4307e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 11/25\n",
      "656/656 - 20s - loss: 3.8716e-04 - val_loss: 1.9708e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 12/25\n",
      "656/656 - 20s - loss: 3.3433e-04 - val_loss: 1.6602e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 13/25\n",
      "656/656 - 20s - loss: 2.9391e-04 - val_loss: 1.4458e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 14/25\n",
      "656/656 - 20s - loss: 2.6564e-04 - val_loss: 1.2431e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 15/25\n",
      "656/656 - 20s - loss: 2.4617e-04 - val_loss: 1.1599e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 16/25\n",
      "656/656 - 20s - loss: 2.3176e-04 - val_loss: 1.0501e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 17/25\n",
      "656/656 - 20s - loss: 2.1508e-04 - val_loss: 9.3599e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 18/25\n",
      "656/656 - 20s - loss: 2.0309e-04 - val_loss: 8.8386e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 19/25\n",
      "656/656 - 20s - loss: 1.9418e-04 - val_loss: 8.0462e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 20/25\n",
      "656/656 - 20s - loss: 1.8662e-04 - val_loss: 7.6643e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 21/25\n",
      "656/656 - 20s - loss: 1.7844e-04 - val_loss: 6.9396e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 22/25\n",
      "656/656 - 20s - loss: 1.7013e-04 - val_loss: 6.3616e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 23/25\n",
      "656/656 - 20s - loss: 1.6470e-04 - val_loss: 5.9860e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 24/25\n",
      "656/656 - 20s - loss: 1.5877e-04 - val_loss: 5.4700e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 25/25\n",
      "656/656 - 20s - loss: 1.5314e-04 - val_loss: 5.0288e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 09:02:40.152166: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:02:40.297723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:02:40.309672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:02:40.496620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:02:40.512531: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:02:59.518090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:02:59.566205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:02:59.574934: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 23s - loss: 3.8610e-04 - val_loss: 6.8979e-04 - 23s/epoch - 35ms/step\n",
      "Epoch 2/25\n",
      "656/656 - 21s - loss: 4.2263e-04 - val_loss: 4.5976e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 3/25\n",
      "656/656 - 21s - loss: 5.7585e-04 - val_loss: 4.9245e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 4/25\n",
      "656/656 - 21s - loss: 8.2307e-04 - val_loss: 0.0011 - 21s/epoch - 32ms/step\n",
      "Epoch 5/25\n",
      "656/656 - 21s - loss: 9.0276e-04 - val_loss: 0.0013 - 21s/epoch - 31ms/step\n",
      "Epoch 6/25\n",
      "656/656 - 21s - loss: 8.3393e-04 - val_loss: 0.0010 - 21s/epoch - 31ms/step\n",
      "Epoch 7/25\n",
      "656/656 - 21s - loss: 6.9132e-04 - val_loss: 6.9351e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 8/25\n",
      "656/656 - 21s - loss: 5.5194e-04 - val_loss: 4.7642e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 9/25\n",
      "656/656 - 21s - loss: 4.5217e-04 - val_loss: 3.3989e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 10/25\n",
      "656/656 - 21s - loss: 3.8337e-04 - val_loss: 2.5282e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 11/25\n",
      "656/656 - 21s - loss: 3.3300e-04 - val_loss: 2.0090e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 12/25\n",
      "656/656 - 21s - loss: 2.9557e-04 - val_loss: 1.6779e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 13/25\n",
      "656/656 - 21s - loss: 2.6749e-04 - val_loss: 1.3934e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 14/25\n",
      "656/656 - 20s - loss: 2.4687e-04 - val_loss: 1.1840e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 15/25\n",
      "656/656 - 20s - loss: 2.2803e-04 - val_loss: 1.0433e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 16/25\n",
      "656/656 - 21s - loss: 2.1420e-04 - val_loss: 9.3767e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 17/25\n",
      "656/656 - 21s - loss: 2.0164e-04 - val_loss: 8.3607e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 18/25\n",
      "656/656 - 20s - loss: 1.9018e-04 - val_loss: 7.4297e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 19/25\n",
      "656/656 - 21s - loss: 1.7942e-04 - val_loss: 6.5972e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 20/25\n",
      "656/656 - 20s - loss: 1.7184e-04 - val_loss: 6.0429e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 21/25\n",
      "656/656 - 21s - loss: 1.6555e-04 - val_loss: 5.7024e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 22/25\n",
      "656/656 - 21s - loss: 1.6138e-04 - val_loss: 5.3513e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 23/25\n",
      "656/656 - 21s - loss: 1.5494e-04 - val_loss: 4.9825e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 24/25\n",
      "656/656 - 20s - loss: 1.4919e-04 - val_loss: 4.6186e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 25/25\n",
      "656/656 - 21s - loss: 1.4366e-04 - val_loss: 4.2656e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 09:11:17.044194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:11:17.177801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:11:17.190001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:11:17.384834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:11:17.400374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:11:36.441919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:11:36.492295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:11:36.501061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 23s - loss: 4.1774e-04 - val_loss: 0.0011 - 23s/epoch - 35ms/step\n",
      "Epoch 2/25\n",
      "656/656 - 21s - loss: 4.7678e-04 - val_loss: 7.0081e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 3/25\n",
      "656/656 - 21s - loss: 5.5095e-04 - val_loss: 4.8528e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 4/25\n",
      "656/656 - 21s - loss: 7.7926e-04 - val_loss: 8.7126e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 5/25\n",
      "656/656 - 21s - loss: 0.0010 - val_loss: 0.0014 - 21s/epoch - 32ms/step\n",
      "Epoch 6/25\n",
      "656/656 - 21s - loss: 0.0011 - val_loss: 0.0012 - 21s/epoch - 32ms/step\n",
      "Epoch 7/25\n",
      "656/656 - 21s - loss: 9.1875e-04 - val_loss: 8.4252e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 8/25\n",
      "656/656 - 21s - loss: 7.5410e-04 - val_loss: 6.0095e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 9/25\n",
      "656/656 - 21s - loss: 6.1195e-04 - val_loss: 4.4193e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 10/25\n",
      "656/656 - 21s - loss: 5.0663e-04 - val_loss: 3.3297e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 11/25\n",
      "656/656 - 21s - loss: 4.2330e-04 - val_loss: 2.6449e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 12/25\n",
      "656/656 - 21s - loss: 3.6252e-04 - val_loss: 2.1935e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 13/25\n",
      "656/656 - 21s - loss: 3.1572e-04 - val_loss: 1.8634e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 14/25\n",
      "656/656 - 21s - loss: 2.8274e-04 - val_loss: 1.5813e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 15/25\n",
      "656/656 - 21s - loss: 2.6301e-04 - val_loss: 1.4830e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 16/25\n",
      "656/656 - 21s - loss: 2.4969e-04 - val_loss: 1.3854e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 17/25\n",
      "656/656 - 21s - loss: 2.3414e-04 - val_loss: 1.2813e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 18/25\n",
      "656/656 - 21s - loss: 2.2054e-04 - val_loss: 1.1905e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 19/25\n",
      "656/656 - 21s - loss: 2.0752e-04 - val_loss: 1.1051e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 20/25\n",
      "656/656 - 21s - loss: 1.9515e-04 - val_loss: 9.8060e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 21/25\n",
      "656/656 - 21s - loss: 1.8603e-04 - val_loss: 9.2743e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 22/25\n",
      "656/656 - 21s - loss: 1.8013e-04 - val_loss: 9.1511e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 23/25\n",
      "656/656 - 21s - loss: 1.7456e-04 - val_loss: 8.6219e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 24/25\n",
      "656/656 - 21s - loss: 1.6718e-04 - val_loss: 8.2627e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 25/25\n",
      "656/656 - 21s - loss: 1.6162e-04 - val_loss: 8.1315e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 09:19:59.554227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:19:59.684792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:19:59.696905: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:19:59.886825: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:19:59.904162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:20:19.179263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:20:19.227606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:20:19.236543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 23s - loss: 4.5518e-04 - val_loss: 5.7844e-04 - 23s/epoch - 35ms/step\n",
      "Epoch 2/50\n",
      "656/656 - 21s - loss: 5.4417e-04 - val_loss: 5.0098e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 3/50\n",
      "656/656 - 21s - loss: 7.4583e-04 - val_loss: 9.7901e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "656/656 - 21s - loss: 9.1721e-04 - val_loss: 0.0015 - 21s/epoch - 32ms/step\n",
      "Epoch 5/50\n",
      "656/656 - 21s - loss: 9.0748e-04 - val_loss: 0.0014 - 21s/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "656/656 - 21s - loss: 7.6831e-04 - val_loss: 0.0010 - 21s/epoch - 32ms/step\n",
      "Epoch 7/50\n",
      "656/656 - 21s - loss: 6.2066e-04 - val_loss: 7.0768e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "656/656 - 21s - loss: 5.0999e-04 - val_loss: 5.1522e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "656/656 - 21s - loss: 4.3140e-04 - val_loss: 3.9589e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 10/50\n",
      "656/656 - 21s - loss: 3.7639e-04 - val_loss: 3.2420e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "656/656 - 21s - loss: 3.3636e-04 - val_loss: 2.7849e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 12/50\n",
      "656/656 - 21s - loss: 3.0513e-04 - val_loss: 2.4442e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 13/50\n",
      "656/656 - 21s - loss: 2.8558e-04 - val_loss: 2.2558e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "656/656 - 21s - loss: 2.6893e-04 - val_loss: 1.9781e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "656/656 - 21s - loss: 2.4994e-04 - val_loss: 1.7763e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 16/50\n",
      "656/656 - 21s - loss: 2.3248e-04 - val_loss: 1.5585e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "656/656 - 21s - loss: 2.1754e-04 - val_loss: 1.3467e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 18/50\n",
      "656/656 - 21s - loss: 2.0130e-04 - val_loss: 1.1656e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "656/656 - 21s - loss: 1.8910e-04 - val_loss: 9.9413e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "656/656 - 21s - loss: 1.8059e-04 - val_loss: 9.1155e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "656/656 - 20s - loss: 1.7444e-04 - val_loss: 8.2984e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "656/656 - 20s - loss: 1.6877e-04 - val_loss: 7.8402e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 23/50\n",
      "656/656 - 21s - loss: 1.6171e-04 - val_loss: 6.8750e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 24/50\n",
      "656/656 - 21s - loss: 1.5436e-04 - val_loss: 6.1982e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 25/50\n",
      "656/656 - 20s - loss: 1.4984e-04 - val_loss: 5.7759e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "656/656 - 21s - loss: 1.4521e-04 - val_loss: 5.2061e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 27/50\n",
      "656/656 - 21s - loss: 1.4118e-04 - val_loss: 4.8010e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "656/656 - 20s - loss: 1.3559e-04 - val_loss: 4.4161e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 29/50\n",
      "656/656 - 20s - loss: 1.3199e-04 - val_loss: 4.0670e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 30/50\n",
      "656/656 - 20s - loss: 1.2747e-04 - val_loss: 3.7264e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "656/656 - 21s - loss: 1.2478e-04 - val_loss: 3.6344e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "656/656 - 21s - loss: 1.2188e-04 - val_loss: 3.3905e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 33/50\n",
      "656/656 - 21s - loss: 1.1932e-04 - val_loss: 3.3183e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 34/50\n",
      "656/656 - 21s - loss: 1.1657e-04 - val_loss: 3.1856e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 35/50\n",
      "656/656 - 21s - loss: 1.1468e-04 - val_loss: 3.0992e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 36/50\n",
      "656/656 - 21s - loss: 1.1341e-04 - val_loss: 3.1703e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "656/656 - 20s - loss: 1.1177e-04 - val_loss: 3.0994e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 38/50\n",
      "656/656 - 21s - loss: 1.0773e-04 - val_loss: 2.8258e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 39/50\n",
      "656/656 - 21s - loss: 1.0411e-04 - val_loss: 2.7316e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 40/50\n",
      "656/656 - 21s - loss: 1.0193e-04 - val_loss: 2.6602e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 41/50\n",
      "656/656 - 21s - loss: 1.0017e-04 - val_loss: 2.6390e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "656/656 - 21s - loss: 9.8888e-05 - val_loss: 2.5948e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 43/50\n",
      "656/656 - 21s - loss: 9.7603e-05 - val_loss: 2.5920e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "656/656 - 20s - loss: 9.6338e-05 - val_loss: 2.5572e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "656/656 - 21s - loss: 9.4630e-05 - val_loss: 2.5089e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 46/50\n",
      "656/656 - 21s - loss: 9.2899e-05 - val_loss: 2.4625e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "656/656 - 21s - loss: 9.1217e-05 - val_loss: 2.4466e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 48/50\n",
      "656/656 - 21s - loss: 8.9688e-05 - val_loss: 2.4201e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 49/50\n",
      "656/656 - 21s - loss: 8.8699e-05 - val_loss: 2.3824e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "656/656 - 21s - loss: 8.7153e-05 - val_loss: 2.3844e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 09:37:16.782929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:37:16.923807: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:37:16.936108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:37:17.145731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:37:17.161610: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:37:36.302916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:37:36.351440: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:37:36.360839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 23s - loss: 3.3353e-04 - val_loss: 7.1845e-04 - 23s/epoch - 35ms/step\n",
      "Epoch 2/50\n",
      "656/656 - 21s - loss: 3.6627e-04 - val_loss: 5.3041e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 3/50\n",
      "656/656 - 21s - loss: 4.9084e-04 - val_loss: 3.4686e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "656/656 - 21s - loss: 7.8374e-04 - val_loss: 8.1457e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 5/50\n",
      "656/656 - 21s - loss: 9.1028e-04 - val_loss: 0.0011 - 21s/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "656/656 - 21s - loss: 8.4904e-04 - val_loss: 8.6629e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 7/50\n",
      "656/656 - 21s - loss: 7.2989e-04 - val_loss: 6.0008e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "656/656 - 21s - loss: 5.9057e-04 - val_loss: 4.1506e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "656/656 - 21s - loss: 4.8907e-04 - val_loss: 2.9010e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 10/50\n",
      "656/656 - 21s - loss: 4.1357e-04 - val_loss: 2.1329e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "656/656 - 21s - loss: 3.5623e-04 - val_loss: 1.6550e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 12/50\n",
      "656/656 - 21s - loss: 3.1248e-04 - val_loss: 1.3493e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 13/50\n",
      "656/656 - 21s - loss: 2.7961e-04 - val_loss: 1.1333e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "656/656 - 21s - loss: 2.5679e-04 - val_loss: 9.5361e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "656/656 - 21s - loss: 2.3740e-04 - val_loss: 8.6322e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 16/50\n",
      "656/656 - 21s - loss: 2.1996e-04 - val_loss: 7.5259e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "656/656 - 21s - loss: 2.0819e-04 - val_loss: 7.0375e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 18/50\n",
      "656/656 - 21s - loss: 1.9593e-04 - val_loss: 6.2467e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "656/656 - 21s - loss: 1.8488e-04 - val_loss: 5.6635e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 20/50\n",
      "656/656 - 21s - loss: 1.7772e-04 - val_loss: 5.3182e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 21/50\n",
      "656/656 - 21s - loss: 1.7153e-04 - val_loss: 4.7830e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "656/656 - 21s - loss: 1.6359e-04 - val_loss: 4.2182e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 23/50\n",
      "656/656 - 21s - loss: 1.5731e-04 - val_loss: 3.9734e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 24/50\n",
      "656/656 - 21s - loss: 1.5218e-04 - val_loss: 3.7985e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 25/50\n",
      "656/656 - 21s - loss: 1.4752e-04 - val_loss: 3.5286e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "656/656 - 21s - loss: 1.4358e-04 - val_loss: 3.3642e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 27/50\n",
      "656/656 - 21s - loss: 1.4112e-04 - val_loss: 3.3911e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "656/656 - 21s - loss: 1.3801e-04 - val_loss: 3.2989e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 29/50\n",
      "656/656 - 21s - loss: 1.3467e-04 - val_loss: 3.0919e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 30/50\n",
      "656/656 - 21s - loss: 1.3033e-04 - val_loss: 2.9617e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 31/50\n",
      "656/656 - 21s - loss: 1.2640e-04 - val_loss: 2.7648e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 32/50\n",
      "656/656 - 21s - loss: 1.2254e-04 - val_loss: 2.6964e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 33/50\n",
      "656/656 - 21s - loss: 1.2063e-04 - val_loss: 2.6046e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 34/50\n",
      "656/656 - 21s - loss: 1.1835e-04 - val_loss: 2.5136e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "656/656 - 21s - loss: 1.1542e-04 - val_loss: 2.4140e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 36/50\n",
      "656/656 - 21s - loss: 1.1295e-04 - val_loss: 2.3849e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "656/656 - 21s - loss: 1.1035e-04 - val_loss: 2.2654e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 38/50\n",
      "656/656 - 21s - loss: 1.0778e-04 - val_loss: 2.1623e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 39/50\n",
      "656/656 - 21s - loss: 1.0626e-04 - val_loss: 2.1354e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 40/50\n",
      "656/656 - 21s - loss: 1.0542e-04 - val_loss: 2.1229e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 41/50\n",
      "656/656 - 21s - loss: 1.0404e-04 - val_loss: 2.1133e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "656/656 - 21s - loss: 1.0203e-04 - val_loss: 2.0195e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 43/50\n",
      "656/656 - 21s - loss: 1.0028e-04 - val_loss: 1.9843e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "656/656 - 21s - loss: 9.8969e-05 - val_loss: 1.9448e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "656/656 - 21s - loss: 9.7161e-05 - val_loss: 1.9177e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 46/50\n",
      "656/656 - 21s - loss: 9.6437e-05 - val_loss: 1.8651e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "656/656 - 21s - loss: 9.4352e-05 - val_loss: 1.8412e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 48/50\n",
      "656/656 - 21s - loss: 9.3169e-05 - val_loss: 1.7701e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 49/50\n",
      "656/656 - 21s - loss: 9.1429e-05 - val_loss: 1.7705e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "656/656 - 21s - loss: 9.0321e-05 - val_loss: 1.7443e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 09:54:32.747104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:54:32.878559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:54:32.890943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:54:33.111466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:54:33.127164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:54:52.191020: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:54:52.239157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 09:54:52.250120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 23s - loss: 4.1987e-04 - val_loss: 9.5033e-04 - 23s/epoch - 35ms/step\n",
      "Epoch 2/50\n",
      "656/656 - 21s - loss: 4.4877e-04 - val_loss: 6.8029e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 3/50\n",
      "656/656 - 21s - loss: 4.9877e-04 - val_loss: 4.6760e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "656/656 - 21s - loss: 6.6755e-04 - val_loss: 6.5676e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 5/50\n",
      "656/656 - 21s - loss: 9.4356e-04 - val_loss: 0.0014 - 21s/epoch - 31ms/step\n",
      "Epoch 6/50\n",
      "656/656 - 21s - loss: 9.7284e-04 - val_loss: 0.0012 - 21s/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "656/656 - 20s - loss: 8.5445e-04 - val_loss: 8.9155e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 8/50\n",
      "656/656 - 20s - loss: 6.9376e-04 - val_loss: 6.3701e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 9/50\n",
      "656/656 - 20s - loss: 5.6413e-04 - val_loss: 4.6719e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 10/50\n",
      "656/656 - 20s - loss: 4.7070e-04 - val_loss: 3.6055e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 11/50\n",
      "656/656 - 20s - loss: 4.0485e-04 - val_loss: 2.9499e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 12/50\n",
      "656/656 - 20s - loss: 3.5476e-04 - val_loss: 2.5302e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 13/50\n",
      "656/656 - 20s - loss: 3.1570e-04 - val_loss: 2.2262e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "656/656 - 20s - loss: 2.8790e-04 - val_loss: 1.9167e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 15/50\n",
      "656/656 - 20s - loss: 2.6578e-04 - val_loss: 1.7408e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 16/50\n",
      "656/656 - 21s - loss: 2.4934e-04 - val_loss: 1.6224e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 17/50\n",
      "656/656 - 20s - loss: 2.3273e-04 - val_loss: 1.4915e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 18/50\n",
      "656/656 - 20s - loss: 2.1920e-04 - val_loss: 1.4187e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 19/50\n",
      "656/656 - 20s - loss: 2.0995e-04 - val_loss: 1.3655e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 20/50\n",
      "656/656 - 20s - loss: 1.9980e-04 - val_loss: 1.2715e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 21/50\n",
      "656/656 - 20s - loss: 1.9008e-04 - val_loss: 1.1890e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 22/50\n",
      "656/656 - 20s - loss: 1.8175e-04 - val_loss: 1.1236e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 23/50\n",
      "656/656 - 20s - loss: 1.7434e-04 - val_loss: 1.0884e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 24/50\n",
      "656/656 - 20s - loss: 1.6888e-04 - val_loss: 1.0694e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 25/50\n",
      "656/656 - 20s - loss: 1.6426e-04 - val_loss: 1.0238e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "656/656 - 20s - loss: 1.5855e-04 - val_loss: 1.0305e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 27/50\n",
      "656/656 - 21s - loss: 1.5391e-04 - val_loss: 1.0010e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "656/656 - 20s - loss: 1.4789e-04 - val_loss: 9.4926e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 29/50\n",
      "656/656 - 20s - loss: 1.4248e-04 - val_loss: 9.2096e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 30/50\n",
      "656/656 - 20s - loss: 1.3914e-04 - val_loss: 9.1188e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "656/656 - 20s - loss: 1.3470e-04 - val_loss: 8.7779e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "656/656 - 20s - loss: 1.3094e-04 - val_loss: 8.6918e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 33/50\n",
      "656/656 - 20s - loss: 1.2847e-04 - val_loss: 8.5215e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 34/50\n",
      "656/656 - 20s - loss: 1.2435e-04 - val_loss: 8.3494e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 35/50\n",
      "656/656 - 20s - loss: 1.2153e-04 - val_loss: 8.2167e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 36/50\n",
      "656/656 - 20s - loss: 1.1811e-04 - val_loss: 8.0081e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 37/50\n",
      "656/656 - 20s - loss: 1.1557e-04 - val_loss: 7.8815e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 38/50\n",
      "656/656 - 20s - loss: 1.1283e-04 - val_loss: 7.7202e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 39/50\n",
      "656/656 - 20s - loss: 1.1031e-04 - val_loss: 7.5436e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 40/50\n",
      "656/656 - 20s - loss: 1.0794e-04 - val_loss: 7.4035e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 41/50\n",
      "656/656 - 20s - loss: 1.0546e-04 - val_loss: 7.2144e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "656/656 - 20s - loss: 1.0285e-04 - val_loss: 6.8961e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 43/50\n",
      "656/656 - 20s - loss: 1.0058e-04 - val_loss: 6.6748e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "656/656 - 20s - loss: 9.8441e-05 - val_loss: 6.4909e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "656/656 - 20s - loss: 9.6503e-05 - val_loss: 6.3881e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 46/50\n",
      "656/656 - 20s - loss: 9.4715e-05 - val_loss: 6.2210e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "656/656 - 20s - loss: 9.2886e-05 - val_loss: 6.1200e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 48/50\n",
      "656/656 - 20s - loss: 9.1815e-05 - val_loss: 6.0880e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 49/50\n",
      "656/656 - 20s - loss: 9.0115e-05 - val_loss: 5.9217e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 50/50\n",
      "656/656 - 20s - loss: 8.8152e-05 - val_loss: 5.7067e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:11:38.047338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:11:38.180981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:11:38.193490: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:11:38.421193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:11:38.436960: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:11:57.689399: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:11:57.737269: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:11:57.746624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 24s - loss: 4.4767e-04 - val_loss: 6.3309e-04 - 24s/epoch - 36ms/step\n",
      "Epoch 2/100\n",
      "656/656 - 21s - loss: 5.3911e-04 - val_loss: 4.5978e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "656/656 - 21s - loss: 7.3412e-04 - val_loss: 7.9548e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 4/100\n",
      "656/656 - 21s - loss: 9.1768e-04 - val_loss: 0.0013 - 21s/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "656/656 - 21s - loss: 9.0359e-04 - val_loss: 0.0011 - 21s/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "656/656 - 21s - loss: 7.8146e-04 - val_loss: 7.9992e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "656/656 - 21s - loss: 6.4311e-04 - val_loss: 5.7306e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 8/100\n",
      "656/656 - 21s - loss: 5.3901e-04 - val_loss: 4.1362e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "656/656 - 21s - loss: 4.5442e-04 - val_loss: 3.0889e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "656/656 - 21s - loss: 3.9245e-04 - val_loss: 2.4147e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 11/100\n",
      "656/656 - 21s - loss: 3.4556e-04 - val_loss: 1.9732e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "656/656 - 21s - loss: 3.1068e-04 - val_loss: 1.6681e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "656/656 - 21s - loss: 2.8341e-04 - val_loss: 1.4787e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "656/656 - 21s - loss: 2.6348e-04 - val_loss: 1.2629e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "656/656 - 21s - loss: 2.4545e-04 - val_loss: 1.1377e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "656/656 - 21s - loss: 2.2733e-04 - val_loss: 1.0093e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "656/656 - 21s - loss: 2.1474e-04 - val_loss: 8.7363e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "656/656 - 21s - loss: 1.9911e-04 - val_loss: 7.5590e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "656/656 - 21s - loss: 1.8708e-04 - val_loss: 6.6059e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "656/656 - 21s - loss: 1.7687e-04 - val_loss: 5.9890e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "656/656 - 21s - loss: 1.7152e-04 - val_loss: 5.5298e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "656/656 - 21s - loss: 1.6320e-04 - val_loss: 5.0082e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "656/656 - 21s - loss: 1.5830e-04 - val_loss: 4.8874e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "656/656 - 21s - loss: 1.5327e-04 - val_loss: 4.6043e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "656/656 - 21s - loss: 1.4862e-04 - val_loss: 4.2669e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "656/656 - 21s - loss: 1.4337e-04 - val_loss: 4.0503e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "656/656 - 21s - loss: 1.3942e-04 - val_loss: 3.9456e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "656/656 - 21s - loss: 1.3514e-04 - val_loss: 3.7182e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "656/656 - 21s - loss: 1.2991e-04 - val_loss: 3.5163e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "656/656 - 21s - loss: 1.2689e-04 - val_loss: 3.4681e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "656/656 - 21s - loss: 1.2371e-04 - val_loss: 3.3632e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "656/656 - 21s - loss: 1.2172e-04 - val_loss: 3.3471e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "656/656 - 21s - loss: 1.1987e-04 - val_loss: 3.3947e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "656/656 - 21s - loss: 1.1702e-04 - val_loss: 3.3371e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "656/656 - 21s - loss: 1.1852e-04 - val_loss: 3.7966e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "656/656 - 21s - loss: 1.1617e-04 - val_loss: 3.4933e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "656/656 - 21s - loss: 1.0983e-04 - val_loss: 3.2284e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "656/656 - 21s - loss: 1.0542e-04 - val_loss: 3.0592e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "656/656 - 21s - loss: 1.0249e-04 - val_loss: 2.9855e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "656/656 - 21s - loss: 1.0179e-04 - val_loss: 3.0724e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 41/100\n",
      "656/656 - 21s - loss: 1.0086e-04 - val_loss: 3.0803e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "656/656 - 21s - loss: 9.9303e-05 - val_loss: 3.0145e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 43/100\n",
      "656/656 - 21s - loss: 9.7825e-05 - val_loss: 3.0259e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "656/656 - 21s - loss: 9.6622e-05 - val_loss: 3.0023e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "656/656 - 20s - loss: 9.6155e-05 - val_loss: 3.1165e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 46/100\n",
      "656/656 - 20s - loss: 9.4630e-05 - val_loss: 3.0770e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 47/100\n",
      "656/656 - 20s - loss: 9.3634e-05 - val_loss: 3.1113e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 48/100\n",
      "656/656 - 20s - loss: 9.1772e-05 - val_loss: 3.0562e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 49/100\n",
      "656/656 - 20s - loss: 9.0291e-05 - val_loss: 3.0510e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 50/100\n",
      "656/656 - 20s - loss: 8.8817e-05 - val_loss: 3.0325e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 51/100\n",
      "656/656 - 20s - loss: 8.7887e-05 - val_loss: 3.0496e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 52/100\n",
      "656/656 - 20s - loss: 8.6794e-05 - val_loss: 3.0219e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 53/100\n",
      "656/656 - 20s - loss: 8.5475e-05 - val_loss: 2.9998e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 54/100\n",
      "656/656 - 20s - loss: 8.4654e-05 - val_loss: 3.0329e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 55/100\n",
      "656/656 - 20s - loss: 8.3730e-05 - val_loss: 3.0210e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 56/100\n",
      "656/656 - 20s - loss: 8.2823e-05 - val_loss: 3.0196e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 57/100\n",
      "656/656 - 20s - loss: 8.1804e-05 - val_loss: 2.9836e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "656/656 - 20s - loss: 8.0700e-05 - val_loss: 2.9707e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 59/100\n",
      "656/656 - 21s - loss: 7.9560e-05 - val_loss: 2.9304e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 60/100\n",
      "656/656 - 20s - loss: 7.8527e-05 - val_loss: 2.9236e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 61/100\n",
      "656/656 - 20s - loss: 7.7567e-05 - val_loss: 2.8812e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 62/100\n",
      "656/656 - 20s - loss: 7.6743e-05 - val_loss: 2.8949e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 63/100\n",
      "656/656 - 20s - loss: 7.5993e-05 - val_loss: 2.8383e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 64/100\n",
      "656/656 - 20s - loss: 7.5434e-05 - val_loss: 2.8848e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 65/100\n",
      "656/656 - 20s - loss: 7.4863e-05 - val_loss: 2.8202e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 66/100\n",
      "656/656 - 20s - loss: 7.3913e-05 - val_loss: 2.7795e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 67/100\n",
      "656/656 - 20s - loss: 7.2964e-05 - val_loss: 2.6964e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 68/100\n",
      "656/656 - 21s - loss: 7.1933e-05 - val_loss: 2.6484e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 69/100\n",
      "656/656 - 20s - loss: 7.1138e-05 - val_loss: 2.5897e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 70/100\n",
      "656/656 - 20s - loss: 7.0458e-05 - val_loss: 2.5505e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 71/100\n",
      "656/656 - 20s - loss: 6.9885e-05 - val_loss: 2.4980e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 72/100\n",
      "656/656 - 20s - loss: 6.9404e-05 - val_loss: 2.4703e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 73/100\n",
      "656/656 - 20s - loss: 6.9048e-05 - val_loss: 2.4249e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "656/656 - 20s - loss: 6.8476e-05 - val_loss: 2.3866e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 75/100\n",
      "656/656 - 20s - loss: 6.7833e-05 - val_loss: 2.3041e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 76/100\n",
      "656/656 - 20s - loss: 6.6996e-05 - val_loss: 2.2573e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 77/100\n",
      "656/656 - 20s - loss: 6.6442e-05 - val_loss: 2.2032e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 78/100\n",
      "656/656 - 20s - loss: 6.5909e-05 - val_loss: 2.1555e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 79/100\n",
      "656/656 - 20s - loss: 6.5457e-05 - val_loss: 2.1137e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "656/656 - 20s - loss: 6.5037e-05 - val_loss: 2.0662e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 81/100\n",
      "656/656 - 20s - loss: 6.4553e-05 - val_loss: 2.0256e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 82/100\n",
      "656/656 - 20s - loss: 6.4172e-05 - val_loss: 1.9826e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 83/100\n",
      "656/656 - 20s - loss: 6.3685e-05 - val_loss: 1.9443e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 84/100\n",
      "656/656 - 20s - loss: 6.3231e-05 - val_loss: 1.8916e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 85/100\n",
      "656/656 - 20s - loss: 6.2670e-05 - val_loss: 1.8556e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 86/100\n",
      "656/656 - 20s - loss: 6.2232e-05 - val_loss: 1.8179e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 87/100\n",
      "656/656 - 20s - loss: 6.1806e-05 - val_loss: 1.7838e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 88/100\n",
      "656/656 - 21s - loss: 6.1420e-05 - val_loss: 1.7529e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 89/100\n",
      "656/656 - 20s - loss: 6.1073e-05 - val_loss: 1.7246e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 90/100\n",
      "656/656 - 20s - loss: 6.0741e-05 - val_loss: 1.6952e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 91/100\n",
      "656/656 - 20s - loss: 6.0376e-05 - val_loss: 1.6646e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 92/100\n",
      "656/656 - 21s - loss: 5.9991e-05 - val_loss: 1.6352e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 93/100\n",
      "656/656 - 20s - loss: 5.9607e-05 - val_loss: 1.6075e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 94/100\n",
      "656/656 - 20s - loss: 5.9224e-05 - val_loss: 1.5817e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 95/100\n",
      "656/656 - 20s - loss: 5.8852e-05 - val_loss: 1.5568e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "656/656 - 20s - loss: 5.8483e-05 - val_loss: 1.5321e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 97/100\n",
      "656/656 - 20s - loss: 5.8110e-05 - val_loss: 1.5075e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 98/100\n",
      "656/656 - 20s - loss: 5.7728e-05 - val_loss: 1.4832e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 99/100\n",
      "656/656 - 20s - loss: 5.7337e-05 - val_loss: 1.4593e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 100/100\n",
      "656/656 - 20s - loss: 5.6935e-05 - val_loss: 1.4359e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:46:03.496402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:46:03.631055: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:46:03.643679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:46:03.865305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:46:03.881108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:46:23.065996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:46:23.114262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 10:46:23.123387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 23s - loss: 3.7346e-04 - val_loss: 7.4202e-04 - 23s/epoch - 36ms/step\n",
      "Epoch 2/100\n",
      "656/656 - 21s - loss: 4.3439e-04 - val_loss: 4.8516e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "656/656 - 21s - loss: 6.1476e-04 - val_loss: 5.5033e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 4/100\n",
      "656/656 - 21s - loss: 8.6042e-04 - val_loss: 0.0012 - 21s/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "656/656 - 21s - loss: 9.2288e-04 - val_loss: 0.0012 - 21s/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "656/656 - 21s - loss: 8.3270e-04 - val_loss: 8.7912e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "656/656 - 21s - loss: 7.0559e-04 - val_loss: 6.0202e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 8/100\n",
      "656/656 - 21s - loss: 5.6352e-04 - val_loss: 4.1513e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 9/100\n",
      "656/656 - 21s - loss: 4.6653e-04 - val_loss: 2.9179e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 10/100\n",
      "656/656 - 21s - loss: 3.9568e-04 - val_loss: 2.1890e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 11/100\n",
      "656/656 - 21s - loss: 3.4116e-04 - val_loss: 1.7194e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "656/656 - 21s - loss: 3.0065e-04 - val_loss: 1.4232e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "656/656 - 21s - loss: 2.7182e-04 - val_loss: 1.1850e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "656/656 - 21s - loss: 2.4987e-04 - val_loss: 1.0201e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "656/656 - 21s - loss: 2.3234e-04 - val_loss: 8.9615e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "656/656 - 21s - loss: 2.1536e-04 - val_loss: 7.8726e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "656/656 - 21s - loss: 2.0290e-04 - val_loss: 7.1315e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "656/656 - 21s - loss: 1.9077e-04 - val_loss: 6.4364e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "656/656 - 21s - loss: 1.8164e-04 - val_loss: 5.8948e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "656/656 - 21s - loss: 1.7432e-04 - val_loss: 5.5769e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "656/656 - 21s - loss: 1.6733e-04 - val_loss: 5.2898e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "656/656 - 21s - loss: 1.6147e-04 - val_loss: 4.9482e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "656/656 - 21s - loss: 1.5469e-04 - val_loss: 4.6076e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 24/100\n",
      "656/656 - 21s - loss: 1.5140e-04 - val_loss: 4.4713e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "656/656 - 21s - loss: 1.4639e-04 - val_loss: 4.2954e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "656/656 - 21s - loss: 1.4075e-04 - val_loss: 3.9704e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "656/656 - 21s - loss: 1.3620e-04 - val_loss: 3.8440e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "656/656 - 21s - loss: 1.3244e-04 - val_loss: 3.6732e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "656/656 - 21s - loss: 1.2900e-04 - val_loss: 3.6061e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "656/656 - 21s - loss: 1.2761e-04 - val_loss: 3.7202e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 31/100\n",
      "656/656 - 21s - loss: 1.2551e-04 - val_loss: 3.6855e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "656/656 - 20s - loss: 1.2279e-04 - val_loss: 3.5282e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 33/100\n",
      "656/656 - 20s - loss: 1.1926e-04 - val_loss: 3.3259e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 34/100\n",
      "656/656 - 20s - loss: 1.1627e-04 - val_loss: 3.1917e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 35/100\n",
      "656/656 - 20s - loss: 1.1418e-04 - val_loss: 3.1724e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 36/100\n",
      "656/656 - 20s - loss: 1.1291e-04 - val_loss: 3.1473e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 37/100\n",
      "656/656 - 20s - loss: 1.1182e-04 - val_loss: 3.1716e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 38/100\n",
      "656/656 - 20s - loss: 1.0965e-04 - val_loss: 3.0672e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 39/100\n",
      "656/656 - 20s - loss: 1.0811e-04 - val_loss: 3.0049e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 40/100\n",
      "656/656 - 20s - loss: 1.0645e-04 - val_loss: 3.0407e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 41/100\n",
      "656/656 - 20s - loss: 1.0638e-04 - val_loss: 3.0699e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "656/656 - 20s - loss: 1.0473e-04 - val_loss: 3.0352e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 43/100\n",
      "656/656 - 20s - loss: 1.0383e-04 - val_loss: 3.0728e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 44/100\n",
      "656/656 - 20s - loss: 1.0236e-04 - val_loss: 3.0521e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "656/656 - 20s - loss: 1.0083e-04 - val_loss: 3.0141e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 46/100\n",
      "656/656 - 20s - loss: 9.9118e-05 - val_loss: 2.9806e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 47/100\n",
      "656/656 - 20s - loss: 9.8067e-05 - val_loss: 2.9791e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 48/100\n",
      "656/656 - 20s - loss: 9.7256e-05 - val_loss: 3.0117e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 49/100\n",
      "656/656 - 20s - loss: 9.6753e-05 - val_loss: 3.0333e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 50/100\n",
      "656/656 - 20s - loss: 9.6142e-05 - val_loss: 3.1173e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 51/100\n",
      "656/656 - 20s - loss: 9.5619e-05 - val_loss: 3.0757e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 52/100\n",
      "656/656 - 20s - loss: 9.3762e-05 - val_loss: 3.0738e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 53/100\n",
      "656/656 - 20s - loss: 9.2905e-05 - val_loss: 3.0619e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 54/100\n",
      "656/656 - 20s - loss: 9.1187e-05 - val_loss: 3.0373e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 55/100\n",
      "656/656 - 20s - loss: 9.0229e-05 - val_loss: 3.0041e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 56/100\n",
      "656/656 - 20s - loss: 8.8963e-05 - val_loss: 2.9914e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 57/100\n",
      "656/656 - 20s - loss: 8.8068e-05 - val_loss: 2.9583e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "656/656 - 20s - loss: 8.6968e-05 - val_loss: 2.9353e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 59/100\n",
      "656/656 - 20s - loss: 8.6280e-05 - val_loss: 2.9110e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 60/100\n",
      "656/656 - 20s - loss: 8.5632e-05 - val_loss: 2.9612e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 61/100\n",
      "656/656 - 20s - loss: 8.5126e-05 - val_loss: 2.8614e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 62/100\n",
      "656/656 - 20s - loss: 8.3039e-05 - val_loss: 2.7773e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 63/100\n",
      "656/656 - 20s - loss: 8.1555e-05 - val_loss: 2.6529e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 64/100\n",
      "656/656 - 20s - loss: 8.0322e-05 - val_loss: 2.5619e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 65/100\n",
      "656/656 - 20s - loss: 7.8995e-05 - val_loss: 2.4711e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 66/100\n",
      "656/656 - 20s - loss: 7.8087e-05 - val_loss: 2.3673e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 67/100\n",
      "656/656 - 20s - loss: 7.6866e-05 - val_loss: 2.2927e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 68/100\n",
      "656/656 - 20s - loss: 7.5921e-05 - val_loss: 2.2196e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 69/100\n",
      "656/656 - 20s - loss: 7.4963e-05 - val_loss: 2.1496e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 70/100\n",
      "656/656 - 20s - loss: 7.3997e-05 - val_loss: 2.0650e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 71/100\n",
      "656/656 - 20s - loss: 7.3024e-05 - val_loss: 1.9993e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 72/100\n",
      "656/656 - 20s - loss: 7.2321e-05 - val_loss: 1.9451e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 73/100\n",
      "656/656 - 20s - loss: 7.1689e-05 - val_loss: 1.9069e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "656/656 - 21s - loss: 7.1246e-05 - val_loss: 1.8739e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 75/100\n",
      "656/656 - 20s - loss: 7.0786e-05 - val_loss: 1.8571e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 76/100\n",
      "656/656 - 20s - loss: 7.0244e-05 - val_loss: 1.8223e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 77/100\n",
      "656/656 - 20s - loss: 6.9536e-05 - val_loss: 1.7846e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 78/100\n",
      "656/656 - 20s - loss: 6.8830e-05 - val_loss: 1.7485e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 79/100\n",
      "656/656 - 20s - loss: 6.8216e-05 - val_loss: 1.7125e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "656/656 - 20s - loss: 6.7578e-05 - val_loss: 1.6786e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 81/100\n",
      "656/656 - 20s - loss: 6.6972e-05 - val_loss: 1.6474e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 82/100\n",
      "656/656 - 20s - loss: 6.6347e-05 - val_loss: 1.6158e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 83/100\n",
      "656/656 - 20s - loss: 6.5750e-05 - val_loss: 1.5864e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 84/100\n",
      "656/656 - 20s - loss: 6.5192e-05 - val_loss: 1.5595e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 85/100\n",
      "656/656 - 20s - loss: 6.4630e-05 - val_loss: 1.5345e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 86/100\n",
      "656/656 - 20s - loss: 6.4073e-05 - val_loss: 1.5117e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 87/100\n",
      "656/656 - 20s - loss: 6.3519e-05 - val_loss: 1.4912e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 88/100\n",
      "656/656 - 20s - loss: 6.2974e-05 - val_loss: 1.4731e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 89/100\n",
      "656/656 - 20s - loss: 6.2443e-05 - val_loss: 1.4574e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 90/100\n",
      "656/656 - 20s - loss: 6.1932e-05 - val_loss: 1.4439e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 91/100\n",
      "656/656 - 20s - loss: 6.1445e-05 - val_loss: 1.4325e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 92/100\n",
      "656/656 - 20s - loss: 6.0974e-05 - val_loss: 1.4229e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 93/100\n",
      "656/656 - 20s - loss: 6.0516e-05 - val_loss: 1.4147e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 94/100\n",
      "656/656 - 20s - loss: 6.0071e-05 - val_loss: 1.4080e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 95/100\n",
      "656/656 - 20s - loss: 5.9638e-05 - val_loss: 1.4023e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "656/656 - 20s - loss: 5.9220e-05 - val_loss: 1.3975e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 97/100\n",
      "656/656 - 20s - loss: 5.8815e-05 - val_loss: 1.3933e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 98/100\n",
      "656/656 - 20s - loss: 5.8423e-05 - val_loss: 1.3895e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 99/100\n",
      "656/656 - 20s - loss: 5.8045e-05 - val_loss: 1.3858e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 100/100\n",
      "656/656 - 20s - loss: 5.7681e-05 - val_loss: 1.3822e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 11:20:14.797345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:20:14.938657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:20:14.952815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:20:15.172335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:20:15.188060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:20:34.252531: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:20:34.308441: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:20:34.317285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 23s - loss: 3.9246e-04 - val_loss: 0.0011 - 23s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "656/656 - 21s - loss: 4.3081e-04 - val_loss: 7.1541e-04 - 21s/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "656/656 - 21s - loss: 4.5439e-04 - val_loss: 4.4230e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 4/100\n",
      "656/656 - 21s - loss: 6.4113e-04 - val_loss: 5.2811e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 5/100\n",
      "656/656 - 21s - loss: 9.5830e-04 - val_loss: 0.0013 - 21s/epoch - 31ms/step\n",
      "Epoch 6/100\n",
      "656/656 - 20s - loss: 0.0011 - val_loss: 0.0013 - 20s/epoch - 31ms/step\n",
      "Epoch 7/100\n",
      "656/656 - 20s - loss: 9.7138e-04 - val_loss: 8.8187e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 8/100\n",
      "656/656 - 20s - loss: 8.1510e-04 - val_loss: 5.7387e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 9/100\n",
      "656/656 - 21s - loss: 6.6655e-04 - val_loss: 4.0079e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 10/100\n",
      "656/656 - 21s - loss: 5.5256e-04 - val_loss: 3.0560e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 11/100\n",
      "656/656 - 20s - loss: 4.5934e-04 - val_loss: 2.4103e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 12/100\n",
      "656/656 - 21s - loss: 3.8877e-04 - val_loss: 1.9074e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 13/100\n",
      "656/656 - 20s - loss: 3.3168e-04 - val_loss: 1.4954e-04 - 20s/epoch - 31ms/step\n",
      "Epoch 14/100\n",
      "656/656 - 21s - loss: 2.9093e-04 - val_loss: 1.2205e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 15/100\n",
      "656/656 - 21s - loss: 2.6345e-04 - val_loss: 1.0353e-04 - 21s/epoch - 31ms/step\n",
      "Epoch 16/100\n",
      "656/656 - 20s - loss: 2.4431e-04 - val_loss: 9.3133e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 17/100\n",
      "656/656 - 21s - loss: 2.3050e-04 - val_loss: 8.9880e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 18/100\n",
      "656/656 - 20s - loss: 2.2468e-04 - val_loss: 8.6888e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 19/100\n",
      "656/656 - 21s - loss: 2.1677e-04 - val_loss: 8.1783e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 20/100\n",
      "656/656 - 20s - loss: 2.0642e-04 - val_loss: 7.2606e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 21/100\n",
      "656/656 - 20s - loss: 1.9336e-04 - val_loss: 6.3346e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 22/100\n",
      "656/656 - 20s - loss: 1.8352e-04 - val_loss: 5.9060e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 23/100\n",
      "656/656 - 20s - loss: 1.7546e-04 - val_loss: 5.2250e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 24/100\n",
      "656/656 - 20s - loss: 1.6792e-04 - val_loss: 4.8579e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 25/100\n",
      "656/656 - 20s - loss: 1.6432e-04 - val_loss: 4.7823e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 26/100\n",
      "656/656 - 20s - loss: 1.6201e-04 - val_loss: 4.8243e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 27/100\n",
      "656/656 - 20s - loss: 1.6183e-04 - val_loss: 4.7394e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 28/100\n",
      "656/656 - 20s - loss: 1.5546e-04 - val_loss: 4.2222e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 29/100\n",
      "656/656 - 20s - loss: 1.4638e-04 - val_loss: 3.6423e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 30/100\n",
      "656/656 - 20s - loss: 1.3934e-04 - val_loss: 3.3390e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 31/100\n",
      "656/656 - 20s - loss: 1.3567e-04 - val_loss: 3.2787e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 32/100\n",
      "656/656 - 20s - loss: 1.3310e-04 - val_loss: 3.2626e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 33/100\n",
      "656/656 - 20s - loss: 1.3141e-04 - val_loss: 3.1817e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 34/100\n",
      "656/656 - 20s - loss: 1.2925e-04 - val_loss: 3.0882e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 35/100\n",
      "656/656 - 20s - loss: 1.2609e-04 - val_loss: 2.9494e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 36/100\n",
      "656/656 - 20s - loss: 1.2280e-04 - val_loss: 2.9250e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 37/100\n",
      "656/656 - 20s - loss: 1.2162e-04 - val_loss: 2.8862e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 38/100\n",
      "656/656 - 20s - loss: 1.1908e-04 - val_loss: 2.7814e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 39/100\n",
      "656/656 - 20s - loss: 1.1757e-04 - val_loss: 2.7646e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 40/100\n",
      "656/656 - 20s - loss: 1.1608e-04 - val_loss: 2.7505e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 41/100\n",
      "656/656 - 20s - loss: 1.1308e-04 - val_loss: 2.6739e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "656/656 - 20s - loss: 1.0987e-04 - val_loss: 2.5460e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 43/100\n",
      "656/656 - 20s - loss: 1.0675e-04 - val_loss: 2.4524e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 44/100\n",
      "656/656 - 20s - loss: 1.0545e-04 - val_loss: 2.5746e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "656/656 - 20s - loss: 1.0534e-04 - val_loss: 2.5994e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 46/100\n",
      "656/656 - 20s - loss: 1.0439e-04 - val_loss: 2.6070e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 47/100\n",
      "656/656 - 20s - loss: 1.0195e-04 - val_loss: 2.5300e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 48/100\n",
      "656/656 - 20s - loss: 9.9863e-05 - val_loss: 2.4910e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 49/100\n",
      "656/656 - 20s - loss: 9.7871e-05 - val_loss: 2.4902e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 50/100\n",
      "656/656 - 20s - loss: 9.6661e-05 - val_loss: 2.4487e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 51/100\n",
      "656/656 - 20s - loss: 9.5583e-05 - val_loss: 2.5253e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 52/100\n",
      "656/656 - 20s - loss: 9.4209e-05 - val_loss: 2.4204e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 53/100\n",
      "656/656 - 20s - loss: 9.2735e-05 - val_loss: 2.5294e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 54/100\n",
      "656/656 - 20s - loss: 9.3143e-05 - val_loss: 2.5722e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 55/100\n",
      "656/656 - 20s - loss: 9.1812e-05 - val_loss: 2.5362e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 56/100\n",
      "656/656 - 20s - loss: 8.9920e-05 - val_loss: 2.5127e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 57/100\n",
      "656/656 - 20s - loss: 8.8209e-05 - val_loss: 2.4804e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "656/656 - 20s - loss: 8.6836e-05 - val_loss: 2.4907e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 59/100\n",
      "656/656 - 20s - loss: 8.5313e-05 - val_loss: 2.4343e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 60/100\n",
      "656/656 - 20s - loss: 8.4417e-05 - val_loss: 2.4688e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 61/100\n",
      "656/656 - 20s - loss: 8.3838e-05 - val_loss: 2.4211e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 62/100\n",
      "656/656 - 20s - loss: 8.2788e-05 - val_loss: 2.4638e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 63/100\n",
      "656/656 - 20s - loss: 8.1739e-05 - val_loss: 2.3833e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 64/100\n",
      "656/656 - 20s - loss: 8.0515e-05 - val_loss: 2.4005e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 65/100\n",
      "656/656 - 20s - loss: 7.9561e-05 - val_loss: 2.3259e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 66/100\n",
      "656/656 - 20s - loss: 7.8271e-05 - val_loss: 2.3262e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 67/100\n",
      "656/656 - 20s - loss: 7.7229e-05 - val_loss: 2.2374e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 68/100\n",
      "656/656 - 20s - loss: 7.6084e-05 - val_loss: 2.2247e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 69/100\n",
      "656/656 - 20s - loss: 7.5183e-05 - val_loss: 2.1572e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 70/100\n",
      "656/656 - 20s - loss: 7.4321e-05 - val_loss: 2.1202e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 71/100\n",
      "656/656 - 20s - loss: 7.3172e-05 - val_loss: 2.0561e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 72/100\n",
      "656/656 - 20s - loss: 7.2369e-05 - val_loss: 2.0360e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 73/100\n",
      "656/656 - 20s - loss: 7.1397e-05 - val_loss: 1.9690e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "656/656 - 20s - loss: 7.0388e-05 - val_loss: 1.9325e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 75/100\n",
      "656/656 - 20s - loss: 6.9402e-05 - val_loss: 1.8667e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 76/100\n",
      "656/656 - 20s - loss: 6.8545e-05 - val_loss: 1.8394e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 77/100\n",
      "656/656 - 20s - loss: 6.7827e-05 - val_loss: 1.7771e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 78/100\n",
      "656/656 - 20s - loss: 6.7020e-05 - val_loss: 1.7609e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 79/100\n",
      "656/656 - 20s - loss: 6.6402e-05 - val_loss: 1.6948e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "656/656 - 20s - loss: 6.5536e-05 - val_loss: 1.6903e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 81/100\n",
      "656/656 - 20s - loss: 6.5156e-05 - val_loss: 1.6226e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 82/100\n",
      "656/656 - 20s - loss: 6.4193e-05 - val_loss: 1.6250e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 83/100\n",
      "656/656 - 20s - loss: 6.3909e-05 - val_loss: 1.5558e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 84/100\n",
      "656/656 - 20s - loss: 6.2846e-05 - val_loss: 1.5654e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 85/100\n",
      "656/656 - 20s - loss: 6.2673e-05 - val_loss: 1.4971e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 86/100\n",
      "656/656 - 20s - loss: 6.1518e-05 - val_loss: 1.5120e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 87/100\n",
      "656/656 - 20s - loss: 6.1443e-05 - val_loss: 1.4455e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 88/100\n",
      "656/656 - 20s - loss: 6.0242e-05 - val_loss: 1.4664e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 89/100\n",
      "656/656 - 20s - loss: 6.0338e-05 - val_loss: 1.4030e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 90/100\n",
      "656/656 - 20s - loss: 5.9112e-05 - val_loss: 1.4279e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 91/100\n",
      "656/656 - 21s - loss: 5.9336e-05 - val_loss: 1.3666e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "656/656 - 21s - loss: 5.8050e-05 - val_loss: 1.3944e-05 - 21s/epoch - 33ms/step\n",
      "Epoch 93/100\n",
      "656/656 - 21s - loss: 5.8350e-05 - val_loss: 1.3350e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "656/656 - 21s - loss: 5.7023e-05 - val_loss: 1.3642e-05 - 21s/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "656/656 - 21s - loss: 5.7375e-05 - val_loss: 1.3068e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "656/656 - 21s - loss: 5.6040e-05 - val_loss: 1.3375e-05 - 21s/epoch - 31ms/step\n",
      "Epoch 97/100\n",
      "656/656 - 20s - loss: 5.6450e-05 - val_loss: 1.2813e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 98/100\n",
      "656/656 - 20s - loss: 5.5113e-05 - val_loss: 1.3137e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 99/100\n",
      "656/656 - 20s - loss: 5.5569e-05 - val_loss: 1.2580e-05 - 20s/epoch - 31ms/step\n",
      "Epoch 100/100\n",
      "656/656 - 20s - loss: 5.4211e-05 - val_loss: 1.2918e-05 - 20s/epoch - 31ms/step\n"
     ]
    }
   ],
   "source": [
    "bilstms1 = []\n",
    "models1 = []\n",
    "for batch, epoch, neuron in hyperparam1:\n",
    "    model, bilstm = LSTMUnit.train_bilstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    bilstms1.append(bilstm)\n",
    "    models1.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe15d8d-6bc9-4220-a7db-48e4d4c7cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 3s 16ms/step\n",
      "(32, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "33.68467402845758\n",
      "MAE\n",
      "29.02312260362249\n",
      "MAPE\n",
      "2.2177787396527515\n",
      "163/163 [==============================] - 3s 15ms/step\n",
      "(32, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "31.023670856903372\n",
      "MAE\n",
      "26.642899496615303\n",
      "MAPE\n",
      "2.026875102261301\n",
      "163/163 [==============================] - 3s 16ms/step\n",
      "(32, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "42.83386991817848\n",
      "MAE\n",
      "37.135559742923014\n",
      "MAPE\n",
      "2.8810187612317444\n",
      "163/163 [==============================] - 3s 16ms/step\n",
      "(32, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "23.194798544485874\n",
      "MAE\n",
      "19.550082221215273\n",
      "MAPE\n",
      "1.4431084711738624\n",
      "163/163 [==============================] - 3s 15ms/step\n",
      "(32, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "19.838731526615515\n",
      "MAE\n",
      "16.181543412471466\n",
      "MAPE\n",
      "1.1756605851209518\n",
      "163/163 [==============================] - 3s 16ms/step\n",
      "(32, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "35.88338858357046\n",
      "MAE\n",
      "30.96003548036365\n",
      "MAPE\n",
      "2.386185223001032\n",
      "163/163 [==============================] - 3s 15ms/step\n",
      "(32, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "17.99946430229498\n",
      "MAE\n",
      "13.815458705759202\n",
      "MAPE\n",
      "0.9869571207561514\n",
      "163/163 [==============================] - 3s 15ms/step\n",
      "(32, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "17.659528100227256\n",
      "MAE\n",
      "12.698034805400482\n",
      "MAPE\n",
      "0.8753756782108595\n",
      "163/163 [==============================] - 3s 16ms/step\n",
      "(32, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "17.072859737779194\n",
      "MAE\n",
      "12.467630650647687\n",
      "MAPE\n",
      "0.8788786194731122\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb1 = Workbook()\n",
    "ws1 = wb1.active\n",
    "for m in models1:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = LSTMUnit.predict(test_x2, m)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparam1[i])\n",
    "    print(\"Epoch: \"+ str(bilstms1[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].layer.units))\n",
    "    i = i+1\n",
    "    ws1['A'+str(i)] = 'BiLSTM'\n",
    "    ws1['B'+str(i)] = hyperparam1[i-1][0]\n",
    "    ws1['C'+str(i)] = hyperparam1[i-1][1]\n",
    "    ws1['D'+str(i)] = hyperparam1[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
    "    ws1['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
    "    print('MAE')\n",
    "    print(Evaluation.mae(inv_y,inv_yhat))\n",
    "    ws1['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
    "    print('MAPE')\n",
    "    print(Evaluation.mape(inv_y,inv_yhat))\n",
    "    ws1['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
    "    LSTMUnit.save_model(m, 1, 'ETH',hyperparam1[i-1])\n",
    "    with open('BiLSTM_ETH'+str(hyperparam1[i-1])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(bilstms1[i-1].history, f)\n",
    "wb1.save('BiLSTM_ETH_result1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b72569-a783-465c-b828-1a68e970e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 11:54:46.761643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:54:46.902273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:54:46.914552: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:54:47.198814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:54:47.214480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:54:57.519387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:54:57.573061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:54:57.582143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 13s - loss: 8.0737e-04 - val_loss: 5.0371e-04 - 13s/epoch - 41ms/step\n",
      "Epoch 2/25\n",
      "328/328 - 10s - loss: 8.3597e-04 - val_loss: 3.2567e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 3/25\n",
      "328/328 - 10s - loss: 7.8185e-04 - val_loss: 3.7901e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 4/25\n",
      "328/328 - 10s - loss: 8.5525e-04 - val_loss: 7.4665e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 5/25\n",
      "328/328 - 10s - loss: 0.0011 - val_loss: 0.0012 - 10s/epoch - 31ms/step\n",
      "Epoch 6/25\n",
      "328/328 - 10s - loss: 0.0013 - val_loss: 0.0022 - 10s/epoch - 31ms/step\n",
      "Epoch 7/25\n",
      "328/328 - 10s - loss: 0.0016 - val_loss: 0.0025 - 10s/epoch - 32ms/step\n",
      "Epoch 8/25\n",
      "328/328 - 10s - loss: 0.0017 - val_loss: 0.0027 - 10s/epoch - 32ms/step\n",
      "Epoch 9/25\n",
      "328/328 - 10s - loss: 0.0014 - val_loss: 0.0020 - 10s/epoch - 32ms/step\n",
      "Epoch 10/25\n",
      "328/328 - 10s - loss: 0.0011 - val_loss: 0.0014 - 10s/epoch - 31ms/step\n",
      "Epoch 11/25\n",
      "328/328 - 10s - loss: 9.0916e-04 - val_loss: 9.2856e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 12/25\n",
      "328/328 - 10s - loss: 7.6160e-04 - val_loss: 6.7291e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 13/25\n",
      "328/328 - 10s - loss: 6.6226e-04 - val_loss: 5.3198e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 14/25\n",
      "328/328 - 10s - loss: 5.9441e-04 - val_loss: 4.5907e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 15/25\n",
      "328/328 - 10s - loss: 5.4757e-04 - val_loss: 4.2757e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 16/25\n",
      "328/328 - 10s - loss: 5.1458e-04 - val_loss: 4.2074e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 17/25\n",
      "328/328 - 10s - loss: 4.9432e-04 - val_loss: 4.2597e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 18/25\n",
      "328/328 - 10s - loss: 4.7591e-04 - val_loss: 4.4041e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 19/25\n",
      "328/328 - 10s - loss: 4.6719e-04 - val_loss: 4.6100e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 20/25\n",
      "328/328 - 10s - loss: 4.3458e-04 - val_loss: 4.6106e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 21/25\n",
      "328/328 - 10s - loss: 4.2147e-04 - val_loss: 4.4977e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 22/25\n",
      "328/328 - 10s - loss: 4.2360e-04 - val_loss: 4.7615e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 23/25\n",
      "328/328 - 10s - loss: 4.3069e-04 - val_loss: 5.0973e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 24/25\n",
      "328/328 - 10s - loss: 4.2883e-04 - val_loss: 5.3309e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 25/25\n",
      "328/328 - 10s - loss: 4.3445e-04 - val_loss: 5.4638e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 11:59:06.106052: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:59:06.248995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:59:06.261171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:59:06.681194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:59:06.697162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:59:17.324772: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:59:17.391924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 11:59:17.400999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 14s - loss: 2.8654e-04 - val_loss: 1.9167e-04 - 14s/epoch - 42ms/step\n",
      "Epoch 2/25\n",
      "328/328 - 10s - loss: 6.5045e-04 - val_loss: 9.0354e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 3/25\n",
      "328/328 - 10s - loss: 5.2914e-04 - val_loss: 5.0378e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 4/25\n",
      "328/328 - 11s - loss: 3.8509e-04 - val_loss: 3.7649e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 5/25\n",
      "328/328 - 11s - loss: 2.9369e-04 - val_loss: 3.1746e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 6/25\n",
      "328/328 - 10s - loss: 2.5918e-04 - val_loss: 2.8936e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 7/25\n",
      "328/328 - 10s - loss: 2.3285e-04 - val_loss: 2.6782e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 8/25\n",
      "328/328 - 10s - loss: 2.1355e-04 - val_loss: 2.5269e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 9/25\n",
      "328/328 - 10s - loss: 1.9896e-04 - val_loss: 2.4317e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 10/25\n",
      "328/328 - 10s - loss: 1.8738e-04 - val_loss: 2.3767e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 11/25\n",
      "328/328 - 10s - loss: 1.7741e-04 - val_loss: 2.3451e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 12/25\n",
      "328/328 - 10s - loss: 1.6829e-04 - val_loss: 2.3235e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 13/25\n",
      "328/328 - 10s - loss: 1.6015e-04 - val_loss: 2.3046e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 14/25\n",
      "328/328 - 10s - loss: 1.5282e-04 - val_loss: 2.2854e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 15/25\n",
      "328/328 - 10s - loss: 1.4650e-04 - val_loss: 2.2667e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 16/25\n",
      "328/328 - 10s - loss: 1.4050e-04 - val_loss: 2.2462e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 17/25\n",
      "328/328 - 10s - loss: 1.3840e-04 - val_loss: 2.2681e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 18/25\n",
      "328/328 - 10s - loss: 1.3364e-04 - val_loss: 2.2290e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 19/25\n",
      "328/328 - 10s - loss: 1.3263e-04 - val_loss: 2.2110e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 20/25\n",
      "328/328 - 10s - loss: 1.2401e-04 - val_loss: 2.0705e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 21/25\n",
      "328/328 - 10s - loss: 1.1452e-04 - val_loss: 1.9102e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 22/25\n",
      "328/328 - 10s - loss: 1.1155e-04 - val_loss: 1.8662e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 23/25\n",
      "328/328 - 10s - loss: 1.1128e-04 - val_loss: 1.9004e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 24/25\n",
      "328/328 - 10s - loss: 1.0887e-04 - val_loss: 1.8576e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 25/25\n",
      "328/328 - 10s - loss: 1.0548e-04 - val_loss: 1.8007e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:03:31.029630: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:03:31.173805: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:03:31.186210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:03:31.489881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:03:31.505754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:03:42.155150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:03:42.204451: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:03:42.213454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 14s - loss: 3.9019e-04 - val_loss: 2.3197e-04 - 14s/epoch - 42ms/step\n",
      "Epoch 2/25\n",
      "328/328 - 11s - loss: 7.6301e-04 - val_loss: 9.4599e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 3/25\n",
      "328/328 - 11s - loss: 7.2845e-04 - val_loss: 5.2435e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 4/25\n",
      "328/328 - 11s - loss: 5.8406e-04 - val_loss: 3.3157e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 5/25\n",
      "328/328 - 11s - loss: 4.5718e-04 - val_loss: 2.6936e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 6/25\n",
      "328/328 - 11s - loss: 4.1540e-04 - val_loss: 2.2153e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 7/25\n",
      "328/328 - 11s - loss: 3.5989e-04 - val_loss: 2.1057e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 8/25\n",
      "328/328 - 11s - loss: 3.4329e-04 - val_loss: 2.0252e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 9/25\n",
      "328/328 - 11s - loss: 3.3182e-04 - val_loss: 1.9021e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 10/25\n",
      "328/328 - 11s - loss: 3.1792e-04 - val_loss: 1.8227e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 11/25\n",
      "328/328 - 11s - loss: 3.1114e-04 - val_loss: 1.7111e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 12/25\n",
      "328/328 - 11s - loss: 2.9980e-04 - val_loss: 1.5786e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 13/25\n",
      "328/328 - 11s - loss: 2.8740e-04 - val_loss: 1.4612e-04 - 11s/epoch - 34ms/step\n",
      "Epoch 14/25\n",
      "328/328 - 11s - loss: 2.8111e-04 - val_loss: 1.3752e-04 - 11s/epoch - 34ms/step\n",
      "Epoch 15/25\n",
      "328/328 - 11s - loss: 2.6167e-04 - val_loss: 1.3612e-04 - 11s/epoch - 34ms/step\n",
      "Epoch 16/25\n",
      "328/328 - 11s - loss: 2.5621e-04 - val_loss: 1.3299e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 17/25\n",
      "328/328 - 11s - loss: 2.4707e-04 - val_loss: 1.2633e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 18/25\n",
      "328/328 - 11s - loss: 2.3326e-04 - val_loss: 1.2386e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 19/25\n",
      "328/328 - 11s - loss: 2.1469e-04 - val_loss: 1.2462e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 20/25\n",
      "328/328 - 11s - loss: 1.9831e-04 - val_loss: 1.2730e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 21/25\n",
      "328/328 - 11s - loss: 1.8642e-04 - val_loss: 1.2926e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 22/25\n",
      "328/328 - 11s - loss: 1.7475e-04 - val_loss: 1.2336e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 23/25\n",
      "328/328 - 11s - loss: 1.5470e-04 - val_loss: 1.2640e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 24/25\n",
      "328/328 - 11s - loss: 1.4090e-04 - val_loss: 1.2539e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 25/25\n",
      "328/328 - 11s - loss: 1.2616e-04 - val_loss: 1.2463e-04 - 11s/epoch - 35ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:08:10.051465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:08:10.200905: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:08:10.215637: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:08:10.506676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:08:10.523170: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:08:20.985907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:08:21.037886: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:08:21.046749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 14s - loss: 9.4708e-04 - val_loss: 4.8565e-04 - 14s/epoch - 41ms/step\n",
      "Epoch 2/50\n",
      "328/328 - 10s - loss: 8.6405e-04 - val_loss: 3.7268e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 3/50\n",
      "328/328 - 10s - loss: 8.3578e-04 - val_loss: 4.6841e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "328/328 - 10s - loss: 9.5303e-04 - val_loss: 9.8581e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 5/50\n",
      "328/328 - 11s - loss: 0.0011 - val_loss: 0.0013 - 11s/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "328/328 - 10s - loss: 0.0014 - val_loss: 0.0023 - 10s/epoch - 32ms/step\n",
      "Epoch 7/50\n",
      "328/328 - 10s - loss: 0.0017 - val_loss: 0.0028 - 10s/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "328/328 - 10s - loss: 0.0017 - val_loss: 0.0028 - 10s/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "328/328 - 10s - loss: 0.0014 - val_loss: 0.0020 - 10s/epoch - 32ms/step\n",
      "Epoch 10/50\n",
      "328/328 - 10s - loss: 0.0011 - val_loss: 0.0013 - 10s/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "328/328 - 10s - loss: 8.9560e-04 - val_loss: 9.0202e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 12/50\n",
      "328/328 - 10s - loss: 7.5235e-04 - val_loss: 6.5896e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 13/50\n",
      "328/328 - 10s - loss: 6.5814e-04 - val_loss: 5.3033e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "328/328 - 10s - loss: 5.9516e-04 - val_loss: 4.6825e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "328/328 - 10s - loss: 5.5242e-04 - val_loss: 4.4704e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 16/50\n",
      "328/328 - 10s - loss: 5.2358e-04 - val_loss: 4.5069e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "328/328 - 10s - loss: 4.9631e-04 - val_loss: 4.6581e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 18/50\n",
      "328/328 - 10s - loss: 4.7762e-04 - val_loss: 4.8178e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "328/328 - 10s - loss: 4.8426e-04 - val_loss: 5.1139e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "328/328 - 10s - loss: 4.7693e-04 - val_loss: 5.4756e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "328/328 - 10s - loss: 4.7789e-04 - val_loss: 5.5647e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "328/328 - 10s - loss: 4.5918e-04 - val_loss: 5.4797e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "328/328 - 10s - loss: 4.7031e-04 - val_loss: 5.7536e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 24/50\n",
      "328/328 - 10s - loss: 4.4890e-04 - val_loss: 5.7319e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 25/50\n",
      "328/328 - 10s - loss: 4.4589e-04 - val_loss: 5.6343e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 26/50\n",
      "328/328 - 10s - loss: 4.2349e-04 - val_loss: 5.2992e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "328/328 - 10s - loss: 3.9475e-04 - val_loss: 5.3244e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 28/50\n",
      "328/328 - 10s - loss: 3.7880e-04 - val_loss: 5.1370e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "328/328 - 10s - loss: 3.6070e-04 - val_loss: 5.0369e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 30/50\n",
      "328/328 - 10s - loss: 3.3917e-04 - val_loss: 4.9549e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 31/50\n",
      "328/328 - 10s - loss: 3.2507e-04 - val_loss: 5.0063e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 32/50\n",
      "328/328 - 10s - loss: 3.2008e-04 - val_loss: 5.1785e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "328/328 - 10s - loss: 3.1535e-04 - val_loss: 5.4199e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "328/328 - 10s - loss: 3.0109e-04 - val_loss: 5.5186e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "328/328 - 10s - loss: 3.0815e-04 - val_loss: 5.8788e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 36/50\n",
      "328/328 - 10s - loss: 3.0305e-04 - val_loss: 6.0747e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 37/50\n",
      "328/328 - 10s - loss: 3.0168e-04 - val_loss: 6.2143e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 38/50\n",
      "328/328 - 10s - loss: 2.9345e-04 - val_loss: 6.2902e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 39/50\n",
      "328/328 - 10s - loss: 2.8135e-04 - val_loss: 6.2244e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 40/50\n",
      "328/328 - 10s - loss: 2.7625e-04 - val_loss: 6.5436e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 41/50\n",
      "328/328 - 10s - loss: 2.6418e-04 - val_loss: 6.2782e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 42/50\n",
      "328/328 - 10s - loss: 2.6775e-04 - val_loss: 6.7083e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 43/50\n",
      "328/328 - 10s - loss: 2.5746e-04 - val_loss: 6.5646e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 44/50\n",
      "328/328 - 10s - loss: 2.5604e-04 - val_loss: 6.7598e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 45/50\n",
      "328/328 - 10s - loss: 2.4516e-04 - val_loss: 6.7096e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 46/50\n",
      "328/328 - 10s - loss: 2.4730e-04 - val_loss: 6.9618e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 47/50\n",
      "328/328 - 10s - loss: 2.4175e-04 - val_loss: 6.8798e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 48/50\n",
      "328/328 - 10s - loss: 2.4015e-04 - val_loss: 7.0454e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 49/50\n",
      "328/328 - 10s - loss: 2.3505e-04 - val_loss: 6.9272e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 50/50\n",
      "328/328 - 10s - loss: 2.3043e-04 - val_loss: 7.0366e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:16:53.951474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:16:54.085498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:16:54.099336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:16:54.381132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:16:54.397079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:17:04.779501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:17:04.827343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:17:04.836436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 13s - loss: 2.6335e-04 - val_loss: 1.4806e-04 - 13s/epoch - 41ms/step\n",
      "Epoch 2/50\n",
      "328/328 - 10s - loss: 6.3383e-04 - val_loss: 8.9194e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 3/50\n",
      "328/328 - 10s - loss: 4.8513e-04 - val_loss: 5.1679e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "328/328 - 10s - loss: 3.5406e-04 - val_loss: 3.7694e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 5/50\n",
      "328/328 - 10s - loss: 2.6654e-04 - val_loss: 3.1575e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "328/328 - 10s - loss: 2.3091e-04 - val_loss: 2.8102e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 7/50\n",
      "328/328 - 10s - loss: 2.1146e-04 - val_loss: 2.6030e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 8/50\n",
      "328/328 - 10s - loss: 1.9991e-04 - val_loss: 2.5123e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 9/50\n",
      "328/328 - 10s - loss: 1.9167e-04 - val_loss: 2.4836e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 10/50\n",
      "328/328 - 10s - loss: 1.8340e-04 - val_loss: 2.4585e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 11/50\n",
      "328/328 - 10s - loss: 1.7479e-04 - val_loss: 2.4152e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 12/50\n",
      "328/328 - 10s - loss: 1.6619e-04 - val_loss: 2.3642e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 13/50\n",
      "328/328 - 10s - loss: 1.5917e-04 - val_loss: 2.3052e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 14/50\n",
      "328/328 - 10s - loss: 1.4808e-04 - val_loss: 2.2340e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "328/328 - 10s - loss: 1.4426e-04 - val_loss: 2.2103e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 16/50\n",
      "328/328 - 10s - loss: 1.3882e-04 - val_loss: 2.1906e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 17/50\n",
      "328/328 - 10s - loss: 1.3703e-04 - val_loss: 2.1780e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 18/50\n",
      "328/328 - 10s - loss: 1.3207e-04 - val_loss: 2.1369e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "328/328 - 10s - loss: 1.2523e-04 - val_loss: 2.0248e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "328/328 - 10s - loss: 1.1774e-04 - val_loss: 1.9213e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "328/328 - 10s - loss: 1.2183e-04 - val_loss: 2.0321e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "328/328 - 10s - loss: 1.1235e-04 - val_loss: 1.8403e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 23/50\n",
      "328/328 - 10s - loss: 1.0613e-04 - val_loss: 1.7095e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 24/50\n",
      "328/328 - 10s - loss: 1.0260e-04 - val_loss: 1.6536e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 25/50\n",
      "328/328 - 10s - loss: 1.0294e-04 - val_loss: 1.6929e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 26/50\n",
      "328/328 - 10s - loss: 1.0292e-04 - val_loss: 1.6656e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "328/328 - 10s - loss: 9.8965e-05 - val_loss: 1.6545e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 28/50\n",
      "328/328 - 10s - loss: 9.5335e-05 - val_loss: 1.5392e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "328/328 - 10s - loss: 9.4385e-05 - val_loss: 1.5125e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 30/50\n",
      "328/328 - 10s - loss: 8.9243e-05 - val_loss: 1.3705e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 31/50\n",
      "328/328 - 10s - loss: 8.8839e-05 - val_loss: 1.4087e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 32/50\n",
      "328/328 - 10s - loss: 8.9258e-05 - val_loss: 1.4482e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 33/50\n",
      "328/328 - 10s - loss: 8.8251e-05 - val_loss: 1.3877e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "328/328 - 10s - loss: 8.4697e-05 - val_loss: 1.3450e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 35/50\n",
      "328/328 - 10s - loss: 8.3185e-05 - val_loss: 1.3074e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 36/50\n",
      "328/328 - 10s - loss: 7.9612e-05 - val_loss: 1.2102e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 37/50\n",
      "328/328 - 10s - loss: 8.0613e-05 - val_loss: 1.2446e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 38/50\n",
      "328/328 - 10s - loss: 8.1462e-05 - val_loss: 1.2965e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 39/50\n",
      "328/328 - 10s - loss: 8.0065e-05 - val_loss: 1.2546e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 40/50\n",
      "328/328 - 10s - loss: 7.7226e-05 - val_loss: 1.1798e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 41/50\n",
      "328/328 - 10s - loss: 7.5854e-05 - val_loss: 1.1347e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 42/50\n",
      "328/328 - 10s - loss: 7.5606e-05 - val_loss: 1.1230e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 43/50\n",
      "328/328 - 10s - loss: 7.5669e-05 - val_loss: 1.1663e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 44/50\n",
      "328/328 - 10s - loss: 7.4167e-05 - val_loss: 1.1037e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "328/328 - 10s - loss: 7.2190e-05 - val_loss: 1.0734e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 46/50\n",
      "328/328 - 10s - loss: 7.1868e-05 - val_loss: 1.0627e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "328/328 - 10s - loss: 7.0395e-05 - val_loss: 1.0356e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 48/50\n",
      "328/328 - 10s - loss: 6.9094e-05 - val_loss: 1.0014e-04 - 10s/epoch - 31ms/step\n",
      "Epoch 49/50\n",
      "328/328 - 10s - loss: 7.0826e-05 - val_loss: 1.0658e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 50/50\n",
      "328/328 - 10s - loss: 6.9974e-05 - val_loss: 1.0566e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:25:34.023056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:25:34.159676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:25:34.174384: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:25:34.471595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:25:34.487174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:25:45.171694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:25:45.221454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:25:45.230874: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 14s - loss: 5.0541e-04 - val_loss: 5.3467e-04 - 14s/epoch - 43ms/step\n",
      "Epoch 2/50\n",
      "328/328 - 11s - loss: 8.3602e-04 - val_loss: 0.0010 - 11s/epoch - 33ms/step\n",
      "Epoch 3/50\n",
      "328/328 - 11s - loss: 8.2454e-04 - val_loss: 5.2770e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 4/50\n",
      "328/328 - 11s - loss: 6.3738e-04 - val_loss: 3.9122e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 5/50\n",
      "328/328 - 11s - loss: 5.3343e-04 - val_loss: 3.0810e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 6/50\n",
      "328/328 - 11s - loss: 4.6722e-04 - val_loss: 2.7714e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 7/50\n",
      "328/328 - 11s - loss: 4.3727e-04 - val_loss: 2.6775e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 8/50\n",
      "328/328 - 11s - loss: 4.3621e-04 - val_loss: 2.6241e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 9/50\n",
      "328/328 - 11s - loss: 4.3343e-04 - val_loss: 2.5609e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 10/50\n",
      "328/328 - 11s - loss: 4.3827e-04 - val_loss: 2.3840e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 11/50\n",
      "328/328 - 11s - loss: 4.2372e-04 - val_loss: 2.4084e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 12/50\n",
      "328/328 - 11s - loss: 4.2461e-04 - val_loss: 2.2644e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 13/50\n",
      "328/328 - 11s - loss: 3.9842e-04 - val_loss: 2.3875e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 14/50\n",
      "328/328 - 11s - loss: 3.9567e-04 - val_loss: 2.4477e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 15/50\n",
      "328/328 - 11s - loss: 3.9770e-04 - val_loss: 2.4040e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 16/50\n",
      "328/328 - 11s - loss: 3.8532e-04 - val_loss: 2.6453e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 17/50\n",
      "328/328 - 11s - loss: 4.0037e-04 - val_loss: 2.8364e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 18/50\n",
      "328/328 - 11s - loss: 3.9496e-04 - val_loss: 2.9871e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 19/50\n",
      "328/328 - 11s - loss: 4.0610e-04 - val_loss: 3.5243e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "328/328 - 11s - loss: 4.3445e-04 - val_loss: 4.1045e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 21/50\n",
      "328/328 - 11s - loss: 4.7298e-04 - val_loss: 5.3445e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 22/50\n",
      "328/328 - 11s - loss: 5.1839e-04 - val_loss: 6.7613e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 23/50\n",
      "328/328 - 11s - loss: 5.4975e-04 - val_loss: 7.6745e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 24/50\n",
      "328/328 - 11s - loss: 5.7285e-04 - val_loss: 8.3723e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 25/50\n",
      "328/328 - 11s - loss: 6.1963e-04 - val_loss: 9.2386e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 26/50\n",
      "328/328 - 11s - loss: 6.2445e-04 - val_loss: 9.1676e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 27/50\n",
      "328/328 - 11s - loss: 6.1371e-04 - val_loss: 8.4110e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 28/50\n",
      "328/328 - 11s - loss: 5.5615e-04 - val_loss: 7.1069e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 29/50\n",
      "328/328 - 11s - loss: 4.8423e-04 - val_loss: 5.9744e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 30/50\n",
      "328/328 - 11s - loss: 4.1866e-04 - val_loss: 5.1058e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 31/50\n",
      "328/328 - 11s - loss: 3.7091e-04 - val_loss: 4.5251e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 32/50\n",
      "328/328 - 11s - loss: 3.3855e-04 - val_loss: 4.2503e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 33/50\n",
      "328/328 - 11s - loss: 3.1861e-04 - val_loss: 4.2316e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 34/50\n",
      "328/328 - 11s - loss: 3.0853e-04 - val_loss: 4.3955e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 35/50\n",
      "328/328 - 11s - loss: 3.0884e-04 - val_loss: 4.6686e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 36/50\n",
      "328/328 - 11s - loss: 3.1553e-04 - val_loss: 5.0390e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 37/50\n",
      "328/328 - 11s - loss: 3.2077e-04 - val_loss: 5.4847e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 38/50\n",
      "328/328 - 11s - loss: 3.3042e-04 - val_loss: 5.8619e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 39/50\n",
      "328/328 - 11s - loss: 3.3941e-04 - val_loss: 6.3675e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 40/50\n",
      "328/328 - 11s - loss: 3.3885e-04 - val_loss: 6.5027e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 41/50\n",
      "328/328 - 11s - loss: 3.3122e-04 - val_loss: 6.7016e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 42/50\n",
      "328/328 - 11s - loss: 3.2372e-04 - val_loss: 6.4813e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 43/50\n",
      "328/328 - 11s - loss: 3.1544e-04 - val_loss: 6.5625e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 44/50\n",
      "328/328 - 11s - loss: 2.9500e-04 - val_loss: 6.1971e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 45/50\n",
      "328/328 - 11s - loss: 2.9099e-04 - val_loss: 6.3703e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 46/50\n",
      "328/328 - 11s - loss: 2.7032e-04 - val_loss: 6.0198e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 47/50\n",
      "328/328 - 11s - loss: 2.6153e-04 - val_loss: 6.0187e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 48/50\n",
      "328/328 - 11s - loss: 2.4939e-04 - val_loss: 5.9992e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 49/50\n",
      "328/328 - 11s - loss: 2.4294e-04 - val_loss: 6.2393e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 50/50\n",
      "328/328 - 11s - loss: 2.3603e-04 - val_loss: 6.4660e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:34:31.948420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:34:32.089136: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:34:32.102893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:34:32.372201: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:34:32.387937: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:34:43.034006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:34:43.082818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:34:43.091910: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 14s - loss: 8.7694e-04 - val_loss: 5.9144e-04 - 14s/epoch - 42ms/step\n",
      "Epoch 2/100\n",
      "328/328 - 10s - loss: 8.4290e-04 - val_loss: 3.2403e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "328/328 - 10s - loss: 7.7635e-04 - val_loss: 3.2837e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 4/100\n",
      "328/328 - 11s - loss: 7.7807e-04 - val_loss: 5.4833e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "328/328 - 10s - loss: 9.2910e-04 - val_loss: 8.3732e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "328/328 - 10s - loss: 0.0011 - val_loss: 0.0016 - 10s/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "328/328 - 10s - loss: 0.0014 - val_loss: 0.0020 - 10s/epoch - 32ms/step\n",
      "Epoch 8/100\n",
      "328/328 - 10s - loss: 0.0015 - val_loss: 0.0024 - 10s/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "328/328 - 10s - loss: 0.0016 - val_loss: 0.0022 - 10s/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "328/328 - 10s - loss: 0.0013 - val_loss: 0.0016 - 10s/epoch - 32ms/step\n",
      "Epoch 11/100\n",
      "328/328 - 10s - loss: 0.0010 - val_loss: 0.0011 - 10s/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "328/328 - 10s - loss: 8.2815e-04 - val_loss: 7.2709e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "328/328 - 10s - loss: 6.9457e-04 - val_loss: 5.2607e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "328/328 - 10s - loss: 6.0628e-04 - val_loss: 4.1913e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "328/328 - 10s - loss: 5.4738e-04 - val_loss: 3.6656e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "328/328 - 10s - loss: 5.0670e-04 - val_loss: 3.4661e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "328/328 - 10s - loss: 4.7798e-04 - val_loss: 3.4385e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "328/328 - 10s - loss: 4.5925e-04 - val_loss: 3.5030e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "328/328 - 10s - loss: 4.4995e-04 - val_loss: 3.6105e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "328/328 - 10s - loss: 4.3099e-04 - val_loss: 3.6891e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "328/328 - 10s - loss: 4.1012e-04 - val_loss: 3.4795e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "328/328 - 10s - loss: 4.1012e-04 - val_loss: 3.8501e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "328/328 - 10s - loss: 4.0951e-04 - val_loss: 3.8531e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "328/328 - 10s - loss: 4.2173e-04 - val_loss: 3.9910e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "328/328 - 10s - loss: 4.2675e-04 - val_loss: 4.1620e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "328/328 - 10s - loss: 4.1466e-04 - val_loss: 4.0906e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "328/328 - 10s - loss: 4.0794e-04 - val_loss: 3.9865e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "328/328 - 10s - loss: 3.8594e-04 - val_loss: 3.7413e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "328/328 - 10s - loss: 3.6780e-04 - val_loss: 3.5264e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "328/328 - 10s - loss: 3.4221e-04 - val_loss: 3.3432e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "328/328 - 10s - loss: 3.2453e-04 - val_loss: 3.1344e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "328/328 - 10s - loss: 3.1200e-04 - val_loss: 3.0727e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "328/328 - 10s - loss: 2.9812e-04 - val_loss: 3.0336e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "328/328 - 10s - loss: 2.8916e-04 - val_loss: 3.0566e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "328/328 - 10s - loss: 2.8351e-04 - val_loss: 3.0530e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "328/328 - 10s - loss: 2.7542e-04 - val_loss: 3.1220e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "328/328 - 10s - loss: 2.7060e-04 - val_loss: 3.2222e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "328/328 - 10s - loss: 2.7855e-04 - val_loss: 3.5067e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "328/328 - 10s - loss: 2.7472e-04 - val_loss: 3.6470e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "328/328 - 10s - loss: 2.7883e-04 - val_loss: 3.8439e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 41/100\n",
      "328/328 - 10s - loss: 2.7891e-04 - val_loss: 4.1457e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "328/328 - 10s - loss: 2.7805e-04 - val_loss: 4.3978e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 43/100\n",
      "328/328 - 10s - loss: 2.7612e-04 - val_loss: 4.6455e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "328/328 - 10s - loss: 2.7099e-04 - val_loss: 4.7821e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 45/100\n",
      "328/328 - 10s - loss: 2.6271e-04 - val_loss: 4.8367e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "328/328 - 10s - loss: 2.5209e-04 - val_loss: 4.8028e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "328/328 - 10s - loss: 2.4043e-04 - val_loss: 4.8278e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 48/100\n",
      "328/328 - 10s - loss: 2.3187e-04 - val_loss: 4.8649e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "328/328 - 10s - loss: 2.2204e-04 - val_loss: 4.9367e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 50/100\n",
      "328/328 - 10s - loss: 2.1735e-04 - val_loss: 5.1029e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "328/328 - 10s - loss: 2.1426e-04 - val_loss: 5.2270e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "328/328 - 10s - loss: 2.1294e-04 - val_loss: 5.4844e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "328/328 - 10s - loss: 2.1351e-04 - val_loss: 5.6717e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "328/328 - 10s - loss: 2.1368e-04 - val_loss: 5.8948e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "328/328 - 10s - loss: 2.1265e-04 - val_loss: 6.0093e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "328/328 - 10s - loss: 2.1274e-04 - val_loss: 6.2221e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "328/328 - 10s - loss: 2.1196e-04 - val_loss: 6.2684e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "328/328 - 10s - loss: 2.0827e-04 - val_loss: 6.3723e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "328/328 - 10s - loss: 2.0311e-04 - val_loss: 6.2136e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "328/328 - 10s - loss: 1.9922e-04 - val_loss: 6.2603e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "328/328 - 10s - loss: 1.9257e-04 - val_loss: 6.0466e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "328/328 - 10s - loss: 1.8806e-04 - val_loss: 6.1238e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "328/328 - 10s - loss: 1.8369e-04 - val_loss: 6.0593e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "328/328 - 10s - loss: 1.8356e-04 - val_loss: 6.1869e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "328/328 - 10s - loss: 1.8416e-04 - val_loss: 6.3218e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "328/328 - 10s - loss: 1.8342e-04 - val_loss: 6.3652e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "328/328 - 10s - loss: 1.8385e-04 - val_loss: 6.4820e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "328/328 - 10s - loss: 1.8224e-04 - val_loss: 6.4369e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 69/100\n",
      "328/328 - 10s - loss: 1.8154e-04 - val_loss: 6.4513e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "328/328 - 10s - loss: 1.7890e-04 - val_loss: 6.3018e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "328/328 - 10s - loss: 1.7581e-04 - val_loss: 6.2211e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "328/328 - 10s - loss: 1.7179e-04 - val_loss: 6.0574e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "328/328 - 10s - loss: 1.6887e-04 - val_loss: 5.9483e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "328/328 - 10s - loss: 1.6569e-04 - val_loss: 5.8335e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "328/328 - 10s - loss: 1.6326e-04 - val_loss: 5.7564e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "328/328 - 10s - loss: 1.6192e-04 - val_loss: 5.7147e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "328/328 - 10s - loss: 1.6134e-04 - val_loss: 5.7036e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "328/328 - 10s - loss: 1.6104e-04 - val_loss: 5.7070e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "328/328 - 10s - loss: 1.6072e-04 - val_loss: 5.6916e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "328/328 - 10s - loss: 1.6008e-04 - val_loss: 5.6810e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "328/328 - 10s - loss: 1.5888e-04 - val_loss: 5.6260e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "328/328 - 10s - loss: 1.5727e-04 - val_loss: 5.5307e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "328/328 - 10s - loss: 1.5564e-04 - val_loss: 5.4018e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "328/328 - 10s - loss: 1.5397e-04 - val_loss: 5.3083e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "328/328 - 10s - loss: 1.5200e-04 - val_loss: 5.1877e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "328/328 - 10s - loss: 1.5021e-04 - val_loss: 5.0693e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "328/328 - 10s - loss: 1.4870e-04 - val_loss: 4.9702e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "328/328 - 10s - loss: 1.4769e-04 - val_loss: 4.9130e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "328/328 - 10s - loss: 1.4714e-04 - val_loss: 4.8469e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "328/328 - 10s - loss: 1.4693e-04 - val_loss: 4.8309e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "328/328 - 10s - loss: 1.4666e-04 - val_loss: 4.7939e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "328/328 - 10s - loss: 1.4572e-04 - val_loss: 4.7302e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "328/328 - 10s - loss: 1.4528e-04 - val_loss: 4.6895e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "328/328 - 10s - loss: 1.4349e-04 - val_loss: 4.5833e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "328/328 - 10s - loss: 1.4208e-04 - val_loss: 4.5122e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 96/100\n",
      "328/328 - 10s - loss: 1.3997e-04 - val_loss: 4.4052e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "328/328 - 10s - loss: 1.3849e-04 - val_loss: 4.3425e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "328/328 - 10s - loss: 1.3693e-04 - val_loss: 4.2704e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "328/328 - 10s - loss: 1.3596e-04 - val_loss: 4.2334e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "328/328 - 10s - loss: 1.3530e-04 - val_loss: 4.2043e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:51:58.078465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:51:58.215397: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:51:58.228037: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:51:58.558067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:51:58.573787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:52:09.223414: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:52:09.272268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 12:52:09.281334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 14s - loss: 3.4992e-04 - val_loss: 2.3213e-04 - 14s/epoch - 42ms/step\n",
      "Epoch 2/100\n",
      "328/328 - 10s - loss: 6.6686e-04 - val_loss: 8.1568e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "328/328 - 11s - loss: 6.2849e-04 - val_loss: 3.9263e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 4/100\n",
      "328/328 - 11s - loss: 4.8325e-04 - val_loss: 3.0366e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "328/328 - 11s - loss: 4.3158e-04 - val_loss: 2.6707e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "328/328 - 10s - loss: 4.4191e-04 - val_loss: 2.5614e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "328/328 - 10s - loss: 4.5875e-04 - val_loss: 2.6892e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 8/100\n",
      "328/328 - 10s - loss: 5.1404e-04 - val_loss: 2.7089e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "328/328 - 10s - loss: 5.4181e-04 - val_loss: 3.6190e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "328/328 - 10s - loss: 6.0275e-04 - val_loss: 3.7862e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 11/100\n",
      "328/328 - 10s - loss: 6.9057e-04 - val_loss: 6.9275e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "328/328 - 10s - loss: 7.6390e-04 - val_loss: 9.1463e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "328/328 - 10s - loss: 9.4314e-04 - val_loss: 0.0013 - 10s/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "328/328 - 10s - loss: 0.0011 - val_loss: 0.0014 - 10s/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "328/328 - 10s - loss: 0.0011 - val_loss: 0.0014 - 10s/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "328/328 - 10s - loss: 9.8335e-04 - val_loss: 0.0011 - 10s/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "328/328 - 10s - loss: 7.9306e-04 - val_loss: 7.4974e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "328/328 - 10s - loss: 6.3400e-04 - val_loss: 5.0760e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "328/328 - 10s - loss: 5.2125e-04 - val_loss: 3.6438e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "328/328 - 10s - loss: 4.4520e-04 - val_loss: 2.8719e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "328/328 - 10s - loss: 3.9568e-04 - val_loss: 2.5002e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "328/328 - 10s - loss: 3.6365e-04 - val_loss: 2.3655e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "328/328 - 10s - loss: 3.4286e-04 - val_loss: 2.3625e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "328/328 - 10s - loss: 3.3024e-04 - val_loss: 2.3975e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "328/328 - 10s - loss: 3.2641e-04 - val_loss: 2.4650e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "328/328 - 10s - loss: 3.2347e-04 - val_loss: 2.5139e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "328/328 - 10s - loss: 3.2504e-04 - val_loss: 2.7059e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "328/328 - 10s - loss: 3.2878e-04 - val_loss: 2.9341e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "328/328 - 10s - loss: 3.2996e-04 - val_loss: 3.0341e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "328/328 - 10s - loss: 3.3535e-04 - val_loss: 3.1209e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "328/328 - 10s - loss: 3.4368e-04 - val_loss: 3.2959e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "328/328 - 10s - loss: 3.3223e-04 - val_loss: 3.1409e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "328/328 - 10s - loss: 3.3448e-04 - val_loss: 3.1478e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "328/328 - 10s - loss: 3.2475e-04 - val_loss: 3.0489e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "328/328 - 10s - loss: 3.1493e-04 - val_loss: 2.9723e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "328/328 - 10s - loss: 2.9970e-04 - val_loss: 2.8538e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "328/328 - 10s - loss: 2.8846e-04 - val_loss: 2.8458e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "328/328 - 10s - loss: 2.7564e-04 - val_loss: 2.8138e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "328/328 - 10s - loss: 2.6608e-04 - val_loss: 2.9573e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "328/328 - 10s - loss: 2.6098e-04 - val_loss: 3.1810e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 41/100\n",
      "328/328 - 10s - loss: 2.5783e-04 - val_loss: 3.4957e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "328/328 - 10s - loss: 2.5633e-04 - val_loss: 3.8343e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 43/100\n",
      "328/328 - 10s - loss: 2.5616e-04 - val_loss: 4.1663e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "328/328 - 10s - loss: 2.5600e-04 - val_loss: 4.4604e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 45/100\n",
      "328/328 - 10s - loss: 2.5474e-04 - val_loss: 4.6798e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "328/328 - 10s - loss: 2.5068e-04 - val_loss: 4.8435e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "328/328 - 10s - loss: 2.4379e-04 - val_loss: 4.9227e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 48/100\n",
      "328/328 - 10s - loss: 2.3503e-04 - val_loss: 4.9652e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "328/328 - 10s - loss: 2.2705e-04 - val_loss: 4.9597e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 50/100\n",
      "328/328 - 10s - loss: 2.1900e-04 - val_loss: 4.9822e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "328/328 - 10s - loss: 2.1285e-04 - val_loss: 5.0352e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "328/328 - 10s - loss: 2.0781e-04 - val_loss: 5.0925e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "328/328 - 10s - loss: 2.0446e-04 - val_loss: 5.1977e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "328/328 - 10s - loss: 2.0349e-04 - val_loss: 5.3458e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "328/328 - 10s - loss: 2.0370e-04 - val_loss: 5.5192e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "328/328 - 10s - loss: 2.0460e-04 - val_loss: 5.6952e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "328/328 - 10s - loss: 2.0468e-04 - val_loss: 5.8076e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "328/328 - 10s - loss: 2.0472e-04 - val_loss: 5.8822e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "328/328 - 10s - loss: 2.0267e-04 - val_loss: 5.9058e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "328/328 - 10s - loss: 1.9864e-04 - val_loss: 5.8833e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "328/328 - 10s - loss: 1.9389e-04 - val_loss: 5.8224e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "328/328 - 10s - loss: 1.9214e-04 - val_loss: 5.7856e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "328/328 - 10s - loss: 1.8974e-04 - val_loss: 5.7692e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "328/328 - 10s - loss: 1.8724e-04 - val_loss: 5.6954e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "328/328 - 10s - loss: 1.8566e-04 - val_loss: 5.6542e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "328/328 - 10s - loss: 1.8316e-04 - val_loss: 5.6001e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "328/328 - 10s - loss: 1.8133e-04 - val_loss: 5.5875e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "328/328 - 10s - loss: 1.7915e-04 - val_loss: 5.5598e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 69/100\n",
      "328/328 - 10s - loss: 1.7370e-04 - val_loss: 5.4970e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "328/328 - 10s - loss: 1.7636e-04 - val_loss: 5.5603e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "328/328 - 10s - loss: 1.7555e-04 - val_loss: 5.5658e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "328/328 - 10s - loss: 1.7449e-04 - val_loss: 5.5431e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "328/328 - 10s - loss: 1.7279e-04 - val_loss: 5.4919e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "328/328 - 10s - loss: 1.7041e-04 - val_loss: 5.4149e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "328/328 - 10s - loss: 1.6785e-04 - val_loss: 5.3265e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "328/328 - 10s - loss: 1.6537e-04 - val_loss: 5.2471e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "328/328 - 10s - loss: 1.6325e-04 - val_loss: 5.1899e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "328/328 - 10s - loss: 1.6165e-04 - val_loss: 5.1548e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "328/328 - 10s - loss: 1.6034e-04 - val_loss: 5.1228e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "328/328 - 10s - loss: 1.5930e-04 - val_loss: 5.0939e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "328/328 - 10s - loss: 1.5842e-04 - val_loss: 5.0652e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "328/328 - 10s - loss: 1.5756e-04 - val_loss: 5.0387e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "328/328 - 10s - loss: 1.5656e-04 - val_loss: 5.0069e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "328/328 - 10s - loss: 1.5561e-04 - val_loss: 4.9656e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "328/328 - 10s - loss: 1.5507e-04 - val_loss: 4.9247e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "328/328 - 10s - loss: 1.5416e-04 - val_loss: 4.8583e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "328/328 - 10s - loss: 1.5325e-04 - val_loss: 4.7771e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "328/328 - 10s - loss: 1.5201e-04 - val_loss: 4.7130e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "328/328 - 10s - loss: 1.5067e-04 - val_loss: 4.6532e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "328/328 - 10s - loss: 1.4905e-04 - val_loss: 4.5984e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "328/328 - 10s - loss: 1.4729e-04 - val_loss: 4.5544e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "328/328 - 10s - loss: 1.4549e-04 - val_loss: 4.5267e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "328/328 - 10s - loss: 1.4386e-04 - val_loss: 4.5129e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "328/328 - 10s - loss: 1.4255e-04 - val_loss: 4.4940e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "328/328 - 10s - loss: 1.4160e-04 - val_loss: 4.4781e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 96/100\n",
      "328/328 - 10s - loss: 1.4073e-04 - val_loss: 4.4422e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "328/328 - 10s - loss: 1.4000e-04 - val_loss: 4.4384e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "328/328 - 10s - loss: 1.3950e-04 - val_loss: 4.4188e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "328/328 - 10s - loss: 1.3953e-04 - val_loss: 4.4322e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "328/328 - 10s - loss: 1.3842e-04 - val_loss: 4.3924e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:09:25.167192: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:09:25.314963: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:09:25.327717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:09:25.630678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:09:25.646401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:09:36.581812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:09:36.631104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:09:36.640831: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 14s - loss: 7.4216e-04 - val_loss: 8.1644e-04 - 14s/epoch - 43ms/step\n",
      "Epoch 2/100\n",
      "328/328 - 11s - loss: 6.8801e-04 - val_loss: 5.9264e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "328/328 - 11s - loss: 6.0587e-04 - val_loss: 4.4824e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 4/100\n",
      "328/328 - 11s - loss: 4.9124e-04 - val_loss: 3.5922e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "328/328 - 11s - loss: 3.8930e-04 - val_loss: 3.0693e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "328/328 - 11s - loss: 3.4082e-04 - val_loss: 2.7364e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 7/100\n",
      "328/328 - 11s - loss: 3.0015e-04 - val_loss: 2.5257e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "328/328 - 11s - loss: 2.6460e-04 - val_loss: 2.3774e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "328/328 - 11s - loss: 2.3991e-04 - val_loss: 2.2281e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "328/328 - 11s - loss: 2.1817e-04 - val_loss: 2.0934e-04 - 11s/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "328/328 - 11s - loss: 1.9866e-04 - val_loss: 2.0169e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "328/328 - 11s - loss: 1.8361e-04 - val_loss: 1.9782e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "328/328 - 11s - loss: 1.7228e-04 - val_loss: 1.9568e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "328/328 - 11s - loss: 1.6459e-04 - val_loss: 1.9651e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "328/328 - 11s - loss: 1.6696e-04 - val_loss: 1.9910e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "328/328 - 11s - loss: 1.5228e-04 - val_loss: 1.9564e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "328/328 - 11s - loss: 1.4182e-04 - val_loss: 1.9032e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "328/328 - 11s - loss: 1.3643e-04 - val_loss: 1.8972e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "328/328 - 11s - loss: 1.3417e-04 - val_loss: 1.9232e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "328/328 - 11s - loss: 1.2727e-04 - val_loss: 1.8916e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "328/328 - 11s - loss: 1.2377e-04 - val_loss: 1.8791e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "328/328 - 11s - loss: 1.1431e-04 - val_loss: 1.7570e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "328/328 - 11s - loss: 1.1006e-04 - val_loss: 1.7526e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "328/328 - 11s - loss: 1.0678e-04 - val_loss: 1.7204e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "328/328 - 11s - loss: 1.0746e-04 - val_loss: 1.7828e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "328/328 - 11s - loss: 1.0591e-04 - val_loss: 1.7895e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "328/328 - 11s - loss: 9.8973e-05 - val_loss: 1.5403e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "328/328 - 11s - loss: 9.1833e-05 - val_loss: 1.4176e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "328/328 - 11s - loss: 9.0105e-05 - val_loss: 1.3965e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "328/328 - 11s - loss: 9.1740e-05 - val_loss: 1.4547e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "328/328 - 11s - loss: 8.9530e-05 - val_loss: 1.3279e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "328/328 - 11s - loss: 8.7908e-05 - val_loss: 1.3809e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "328/328 - 11s - loss: 8.8946e-05 - val_loss: 1.4318e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "328/328 - 11s - loss: 8.7939e-05 - val_loss: 1.3718e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "328/328 - 11s - loss: 8.2860e-05 - val_loss: 1.2317e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "328/328 - 11s - loss: 7.9173e-05 - val_loss: 1.1659e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "328/328 - 11s - loss: 7.9780e-05 - val_loss: 1.2262e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "328/328 - 11s - loss: 8.3351e-05 - val_loss: 1.2981e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "328/328 - 11s - loss: 8.3787e-05 - val_loss: 1.3613e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "328/328 - 11s - loss: 8.1956e-05 - val_loss: 1.3450e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 41/100\n",
      "328/328 - 11s - loss: 7.7405e-05 - val_loss: 1.1777e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "328/328 - 11s - loss: 7.3858e-05 - val_loss: 1.1448e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 43/100\n",
      "328/328 - 11s - loss: 7.5003e-05 - val_loss: 1.1800e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "328/328 - 11s - loss: 7.5842e-05 - val_loss: 1.2082e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 45/100\n",
      "328/328 - 11s - loss: 7.7049e-05 - val_loss: 1.2403e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "328/328 - 11s - loss: 7.6732e-05 - val_loss: 1.2818e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "328/328 - 11s - loss: 7.4277e-05 - val_loss: 1.2168e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 48/100\n",
      "328/328 - 11s - loss: 7.1976e-05 - val_loss: 1.1805e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "328/328 - 11s - loss: 7.0909e-05 - val_loss: 1.1312e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 50/100\n",
      "328/328 - 11s - loss: 6.9953e-05 - val_loss: 1.1550e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "328/328 - 11s - loss: 7.1795e-05 - val_loss: 1.2159e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "328/328 - 11s - loss: 7.1522e-05 - val_loss: 1.2214e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "328/328 - 11s - loss: 7.1200e-05 - val_loss: 1.2185e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "328/328 - 11s - loss: 7.0057e-05 - val_loss: 1.1960e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "328/328 - 11s - loss: 6.8226e-05 - val_loss: 1.1820e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "328/328 - 11s - loss: 6.8258e-05 - val_loss: 1.1849e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "328/328 - 11s - loss: 6.7310e-05 - val_loss: 1.1666e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "328/328 - 11s - loss: 6.8516e-05 - val_loss: 1.2098e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "328/328 - 11s - loss: 6.6979e-05 - val_loss: 1.1917e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "328/328 - 11s - loss: 6.5524e-05 - val_loss: 1.1637e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "328/328 - 10s - loss: 6.4745e-05 - val_loss: 1.1478e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "328/328 - 11s - loss: 6.4592e-05 - val_loss: 1.1359e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "328/328 - 11s - loss: 6.4276e-05 - val_loss: 1.1528e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "328/328 - 11s - loss: 6.5104e-05 - val_loss: 1.1953e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "328/328 - 11s - loss: 6.3851e-05 - val_loss: 1.1324e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "328/328 - 11s - loss: 6.2995e-05 - val_loss: 1.1515e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "328/328 - 11s - loss: 6.1556e-05 - val_loss: 1.1192e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "328/328 - 11s - loss: 6.3157e-05 - val_loss: 1.1706e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 69/100\n",
      "328/328 - 11s - loss: 6.3043e-05 - val_loss: 1.1812e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "328/328 - 10s - loss: 6.1123e-05 - val_loss: 1.1353e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "328/328 - 10s - loss: 6.0068e-05 - val_loss: 1.1120e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "328/328 - 10s - loss: 6.0103e-05 - val_loss: 1.1207e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "328/328 - 10s - loss: 6.0183e-05 - val_loss: 1.1198e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "328/328 - 10s - loss: 5.9759e-05 - val_loss: 1.1342e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "328/328 - 11s - loss: 6.0831e-05 - val_loss: 1.1814e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "328/328 - 11s - loss: 5.9147e-05 - val_loss: 1.1510e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "328/328 - 11s - loss: 5.7969e-05 - val_loss: 1.1101e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "328/328 - 11s - loss: 5.7894e-05 - val_loss: 1.1214e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "328/328 - 11s - loss: 5.8290e-05 - val_loss: 1.1482e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "328/328 - 11s - loss: 5.8042e-05 - val_loss: 1.1688e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "328/328 - 10s - loss: 5.8432e-05 - val_loss: 1.1815e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "328/328 - 11s - loss: 5.6371e-05 - val_loss: 1.1364e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "328/328 - 11s - loss: 5.5569e-05 - val_loss: 1.1062e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "328/328 - 11s - loss: 5.5192e-05 - val_loss: 1.1100e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "328/328 - 11s - loss: 5.5940e-05 - val_loss: 1.1561e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "328/328 - 11s - loss: 5.6665e-05 - val_loss: 1.1996e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "328/328 - 11s - loss: 5.5888e-05 - val_loss: 1.1981e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "328/328 - 11s - loss: 5.5961e-05 - val_loss: 1.2068e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "328/328 - 11s - loss: 5.4519e-05 - val_loss: 1.1697e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "328/328 - 11s - loss: 5.4293e-05 - val_loss: 1.1836e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "328/328 - 11s - loss: 5.4611e-05 - val_loss: 1.2081e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "328/328 - 11s - loss: 5.4493e-05 - val_loss: 1.2297e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "328/328 - 11s - loss: 5.4009e-05 - val_loss: 1.2287e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "328/328 - 11s - loss: 5.3900e-05 - val_loss: 1.2458e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "328/328 - 11s - loss: 5.3212e-05 - val_loss: 1.2371e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 96/100\n",
      "328/328 - 11s - loss: 5.3059e-05 - val_loss: 1.2515e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "328/328 - 11s - loss: 5.3119e-05 - val_loss: 1.2581e-04 - 11s/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "328/328 - 10s - loss: 5.2515e-05 - val_loss: 1.2560e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "328/328 - 10s - loss: 5.1521e-05 - val_loss: 1.2378e-04 - 10s/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "328/328 - 11s - loss: 5.1048e-05 - val_loss: 1.2393e-04 - 11s/epoch - 32ms/step\n"
     ]
    }
   ],
   "source": [
    "bilstms2 = []\n",
    "models2 = []\n",
    "for batch, epoch, neuron in hyperparam2:\n",
    "    model, bilstm = LSTMUnit.train_bilstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    bilstms2.append(bilstm)\n",
    "    models2.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ecec446-1f6b-4f7c-8a44-e9c3caf29c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 3s 15ms/step\n",
      "(64, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "111.03218875381283\n",
      "MAE\n",
      "104.37100306758836\n",
      "MAPE\n",
      "7.974480571651521\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(64, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "63.7416140564611\n",
      "MAE\n",
      "59.188858489902564\n",
      "MAPE\n",
      "4.504259513559774\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(64, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "53.02800189638808\n",
      "MAE\n",
      "48.07057183738232\n",
      "MAPE\n",
      "3.655489474236913\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(64, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "126.00372102779414\n",
      "MAE\n",
      "120.14785043677895\n",
      "MAPE\n",
      "9.149896226212592\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(64, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "48.825974122497975\n",
      "MAE\n",
      "44.59903161914263\n",
      "MAPE\n",
      "3.4270983974799925\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(64, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "120.78703137215291\n",
      "MAE\n",
      "115.2529928028934\n",
      "MAPE\n",
      "8.769986019254619\n",
      "163/163 [==============================] - 3s 15ms/step\n",
      "(64, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "97.39831923466863\n",
      "MAE\n",
      "93.48264886433557\n",
      "MAPE\n",
      "7.0697195126856\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(64, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "99.55300916348041\n",
      "MAE\n",
      "95.7048620054334\n",
      "MAPE\n",
      "7.230091251066321\n",
      "163/163 [==============================] - 3s 15ms/step\n",
      "(64, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "52.87929375913382\n",
      "MAE\n",
      "49.13494931021494\n",
      "MAPE\n",
      "3.74717249883856\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb2 = Workbook()\n",
    "ws2 = wb2.active\n",
    "for m in models2:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = LSTMUnit.predict(test_x2, m)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparam2[i])\n",
    "    print(\"Epoch: \"+ str(bilstms2[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].layer.units))\n",
    "    i = i+1\n",
    "    ws2['A'+str(i)] = 'BiLSTM'\n",
    "    ws2['B'+str(i)] = hyperparam2[i-1][0]\n",
    "    ws2['C'+str(i)] = hyperparam2[i-1][1]\n",
    "    ws2['D'+str(i)] = hyperparam2[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
    "    ws2['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
    "    print('MAE')\n",
    "    print(Evaluation.mae(inv_y,inv_yhat))\n",
    "    ws2['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
    "    print('MAPE')\n",
    "    print(Evaluation.mape(inv_y,inv_yhat))\n",
    "    ws2['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
    "    LSTMUnit.save_model(m, 1, 'ETH',hyperparam2[i-1])\n",
    "    with open('BiLSTM_ETH'+str(hyperparam2[i-1])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(bilstms2[i-1].history, f)\n",
    "wb2.save('BiLSTM_ETH_result2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "784abd2d-2770-44d6-b780-c4229562b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:27:34.511968: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:27:34.666077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:27:34.679188: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:27:35.227078: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:27:35.242989: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:27:41.883019: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:27:41.941193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:27:41.951290: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 10s - loss: 9.7757e-04 - val_loss: 5.0291e-04 - 10s/epoch - 61ms/step\n",
      "Epoch 2/25\n",
      "164/164 - 6s - loss: 0.0020 - val_loss: 0.0032 - 6s/epoch - 34ms/step\n",
      "Epoch 3/25\n",
      "164/164 - 5s - loss: 0.0015 - val_loss: 0.0030 - 5s/epoch - 33ms/step\n",
      "Epoch 4/25\n",
      "164/164 - 6s - loss: 9.5435e-04 - val_loss: 0.0015 - 6s/epoch - 34ms/step\n",
      "Epoch 5/25\n",
      "164/164 - 5s - loss: 6.9373e-04 - val_loss: 8.1609e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 6/25\n",
      "164/164 - 5s - loss: 5.8797e-04 - val_loss: 5.6408e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 7/25\n",
      "164/164 - 5s - loss: 5.4195e-04 - val_loss: 4.6707e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 8/25\n",
      "164/164 - 5s - loss: 5.1282e-04 - val_loss: 4.2017e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 9/25\n",
      "164/164 - 5s - loss: 4.8672e-04 - val_loss: 3.8805e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 10/25\n",
      "164/164 - 5s - loss: 4.5923e-04 - val_loss: 3.5827e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 11/25\n",
      "164/164 - 5s - loss: 4.2924e-04 - val_loss: 3.2688e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 12/25\n",
      "164/164 - 5s - loss: 3.9681e-04 - val_loss: 2.9339e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 13/25\n",
      "164/164 - 5s - loss: 3.6242e-04 - val_loss: 2.5876e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 14/25\n",
      "164/164 - 5s - loss: 3.2700e-04 - val_loss: 2.2457e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 15/25\n",
      "164/164 - 5s - loss: 2.9207e-04 - val_loss: 1.9233e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 16/25\n",
      "164/164 - 5s - loss: 2.5999e-04 - val_loss: 1.6394e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 17/25\n",
      "164/164 - 6s - loss: 2.3376e-04 - val_loss: 1.4120e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 18/25\n",
      "164/164 - 5s - loss: 2.1615e-04 - val_loss: 1.2663e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 19/25\n",
      "164/164 - 5s - loss: 2.0844e-04 - val_loss: 1.2166e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 20/25\n",
      "164/164 - 5s - loss: 2.0974e-04 - val_loss: 1.2608e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 21/25\n",
      "164/164 - 5s - loss: 2.1741e-04 - val_loss: 1.3828e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 22/25\n",
      "164/164 - 5s - loss: 2.2801e-04 - val_loss: 1.5512e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 23/25\n",
      "164/164 - 5s - loss: 2.4156e-04 - val_loss: 1.7314e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 24/25\n",
      "164/164 - 5s - loss: 2.5076e-04 - val_loss: 1.8837e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 25/25\n",
      "164/164 - 5s - loss: 2.4490e-04 - val_loss: 1.9138e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:29:55.350385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:29:55.498776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:29:55.512655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:29:56.143670: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:29:56.159365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:30:02.816215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:30:02.864879: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:30:02.873920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 10s - loss: 5.3937e-04 - val_loss: 3.5731e-04 - 10s/epoch - 59ms/step\n",
      "Epoch 2/25\n",
      "164/164 - 6s - loss: 0.0014 - val_loss: 0.0035 - 6s/epoch - 34ms/step\n",
      "Epoch 3/25\n",
      "164/164 - 5s - loss: 0.0021 - val_loss: 0.0032 - 5s/epoch - 33ms/step\n",
      "Epoch 4/25\n",
      "164/164 - 5s - loss: 0.0012 - val_loss: 0.0020 - 5s/epoch - 33ms/step\n",
      "Epoch 5/25\n",
      "164/164 - 6s - loss: 6.9810e-04 - val_loss: 8.0292e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 6/25\n",
      "164/164 - 5s - loss: 4.9425e-04 - val_loss: 4.0768e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 7/25\n",
      "164/164 - 5s - loss: 4.2110e-04 - val_loss: 2.8484e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 8/25\n",
      "164/164 - 5s - loss: 3.8724e-04 - val_loss: 2.3930e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 9/25\n",
      "164/164 - 5s - loss: 3.6170e-04 - val_loss: 2.1441e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 10/25\n",
      "164/164 - 5s - loss: 3.3478e-04 - val_loss: 1.9291e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 11/25\n",
      "164/164 - 5s - loss: 3.0469e-04 - val_loss: 1.7061e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 12/25\n",
      "164/164 - 5s - loss: 2.7338e-04 - val_loss: 1.4802e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 13/25\n",
      "164/164 - 5s - loss: 2.4470e-04 - val_loss: 1.2739e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 14/25\n",
      "164/164 - 5s - loss: 2.2298e-04 - val_loss: 1.1192e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 15/25\n",
      "164/164 - 5s - loss: 2.1139e-04 - val_loss: 1.0471e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 16/25\n",
      "164/164 - 5s - loss: 2.1052e-04 - val_loss: 1.0715e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 17/25\n",
      "164/164 - 5s - loss: 2.1828e-04 - val_loss: 1.1858e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 18/25\n",
      "164/164 - 5s - loss: 2.3054e-04 - val_loss: 1.3647e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 19/25\n",
      "164/164 - 5s - loss: 2.4256e-04 - val_loss: 1.5759e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 20/25\n",
      "164/164 - 5s - loss: 2.5011e-04 - val_loss: 1.7606e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 21/25\n",
      "164/164 - 5s - loss: 2.4931e-04 - val_loss: 1.8306e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 22/25\n",
      "164/164 - 5s - loss: 2.4055e-04 - val_loss: 1.8155e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 23/25\n",
      "164/164 - 5s - loss: 2.3473e-04 - val_loss: 1.7104e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 24/25\n",
      "164/164 - 5s - loss: 2.2359e-04 - val_loss: 1.6262e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 25/25\n",
      "164/164 - 5s - loss: 2.1609e-04 - val_loss: 1.5522e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:32:14.656162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:32:14.810271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:32:14.822888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:32:15.229580: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:32:15.247329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:32:22.137816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:32:22.192888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:32:22.202150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 10s - loss: 9.6621e-04 - val_loss: 8.4183e-04 - 10s/epoch - 59ms/step\n",
      "Epoch 2/25\n",
      "164/164 - 6s - loss: 0.0014 - val_loss: 0.0028 - 6s/epoch - 35ms/step\n",
      "Epoch 3/25\n",
      "164/164 - 6s - loss: 0.0023 - val_loss: 0.0043 - 6s/epoch - 35ms/step\n",
      "Epoch 4/25\n",
      "164/164 - 6s - loss: 0.0018 - val_loss: 0.0034 - 6s/epoch - 35ms/step\n",
      "Epoch 5/25\n",
      "164/164 - 6s - loss: 0.0011 - val_loss: 0.0020 - 6s/epoch - 35ms/step\n",
      "Epoch 6/25\n",
      "164/164 - 6s - loss: 7.6534e-04 - val_loss: 0.0011 - 6s/epoch - 35ms/step\n",
      "Epoch 7/25\n",
      "164/164 - 6s - loss: 6.0774e-04 - val_loss: 7.1909e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 8/25\n",
      "164/164 - 6s - loss: 5.4133e-04 - val_loss: 5.6692e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 9/25\n",
      "164/164 - 6s - loss: 5.0574e-04 - val_loss: 4.9231e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 10/25\n",
      "164/164 - 6s - loss: 4.7752e-04 - val_loss: 4.4256e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 11/25\n",
      "164/164 - 6s - loss: 4.4825e-04 - val_loss: 3.9886e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 12/25\n",
      "164/164 - 6s - loss: 4.1562e-04 - val_loss: 3.5541e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 13/25\n",
      "164/164 - 6s - loss: 3.8007e-04 - val_loss: 3.1172e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 14/25\n",
      "164/164 - 6s - loss: 3.4330e-04 - val_loss: 2.6921e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 15/25\n",
      "164/164 - 6s - loss: 3.0785e-04 - val_loss: 2.2991e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 16/25\n",
      "164/164 - 6s - loss: 2.7674e-04 - val_loss: 1.9606e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 17/25\n",
      "164/164 - 6s - loss: 2.5279e-04 - val_loss: 1.7016e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 18/25\n",
      "164/164 - 6s - loss: 2.3780e-04 - val_loss: 1.5421e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 19/25\n",
      "164/164 - 6s - loss: 2.3175e-04 - val_loss: 1.4872e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 20/25\n",
      "164/164 - 6s - loss: 2.3311e-04 - val_loss: 1.5242e-04 - 6s/epoch - 37ms/step\n",
      "Epoch 21/25\n",
      "164/164 - 6s - loss: 2.3901e-04 - val_loss: 1.6296e-04 - 6s/epoch - 37ms/step\n",
      "Epoch 22/25\n",
      "164/164 - 6s - loss: 2.4857e-04 - val_loss: 1.7850e-04 - 6s/epoch - 38ms/step\n",
      "Epoch 23/25\n",
      "164/164 - 6s - loss: 2.6701e-04 - val_loss: 1.9919e-04 - 6s/epoch - 39ms/step\n",
      "Epoch 24/25\n",
      "164/164 - 6s - loss: 2.7962e-04 - val_loss: 2.3108e-04 - 6s/epoch - 39ms/step\n",
      "Epoch 25/25\n",
      "164/164 - 6s - loss: 2.9433e-04 - val_loss: 2.5599e-04 - 6s/epoch - 40ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:34:45.406893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:34:45.563024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:34:45.582824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:34:46.019733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:34:46.037545: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:34:52.837904: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:34:52.888160: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:34:52.897236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 10s - loss: 9.9003e-04 - val_loss: 9.3770e-04 - 10s/epoch - 60ms/step\n",
      "Epoch 2/50\n",
      "164/164 - 6s - loss: 0.0023 - val_loss: 0.0042 - 6s/epoch - 34ms/step\n",
      "Epoch 3/50\n",
      "164/164 - 6s - loss: 0.0013 - val_loss: 0.0028 - 6s/epoch - 34ms/step\n",
      "Epoch 4/50\n",
      "164/164 - 6s - loss: 8.7713e-04 - val_loss: 0.0013 - 6s/epoch - 34ms/step\n",
      "Epoch 5/50\n",
      "164/164 - 6s - loss: 6.8465e-04 - val_loss: 8.2815e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 6/50\n",
      "164/164 - 6s - loss: 6.1928e-04 - val_loss: 6.6530e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 7/50\n",
      "164/164 - 6s - loss: 5.8686e-04 - val_loss: 5.9788e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 8/50\n",
      "164/164 - 6s - loss: 5.6016e-04 - val_loss: 5.5719e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 9/50\n",
      "164/164 - 6s - loss: 5.3183e-04 - val_loss: 5.2051e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 10/50\n",
      "164/164 - 6s - loss: 5.0178e-04 - val_loss: 4.8133e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 11/50\n",
      "164/164 - 6s - loss: 4.6921e-04 - val_loss: 4.4639e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 12/50\n",
      "164/164 - 6s - loss: 4.3507e-04 - val_loss: 3.9343e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 13/50\n",
      "164/164 - 6s - loss: 3.9709e-04 - val_loss: 3.4842e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 14/50\n",
      "164/164 - 6s - loss: 3.6039e-04 - val_loss: 2.9796e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 15/50\n",
      "164/164 - 6s - loss: 3.2254e-04 - val_loss: 2.5166e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 16/50\n",
      "164/164 - 6s - loss: 2.8735e-04 - val_loss: 2.1344e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 17/50\n",
      "164/164 - 6s - loss: 2.5489e-04 - val_loss: 1.7869e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 18/50\n",
      "164/164 - 6s - loss: 2.2715e-04 - val_loss: 1.5177e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 19/50\n",
      "164/164 - 6s - loss: 2.0664e-04 - val_loss: 1.3129e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 20/50\n",
      "164/164 - 6s - loss: 1.9415e-04 - val_loss: 1.2006e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 21/50\n",
      "164/164 - 6s - loss: 1.9055e-04 - val_loss: 1.1757e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 22/50\n",
      "164/164 - 6s - loss: 1.9354e-04 - val_loss: 1.2314e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 23/50\n",
      "164/164 - 6s - loss: 2.0186e-04 - val_loss: 1.3618e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 24/50\n",
      "164/164 - 6s - loss: 2.1579e-04 - val_loss: 1.5553e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 25/50\n",
      "164/164 - 6s - loss: 2.2449e-04 - val_loss: 1.7149e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 26/50\n",
      "164/164 - 6s - loss: 2.3216e-04 - val_loss: 1.9352e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 27/50\n",
      "164/164 - 6s - loss: 2.2964e-04 - val_loss: 2.0152e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 28/50\n",
      "164/164 - 6s - loss: 2.1823e-04 - val_loss: 1.8392e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 29/50\n",
      "164/164 - 6s - loss: 1.9673e-04 - val_loss: 1.6528e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 30/50\n",
      "164/164 - 6s - loss: 1.7933e-04 - val_loss: 1.4340e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 31/50\n",
      "164/164 - 6s - loss: 1.6691e-04 - val_loss: 1.2808e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 32/50\n",
      "164/164 - 6s - loss: 1.5976e-04 - val_loss: 1.2276e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 33/50\n",
      "164/164 - 6s - loss: 1.6502e-04 - val_loss: 1.2199e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 34/50\n",
      "164/164 - 6s - loss: 1.6581e-04 - val_loss: 1.2899e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 35/50\n",
      "164/164 - 6s - loss: 1.7633e-04 - val_loss: 1.4060e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 36/50\n",
      "164/164 - 6s - loss: 1.8121e-04 - val_loss: 1.5027e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 37/50\n",
      "164/164 - 6s - loss: 1.8352e-04 - val_loss: 1.5208e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 38/50\n",
      "164/164 - 6s - loss: 1.8205e-04 - val_loss: 1.5808e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 39/50\n",
      "164/164 - 6s - loss: 1.7637e-04 - val_loss: 1.5196e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 40/50\n",
      "164/164 - 6s - loss: 1.5980e-04 - val_loss: 1.3454e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 41/50\n",
      "164/164 - 6s - loss: 1.4689e-04 - val_loss: 1.1860e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 42/50\n",
      "164/164 - 6s - loss: 1.3629e-04 - val_loss: 1.0615e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 43/50\n",
      "164/164 - 6s - loss: 1.3192e-04 - val_loss: 1.0176e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 44/50\n",
      "164/164 - 6s - loss: 1.3669e-04 - val_loss: 1.0986e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 45/50\n",
      "164/164 - 6s - loss: 1.4742e-04 - val_loss: 1.1698e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 46/50\n",
      "164/164 - 6s - loss: 1.5558e-04 - val_loss: 1.3011e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 47/50\n",
      "164/164 - 6s - loss: 1.6124e-04 - val_loss: 1.3860e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 48/50\n",
      "164/164 - 6s - loss: 1.5178e-04 - val_loss: 1.3166e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 49/50\n",
      "164/164 - 6s - loss: 1.4587e-04 - val_loss: 1.2433e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 50/50\n",
      "164/164 - 6s - loss: 1.2939e-04 - val_loss: 1.0545e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:39:38.752205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:39:38.896134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:39:38.912151: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:39:39.351375: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:39:39.368003: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:39:46.180865: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:39:46.234490: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:39:46.244603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 10s - loss: 4.0372e-04 - val_loss: 2.0729e-04 - 10s/epoch - 60ms/step\n",
      "Epoch 2/50\n",
      "164/164 - 6s - loss: 4.7875e-04 - val_loss: 6.1931e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 3/50\n",
      "164/164 - 6s - loss: 0.0014 - val_loss: 0.0040 - 6s/epoch - 35ms/step\n",
      "Epoch 4/50\n",
      "164/164 - 6s - loss: 0.0020 - val_loss: 0.0032 - 6s/epoch - 36ms/step\n",
      "Epoch 5/50\n",
      "164/164 - 6s - loss: 0.0011 - val_loss: 0.0020 - 6s/epoch - 36ms/step\n",
      "Epoch 6/50\n",
      "164/164 - 6s - loss: 6.9211e-04 - val_loss: 8.3122e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 7/50\n",
      "164/164 - 6s - loss: 4.5562e-04 - val_loss: 3.9349e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 8/50\n",
      "164/164 - 6s - loss: 3.6203e-04 - val_loss: 2.4841e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 9/50\n",
      "164/164 - 6s - loss: 3.1671e-04 - val_loss: 1.9176e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 10/50\n",
      "164/164 - 6s - loss: 2.8428e-04 - val_loss: 1.6148e-04 - 6s/epoch - 37ms/step\n",
      "Epoch 11/50\n",
      "164/164 - 6s - loss: 2.5415e-04 - val_loss: 1.3855e-04 - 6s/epoch - 37ms/step\n",
      "Epoch 12/50\n",
      "164/164 - 6s - loss: 2.2590e-04 - val_loss: 1.1804e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 13/50\n",
      "164/164 - 6s - loss: 2.0364e-04 - val_loss: 1.0134e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 14/50\n",
      "164/164 - 6s - loss: 1.9181e-04 - val_loss: 9.2586e-05 - 6s/epoch - 36ms/step\n",
      "Epoch 15/50\n",
      "164/164 - 6s - loss: 1.9215e-04 - val_loss: 9.4433e-05 - 6s/epoch - 37ms/step\n",
      "Epoch 16/50\n",
      "164/164 - 6s - loss: 2.0311e-04 - val_loss: 1.0699e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 17/50\n",
      "164/164 - 6s - loss: 2.2055e-04 - val_loss: 1.2874e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 18/50\n",
      "164/164 - 6s - loss: 2.3827e-04 - val_loss: 1.5559e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 19/50\n",
      "164/164 - 6s - loss: 2.4964e-04 - val_loss: 1.7968e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 20/50\n",
      "164/164 - 6s - loss: 2.5075e-04 - val_loss: 1.9275e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 21/50\n",
      "164/164 - 6s - loss: 2.4277e-04 - val_loss: 1.9249e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 22/50\n",
      "164/164 - 6s - loss: 2.3026e-04 - val_loss: 1.8349e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 23/50\n",
      "164/164 - 6s - loss: 2.1752e-04 - val_loss: 1.7226e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 24/50\n",
      "164/164 - 6s - loss: 2.0732e-04 - val_loss: 1.6293e-04 - 6s/epoch - 37ms/step\n",
      "Epoch 25/50\n",
      "164/164 - 6s - loss: 2.0043e-04 - val_loss: 1.5735e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 26/50\n",
      "164/164 - 6s - loss: 1.9739e-04 - val_loss: 1.5489e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 27/50\n",
      "164/164 - 6s - loss: 2.0060e-04 - val_loss: 1.5421e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 28/50\n",
      "164/164 - 6s - loss: 1.9736e-04 - val_loss: 1.5611e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 29/50\n",
      "164/164 - 6s - loss: 2.0351e-04 - val_loss: 1.5867e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 30/50\n",
      "164/164 - 6s - loss: 2.0184e-04 - val_loss: 1.6157e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 31/50\n",
      "164/164 - 6s - loss: 2.0286e-04 - val_loss: 1.6051e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 32/50\n",
      "164/164 - 6s - loss: 2.0279e-04 - val_loss: 1.6224e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 33/50\n",
      "164/164 - 6s - loss: 1.9560e-04 - val_loss: 1.5237e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 34/50\n",
      "164/164 - 6s - loss: 1.8061e-04 - val_loss: 1.3705e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 35/50\n",
      "164/164 - 6s - loss: 1.6085e-04 - val_loss: 1.2280e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 36/50\n",
      "164/164 - 6s - loss: 1.5620e-04 - val_loss: 1.1152e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 37/50\n",
      "164/164 - 6s - loss: 1.5084e-04 - val_loss: 1.0712e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 38/50\n",
      "164/164 - 6s - loss: 1.5257e-04 - val_loss: 1.0806e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 39/50\n",
      "164/164 - 6s - loss: 1.5368e-04 - val_loss: 1.1037e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 40/50\n",
      "164/164 - 6s - loss: 1.5982e-04 - val_loss: 1.1754e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 41/50\n",
      "164/164 - 6s - loss: 1.6403e-04 - val_loss: 1.2212e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 42/50\n",
      "164/164 - 6s - loss: 1.6229e-04 - val_loss: 1.2456e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 43/50\n",
      "164/164 - 6s - loss: 1.5863e-04 - val_loss: 1.2164e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 44/50\n",
      "164/164 - 6s - loss: 1.4825e-04 - val_loss: 1.1481e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 45/50\n",
      "164/164 - 6s - loss: 1.4015e-04 - val_loss: 1.0943e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 46/50\n",
      "164/164 - 6s - loss: 1.3827e-04 - val_loss: 1.0150e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 47/50\n",
      "164/164 - 6s - loss: 1.2889e-04 - val_loss: 9.7077e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 48/50\n",
      "164/164 - 6s - loss: 1.2715e-04 - val_loss: 9.7391e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 49/50\n",
      "164/164 - 6s - loss: 1.3561e-04 - val_loss: 1.0317e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 50/50\n",
      "164/164 - 6s - loss: 1.4227e-04 - val_loss: 1.1254e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:44:29.799106: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:44:29.935044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:44:29.952707: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:44:30.429934: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:44:30.445727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:44:38.016260: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:44:38.077700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:44:38.089258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 11s - loss: 8.3740e-04 - val_loss: 6.6431e-04 - 11s/epoch - 69ms/step\n",
      "Epoch 2/50\n",
      "164/164 - 7s - loss: 0.0010 - val_loss: 0.0015 - 7s/epoch - 41ms/step\n",
      "Epoch 3/50\n",
      "164/164 - 7s - loss: 0.0023 - val_loss: 0.0050 - 7s/epoch - 42ms/step\n",
      "Epoch 4/50\n",
      "164/164 - 7s - loss: 0.0020 - val_loss: 0.0040 - 7s/epoch - 42ms/step\n",
      "Epoch 5/50\n",
      "164/164 - 7s - loss: 0.0013 - val_loss: 0.0024 - 7s/epoch - 42ms/step\n",
      "Epoch 6/50\n",
      "164/164 - 7s - loss: 8.5333e-04 - val_loss: 0.0013 - 7s/epoch - 43ms/step\n",
      "Epoch 7/50\n",
      "164/164 - 7s - loss: 6.4002e-04 - val_loss: 7.7560e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 8/50\n",
      "164/164 - 7s - loss: 5.4588e-04 - val_loss: 5.6496e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 9/50\n",
      "164/164 - 7s - loss: 4.9921e-04 - val_loss: 4.6805e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 10/50\n",
      "164/164 - 7s - loss: 4.6682e-04 - val_loss: 4.1086e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 11/50\n",
      "164/164 - 7s - loss: 4.3647e-04 - val_loss: 3.6621e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 12/50\n",
      "164/164 - 7s - loss: 4.0411e-04 - val_loss: 3.2464e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 13/50\n",
      "164/164 - 7s - loss: 3.6927e-04 - val_loss: 2.8389e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 14/50\n",
      "164/164 - 7s - loss: 3.3330e-04 - val_loss: 2.4457e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 15/50\n",
      "164/164 - 7s - loss: 2.9868e-04 - val_loss: 2.0838e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 16/50\n",
      "164/164 - 7s - loss: 2.6853e-04 - val_loss: 1.7753e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 17/50\n",
      "164/164 - 7s - loss: 2.4585e-04 - val_loss: 1.5465e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 18/50\n",
      "164/164 - 7s - loss: 2.3244e-04 - val_loss: 1.4175e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 19/50\n",
      "164/164 - 7s - loss: 2.2819e-04 - val_loss: 1.3920e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 20/50\n",
      "164/164 - 7s - loss: 2.3125e-04 - val_loss: 1.4570e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 21/50\n",
      "164/164 - 7s - loss: 2.3870e-04 - val_loss: 1.5883e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 22/50\n",
      "164/164 - 7s - loss: 2.4748e-04 - val_loss: 1.7537e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 23/50\n",
      "164/164 - 7s - loss: 2.5539e-04 - val_loss: 1.9270e-04 - 7s/epoch - 44ms/step\n",
      "Epoch 24/50\n",
      "164/164 - 7s - loss: 2.6009e-04 - val_loss: 2.0392e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 25/50\n",
      "164/164 - 7s - loss: 2.6309e-04 - val_loss: 2.1885e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 26/50\n",
      "164/164 - 7s - loss: 2.6449e-04 - val_loss: 2.1554e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 27/50\n",
      "164/164 - 7s - loss: 2.5990e-04 - val_loss: 2.1130e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 28/50\n",
      "164/164 - 7s - loss: 2.5546e-04 - val_loss: 2.0216e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 29/50\n",
      "164/164 - 7s - loss: 2.3136e-04 - val_loss: 1.8534e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 30/50\n",
      "164/164 - 7s - loss: 2.1429e-04 - val_loss: 1.5272e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 31/50\n",
      "164/164 - 7s - loss: 1.8854e-04 - val_loss: 1.3208e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 32/50\n",
      "164/164 - 7s - loss: 1.8177e-04 - val_loss: 1.1586e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 33/50\n",
      "164/164 - 7s - loss: 1.8029e-04 - val_loss: 1.1215e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 34/50\n",
      "164/164 - 7s - loss: 1.7612e-04 - val_loss: 1.1423e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 35/50\n",
      "164/164 - 7s - loss: 1.8324e-04 - val_loss: 1.1873e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 36/50\n",
      "164/164 - 7s - loss: 1.8625e-04 - val_loss: 1.2614e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 37/50\n",
      "164/164 - 7s - loss: 1.9802e-04 - val_loss: 1.4007e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 38/50\n",
      "164/164 - 7s - loss: 2.1934e-04 - val_loss: 1.6003e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 39/50\n",
      "164/164 - 7s - loss: 2.4090e-04 - val_loss: 1.9431e-04 - 7s/epoch - 42ms/step\n",
      "Epoch 40/50\n",
      "164/164 - 7s - loss: 2.8752e-04 - val_loss: 2.5645e-04 - 7s/epoch - 42ms/step\n",
      "Epoch 41/50\n",
      "164/164 - 7s - loss: 2.9910e-04 - val_loss: 2.8397e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 42/50\n",
      "164/164 - 7s - loss: 2.0949e-04 - val_loss: 1.4489e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 43/50\n",
      "164/164 - 7s - loss: 1.1699e-04 - val_loss: 6.7325e-05 - 7s/epoch - 43ms/step\n",
      "Epoch 44/50\n",
      "164/164 - 7s - loss: 8.0339e-05 - val_loss: 3.9657e-05 - 7s/epoch - 43ms/step\n",
      "Epoch 45/50\n",
      "164/164 - 7s - loss: 6.9121e-05 - val_loss: 3.2681e-05 - 7s/epoch - 43ms/step\n",
      "Epoch 46/50\n",
      "164/164 - 7s - loss: 7.1281e-05 - val_loss: 3.3394e-05 - 7s/epoch - 43ms/step\n",
      "Epoch 47/50\n",
      "164/164 - 7s - loss: 8.1035e-05 - val_loss: 4.1200e-05 - 7s/epoch - 43ms/step\n",
      "Epoch 48/50\n",
      "164/164 - 7s - loss: 1.0072e-04 - val_loss: 5.4929e-05 - 7s/epoch - 43ms/step\n",
      "Epoch 49/50\n",
      "164/164 - 7s - loss: 1.3157e-04 - val_loss: 7.5915e-05 - 7s/epoch - 43ms/step\n",
      "Epoch 50/50\n",
      "164/164 - 7s - loss: 1.7511e-04 - val_loss: 1.1032e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:50:25.411424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:50:25.583997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:50:25.601433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:50:26.050364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:50:26.069135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:50:33.465339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:50:33.516992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:50:33.527380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 11s - loss: 0.0010 - val_loss: 0.0010 - 11s/epoch - 65ms/step\n",
      "Epoch 2/100\n",
      "164/164 - 6s - loss: 0.0026 - val_loss: 0.0050 - 6s/epoch - 36ms/step\n",
      "Epoch 3/100\n",
      "164/164 - 6s - loss: 0.0016 - val_loss: 0.0038 - 6s/epoch - 36ms/step\n",
      "Epoch 4/100\n",
      "164/164 - 6s - loss: 9.9699e-04 - val_loss: 0.0016 - 6s/epoch - 37ms/step\n",
      "Epoch 5/100\n",
      "164/164 - 6s - loss: 6.8546e-04 - val_loss: 8.4499e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 6/100\n",
      "164/164 - 6s - loss: 5.8803e-04 - val_loss: 6.0854e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 7/100\n",
      "164/164 - 6s - loss: 5.5218e-04 - val_loss: 5.2504e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 8/100\n",
      "164/164 - 6s - loss: 5.2964e-04 - val_loss: 4.8589e-04 - 6s/epoch - 36ms/step\n",
      "Epoch 9/100\n",
      "164/164 - 6s - loss: 5.0680e-04 - val_loss: 4.5628e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 10/100\n",
      "164/164 - 6s - loss: 4.8029e-04 - val_loss: 4.2487e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 11/100\n",
      "164/164 - 6s - loss: 4.5004e-04 - val_loss: 3.8908e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 12/100\n",
      "164/164 - 6s - loss: 4.1686e-04 - val_loss: 3.4966e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 13/100\n",
      "164/164 - 6s - loss: 3.8174e-04 - val_loss: 3.0848e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 14/100\n",
      "164/164 - 6s - loss: 3.4564e-04 - val_loss: 2.6760e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 15/100\n",
      "164/164 - 6s - loss: 3.0980e-04 - val_loss: 2.2890e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 16/100\n",
      "164/164 - 6s - loss: 2.7590e-04 - val_loss: 1.9396e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 17/100\n",
      "164/164 - 6s - loss: 2.4619e-04 - val_loss: 1.6430e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 18/100\n",
      "164/164 - 6s - loss: 2.2319e-04 - val_loss: 1.4175e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 19/100\n",
      "164/164 - 5s - loss: 2.0877e-04 - val_loss: 1.2812e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 20/100\n",
      "164/164 - 5s - loss: 2.0334e-04 - val_loss: 1.2417e-04 - 5s/epoch - 34ms/step\n",
      "Epoch 21/100\n",
      "164/164 - 5s - loss: 2.0562e-04 - val_loss: 1.2919e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 22/100\n",
      "164/164 - 5s - loss: 2.1300e-04 - val_loss: 1.4134e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "164/164 - 5s - loss: 2.2227e-04 - val_loss: 1.5816e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 24/100\n",
      "164/164 - 5s - loss: 2.3031e-04 - val_loss: 1.7545e-04 - 5s/epoch - 34ms/step\n",
      "Epoch 25/100\n",
      "164/164 - 6s - loss: 2.3195e-04 - val_loss: 1.8485e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 26/100\n",
      "164/164 - 5s - loss: 2.3083e-04 - val_loss: 1.9263e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 27/100\n",
      "164/164 - 6s - loss: 2.2978e-04 - val_loss: 1.9559e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 28/100\n",
      "164/164 - 6s - loss: 2.2264e-04 - val_loss: 1.8641e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 29/100\n",
      "164/164 - 6s - loss: 2.0770e-04 - val_loss: 1.7604e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 30/100\n",
      "164/164 - 6s - loss: 2.0042e-04 - val_loss: 1.5964e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 31/100\n",
      "164/164 - 6s - loss: 1.8579e-04 - val_loss: 1.5080e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 32/100\n",
      "164/164 - 6s - loss: 1.8151e-04 - val_loss: 1.4379e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 33/100\n",
      "164/164 - 6s - loss: 1.7970e-04 - val_loss: 1.4106e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 34/100\n",
      "164/164 - 6s - loss: 1.8324e-04 - val_loss: 1.4202e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 35/100\n",
      "164/164 - 6s - loss: 1.8082e-04 - val_loss: 1.4471e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 36/100\n",
      "164/164 - 6s - loss: 1.8520e-04 - val_loss: 1.4741e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 37/100\n",
      "164/164 - 5s - loss: 1.8106e-04 - val_loss: 1.4763e-04 - 5s/epoch - 34ms/step\n",
      "Epoch 38/100\n",
      "164/164 - 5s - loss: 1.7416e-04 - val_loss: 1.4424e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 39/100\n",
      "164/164 - 6s - loss: 1.6487e-04 - val_loss: 1.3549e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 40/100\n",
      "164/164 - 6s - loss: 1.5795e-04 - val_loss: 1.2675e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 41/100\n",
      "164/164 - 6s - loss: 1.4890e-04 - val_loss: 1.1843e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 42/100\n",
      "164/164 - 6s - loss: 1.5095e-04 - val_loss: 1.1426e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 43/100\n",
      "164/164 - 5s - loss: 1.4437e-04 - val_loss: 1.1244e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 44/100\n",
      "164/164 - 6s - loss: 1.5035e-04 - val_loss: 1.1595e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 45/100\n",
      "164/164 - 6s - loss: 1.5085e-04 - val_loss: 1.2140e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 46/100\n",
      "164/164 - 6s - loss: 1.5697e-04 - val_loss: 1.2608e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 47/100\n",
      "164/164 - 6s - loss: 1.5397e-04 - val_loss: 1.2646e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 48/100\n",
      "164/164 - 6s - loss: 1.4457e-04 - val_loss: 1.2008e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 49/100\n",
      "164/164 - 6s - loss: 1.4167e-04 - val_loss: 1.1047e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 50/100\n",
      "164/164 - 6s - loss: 1.2976e-04 - val_loss: 1.0224e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 51/100\n",
      "164/164 - 6s - loss: 1.2684e-04 - val_loss: 9.6521e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 52/100\n",
      "164/164 - 6s - loss: 1.2254e-04 - val_loss: 9.2427e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 53/100\n",
      "164/164 - 6s - loss: 1.2132e-04 - val_loss: 9.1176e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 54/100\n",
      "164/164 - 6s - loss: 1.2245e-04 - val_loss: 9.1802e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 55/100\n",
      "164/164 - 6s - loss: 1.2382e-04 - val_loss: 9.4284e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 56/100\n",
      "164/164 - 6s - loss: 1.2472e-04 - val_loss: 9.7224e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 57/100\n",
      "164/164 - 6s - loss: 1.2706e-04 - val_loss: 1.0333e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 58/100\n",
      "164/164 - 6s - loss: 1.2847e-04 - val_loss: 1.0231e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 59/100\n",
      "164/164 - 6s - loss: 1.2781e-04 - val_loss: 1.0206e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 60/100\n",
      "164/164 - 6s - loss: 1.2011e-04 - val_loss: 9.1258e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 61/100\n",
      "164/164 - 6s - loss: 1.0959e-04 - val_loss: 8.5573e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 62/100\n",
      "164/164 - 6s - loss: 1.0005e-04 - val_loss: 7.4879e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 63/100\n",
      "164/164 - 6s - loss: 9.6678e-05 - val_loss: 7.3191e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 64/100\n",
      "164/164 - 6s - loss: 9.6012e-05 - val_loss: 6.8538e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 65/100\n",
      "164/164 - 6s - loss: 9.7723e-05 - val_loss: 7.5379e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 66/100\n",
      "164/164 - 6s - loss: 1.0391e-04 - val_loss: 7.5689e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 67/100\n",
      "164/164 - 6s - loss: 1.0989e-04 - val_loss: 8.4478e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 68/100\n",
      "164/164 - 6s - loss: 1.1812e-04 - val_loss: 9.3715e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 69/100\n",
      "164/164 - 6s - loss: 1.2060e-04 - val_loss: 9.8086e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 70/100\n",
      "164/164 - 6s - loss: 1.2466e-04 - val_loss: 1.0395e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 71/100\n",
      "164/164 - 6s - loss: 1.1212e-04 - val_loss: 8.7781e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 72/100\n",
      "164/164 - 6s - loss: 9.3422e-05 - val_loss: 6.9892e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 73/100\n",
      "164/164 - 6s - loss: 7.8699e-05 - val_loss: 5.7002e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 74/100\n",
      "164/164 - 6s - loss: 7.3809e-05 - val_loss: 5.0323e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 75/100\n",
      "164/164 - 6s - loss: 7.1369e-05 - val_loss: 4.9767e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 76/100\n",
      "164/164 - 6s - loss: 7.3963e-05 - val_loss: 5.2550e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 77/100\n",
      "164/164 - 6s - loss: 8.1044e-05 - val_loss: 5.8805e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 78/100\n",
      "164/164 - 5s - loss: 9.1617e-05 - val_loss: 7.1801e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 79/100\n",
      "164/164 - 6s - loss: 1.0755e-04 - val_loss: 8.2722e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 80/100\n",
      "164/164 - 6s - loss: 1.2211e-04 - val_loss: 9.5490e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 81/100\n",
      "164/164 - 6s - loss: 1.2655e-04 - val_loss: 1.0204e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 82/100\n",
      "164/164 - 6s - loss: 1.1462e-04 - val_loss: 9.7389e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 83/100\n",
      "164/164 - 6s - loss: 9.5223e-05 - val_loss: 7.3813e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 84/100\n",
      "164/164 - 5s - loss: 7.3395e-05 - val_loss: 5.3753e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 85/100\n",
      "164/164 - 5s - loss: 6.0556e-05 - val_loss: 4.1374e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 86/100\n",
      "164/164 - 5s - loss: 5.6268e-05 - val_loss: 3.6513e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 87/100\n",
      "164/164 - 5s - loss: 5.5702e-05 - val_loss: 3.7436e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "164/164 - 5s - loss: 5.8346e-05 - val_loss: 4.1223e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 89/100\n",
      "164/164 - 5s - loss: 6.4630e-05 - val_loss: 4.7296e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 90/100\n",
      "164/164 - 5s - loss: 7.4894e-05 - val_loss: 5.6752e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 91/100\n",
      "164/164 - 5s - loss: 9.3489e-05 - val_loss: 7.2285e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 92/100\n",
      "164/164 - 5s - loss: 1.1849e-04 - val_loss: 9.9621e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 93/100\n",
      "164/164 - 5s - loss: 1.4331e-04 - val_loss: 1.1940e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 94/100\n",
      "164/164 - 5s - loss: 1.2531e-04 - val_loss: 1.1441e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 95/100\n",
      "164/164 - 5s - loss: 8.6611e-05 - val_loss: 6.8515e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 96/100\n",
      "164/164 - 5s - loss: 5.9965e-05 - val_loss: 4.3740e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 97/100\n",
      "164/164 - 5s - loss: 4.8502e-05 - val_loss: 3.1898e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 98/100\n",
      "164/164 - 5s - loss: 4.3799e-05 - val_loss: 2.7830e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 99/100\n",
      "164/164 - 5s - loss: 4.2610e-05 - val_loss: 2.7879e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 100/100\n",
      "164/164 - 5s - loss: 4.4030e-05 - val_loss: 3.1045e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 13:59:51.056025: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:59:51.195608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:59:51.223318: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:59:51.617534: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:59:51.633458: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:59:58.252250: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:59:58.308846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 13:59:58.318077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 9s - loss: 6.4019e-04 - val_loss: 4.3061e-04 - 9s/epoch - 57ms/step\n",
      "Epoch 2/100\n",
      "164/164 - 6s - loss: 0.0012 - val_loss: 0.0019 - 6s/epoch - 34ms/step\n",
      "Epoch 3/100\n",
      "164/164 - 5s - loss: 0.0014 - val_loss: 0.0018 - 5s/epoch - 33ms/step\n",
      "Epoch 4/100\n",
      "164/164 - 6s - loss: 0.0010 - val_loss: 0.0016 - 6s/epoch - 34ms/step\n",
      "Epoch 5/100\n",
      "164/164 - 5s - loss: 8.1540e-04 - val_loss: 0.0011 - 5s/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "164/164 - 5s - loss: 6.5513e-04 - val_loss: 7.8240e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 7/100\n",
      "164/164 - 5s - loss: 5.5538e-04 - val_loss: 5.7885e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "164/164 - 5s - loss: 4.9093e-04 - val_loss: 4.6284e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 9/100\n",
      "164/164 - 5s - loss: 4.4495e-04 - val_loss: 3.8712e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 10/100\n",
      "164/164 - 5s - loss: 4.0598e-04 - val_loss: 3.3054e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "164/164 - 5s - loss: 3.6979e-04 - val_loss: 2.8326e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 12/100\n",
      "164/164 - 5s - loss: 3.3375e-04 - val_loss: 2.4069e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "164/164 - 5s - loss: 2.9895e-04 - val_loss: 2.0247e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 14/100\n",
      "164/164 - 5s - loss: 2.6556e-04 - val_loss: 1.6850e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 15/100\n",
      "164/164 - 5s - loss: 2.3761e-04 - val_loss: 1.4059e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 16/100\n",
      "164/164 - 5s - loss: 2.1694e-04 - val_loss: 1.2102e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 17/100\n",
      "164/164 - 5s - loss: 2.0594e-04 - val_loss: 1.1049e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 18/100\n",
      "164/164 - 5s - loss: 2.0421e-04 - val_loss: 1.0990e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 19/100\n",
      "164/164 - 5s - loss: 2.1018e-04 - val_loss: 1.1757e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 20/100\n",
      "164/164 - 5s - loss: 2.2074e-04 - val_loss: 1.3252e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 21/100\n",
      "164/164 - 5s - loss: 2.3283e-04 - val_loss: 1.4510e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 22/100\n",
      "164/164 - 5s - loss: 2.4911e-04 - val_loss: 1.7711e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "164/164 - 5s - loss: 2.6217e-04 - val_loss: 1.9756e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 24/100\n",
      "164/164 - 5s - loss: 2.6434e-04 - val_loss: 1.8959e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 25/100\n",
      "164/164 - 5s - loss: 2.3877e-04 - val_loss: 1.7015e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "164/164 - 5s - loss: 2.1913e-04 - val_loss: 1.3990e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 27/100\n",
      "164/164 - 5s - loss: 1.8713e-04 - val_loss: 1.1379e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 28/100\n",
      "164/164 - 5s - loss: 1.7375e-04 - val_loss: 9.9087e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "164/164 - 5s - loss: 1.6691e-04 - val_loss: 9.3069e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 30/100\n",
      "164/164 - 5s - loss: 1.6760e-04 - val_loss: 9.4873e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 31/100\n",
      "164/164 - 5s - loss: 1.7808e-04 - val_loss: 1.0301e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 32/100\n",
      "164/164 - 5s - loss: 1.9442e-04 - val_loss: 1.1920e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 33/100\n",
      "164/164 - 5s - loss: 2.0979e-04 - val_loss: 1.4342e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 34/100\n",
      "164/164 - 6s - loss: 2.2728e-04 - val_loss: 1.5944e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 35/100\n",
      "164/164 - 6s - loss: 2.1864e-04 - val_loss: 1.5461e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 36/100\n",
      "164/164 - 6s - loss: 1.9417e-04 - val_loss: 1.2598e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 37/100\n",
      "164/164 - 6s - loss: 1.5423e-04 - val_loss: 9.5102e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 38/100\n",
      "164/164 - 6s - loss: 1.3640e-04 - val_loss: 7.4959e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 39/100\n",
      "164/164 - 6s - loss: 1.2679e-04 - val_loss: 6.7931e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 40/100\n",
      "164/164 - 6s - loss: 1.2861e-04 - val_loss: 7.0901e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 41/100\n",
      "164/164 - 6s - loss: 1.4103e-04 - val_loss: 8.0531e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 42/100\n",
      "164/164 - 6s - loss: 1.5911e-04 - val_loss: 9.2605e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 43/100\n",
      "164/164 - 6s - loss: 1.8177e-04 - val_loss: 1.2570e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 44/100\n",
      "164/164 - 6s - loss: 2.2584e-04 - val_loss: 1.7154e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 45/100\n",
      "164/164 - 6s - loss: 2.1838e-04 - val_loss: 1.6439e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 46/100\n",
      "164/164 - 6s - loss: 1.6878e-04 - val_loss: 1.1124e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 47/100\n",
      "164/164 - 6s - loss: 1.2029e-04 - val_loss: 6.6931e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 48/100\n",
      "164/164 - 6s - loss: 9.0743e-05 - val_loss: 4.6803e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 49/100\n",
      "164/164 - 6s - loss: 8.0872e-05 - val_loss: 4.1642e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 50/100\n",
      "164/164 - 6s - loss: 8.1497e-05 - val_loss: 4.3089e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 51/100\n",
      "164/164 - 6s - loss: 9.1185e-05 - val_loss: 5.5461e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 52/100\n",
      "164/164 - 6s - loss: 1.1122e-04 - val_loss: 6.9249e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 53/100\n",
      "164/164 - 6s - loss: 1.4253e-04 - val_loss: 8.8834e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 54/100\n",
      "164/164 - 6s - loss: 1.8476e-04 - val_loss: 1.2987e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 55/100\n",
      "164/164 - 6s - loss: 2.4704e-04 - val_loss: 2.2297e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 56/100\n",
      "164/164 - 6s - loss: 2.2132e-04 - val_loss: 1.9423e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 57/100\n",
      "164/164 - 6s - loss: 1.4595e-04 - val_loss: 9.7433e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 58/100\n",
      "164/164 - 6s - loss: 8.7250e-05 - val_loss: 5.0021e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 59/100\n",
      "164/164 - 5s - loss: 6.3374e-05 - val_loss: 3.1981e-05 - 5s/epoch - 34ms/step\n",
      "Epoch 60/100\n",
      "164/164 - 6s - loss: 5.5698e-05 - val_loss: 2.6797e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 61/100\n",
      "164/164 - 5s - loss: 5.4740e-05 - val_loss: 2.7839e-05 - 5s/epoch - 33ms/step\n",
      "Epoch 62/100\n",
      "164/164 - 6s - loss: 5.8166e-05 - val_loss: 3.3294e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 63/100\n",
      "164/164 - 6s - loss: 6.6803e-05 - val_loss: 4.4738e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 64/100\n",
      "164/164 - 5s - loss: 8.3074e-05 - val_loss: 6.4332e-05 - 5s/epoch - 34ms/step\n",
      "Epoch 65/100\n",
      "164/164 - 6s - loss: 1.1495e-04 - val_loss: 9.2225e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 66/100\n",
      "164/164 - 5s - loss: 1.8646e-04 - val_loss: 1.4449e-04 - 5s/epoch - 34ms/step\n",
      "Epoch 67/100\n",
      "164/164 - 6s - loss: 2.6994e-04 - val_loss: 2.7386e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 68/100\n",
      "164/164 - 6s - loss: 2.3671e-04 - val_loss: 2.3249e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 69/100\n",
      "164/164 - 6s - loss: 1.3700e-04 - val_loss: 9.3697e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 70/100\n",
      "164/164 - 6s - loss: 6.9890e-05 - val_loss: 3.8542e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 71/100\n",
      "164/164 - 6s - loss: 4.8969e-05 - val_loss: 2.3225e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 72/100\n",
      "164/164 - 6s - loss: 4.3007e-05 - val_loss: 1.8775e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 73/100\n",
      "164/164 - 6s - loss: 4.2353e-05 - val_loss: 1.8843e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 74/100\n",
      "164/164 - 6s - loss: 4.4961e-05 - val_loss: 2.2090e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 75/100\n",
      "164/164 - 6s - loss: 5.0624e-05 - val_loss: 2.8861e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 76/100\n",
      "164/164 - 6s - loss: 6.0888e-05 - val_loss: 4.0610e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 77/100\n",
      "164/164 - 6s - loss: 7.9520e-05 - val_loss: 5.7857e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 78/100\n",
      "164/164 - 6s - loss: 1.2043e-04 - val_loss: 9.1727e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 79/100\n",
      "164/164 - 6s - loss: 2.0404e-04 - val_loss: 1.6475e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 80/100\n",
      "164/164 - 6s - loss: 2.5948e-04 - val_loss: 2.7656e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 81/100\n",
      "164/164 - 6s - loss: 1.6150e-04 - val_loss: 1.2056e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 82/100\n",
      "164/164 - 6s - loss: 7.7605e-05 - val_loss: 4.5423e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 83/100\n",
      "164/164 - 6s - loss: 4.7354e-05 - val_loss: 2.2472e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 84/100\n",
      "164/164 - 6s - loss: 3.8591e-05 - val_loss: 1.6243e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 85/100\n",
      "164/164 - 6s - loss: 3.6804e-05 - val_loss: 1.5568e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 86/100\n",
      "164/164 - 6s - loss: 3.8472e-05 - val_loss: 1.7722e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 87/100\n",
      "164/164 - 6s - loss: 4.2516e-05 - val_loss: 2.2833e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 88/100\n",
      "164/164 - 6s - loss: 4.9761e-05 - val_loss: 3.2482e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 89/100\n",
      "164/164 - 6s - loss: 6.2236e-05 - val_loss: 4.7878e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 90/100\n",
      "164/164 - 6s - loss: 8.7052e-05 - val_loss: 7.6907e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 91/100\n",
      "164/164 - 6s - loss: 1.4210e-04 - val_loss: 1.2582e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 92/100\n",
      "164/164 - 6s - loss: 2.5871e-04 - val_loss: 3.0804e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 93/100\n",
      "164/164 - 6s - loss: 2.3441e-04 - val_loss: 2.3726e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 94/100\n",
      "164/164 - 6s - loss: 1.0911e-04 - val_loss: 7.0315e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 95/100\n",
      "164/164 - 6s - loss: 5.3231e-05 - val_loss: 2.9399e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 96/100\n",
      "164/164 - 6s - loss: 3.8350e-05 - val_loss: 1.7604e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 97/100\n",
      "164/164 - 6s - loss: 3.4260e-05 - val_loss: 1.4255e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 98/100\n",
      "164/164 - 6s - loss: 3.4110e-05 - val_loss: 1.4010e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 99/100\n",
      "164/164 - 6s - loss: 3.6419e-05 - val_loss: 1.6207e-05 - 6s/epoch - 34ms/step\n",
      "Epoch 100/100\n",
      "164/164 - 5s - loss: 4.1358e-05 - val_loss: 2.1498e-05 - 5s/epoch - 34ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 14:09:06.684015: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 14:09:06.822251: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 14:09:06.849835: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 14:09:07.281896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 14:09:07.298472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 14:09:14.669187: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 14:09:14.731023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 14:09:14.741858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 10s - loss: 7.5227e-04 - val_loss: 4.9054e-04 - 10s/epoch - 64ms/step\n",
      "Epoch 2/100\n",
      "164/164 - 6s - loss: 9.2407e-04 - val_loss: 0.0015 - 6s/epoch - 39ms/step\n",
      "Epoch 3/100\n",
      "164/164 - 7s - loss: 0.0022 - val_loss: 0.0064 - 7s/epoch - 40ms/step\n",
      "Epoch 4/100\n",
      "164/164 - 7s - loss: 0.0023 - val_loss: 0.0047 - 7s/epoch - 41ms/step\n",
      "Epoch 5/100\n",
      "164/164 - 7s - loss: 0.0014 - val_loss: 0.0028 - 7s/epoch - 41ms/step\n",
      "Epoch 6/100\n",
      "164/164 - 7s - loss: 8.8453e-04 - val_loss: 0.0014 - 7s/epoch - 41ms/step\n",
      "Epoch 7/100\n",
      "164/164 - 7s - loss: 6.1810e-04 - val_loss: 7.5388e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 8/100\n",
      "164/164 - 7s - loss: 5.1126e-04 - val_loss: 5.1991e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 9/100\n",
      "164/164 - 7s - loss: 4.6569e-04 - val_loss: 4.2494e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 10/100\n",
      "164/164 - 7s - loss: 4.3777e-04 - val_loss: 3.7547e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 11/100\n",
      "164/164 - 7s - loss: 4.1211e-04 - val_loss: 3.3910e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 12/100\n",
      "164/164 - 7s - loss: 3.8379e-04 - val_loss: 3.0490e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 13/100\n",
      "164/164 - 7s - loss: 3.5236e-04 - val_loss: 2.7029e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 14/100\n",
      "164/164 - 7s - loss: 3.1950e-04 - val_loss: 2.3595e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 15/100\n",
      "164/164 - 7s - loss: 2.8804e-04 - val_loss: 2.0380e-04 - 7s/epoch - 45ms/step\n",
      "Epoch 16/100\n",
      "164/164 - 7s - loss: 2.6124e-04 - val_loss: 1.7640e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 17/100\n",
      "164/164 - 7s - loss: 2.4187e-04 - val_loss: 1.5656e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 18/100\n",
      "164/164 - 7s - loss: 2.3123e-04 - val_loss: 1.4617e-04 - 7s/epoch - 42ms/step\n",
      "Epoch 19/100\n",
      "164/164 - 7s - loss: 2.2873e-04 - val_loss: 1.4527e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 20/100\n",
      "164/164 - 7s - loss: 2.3229e-04 - val_loss: 1.5232e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 21/100\n",
      "164/164 - 7s - loss: 2.3897e-04 - val_loss: 1.6446e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 22/100\n",
      "164/164 - 7s - loss: 2.4602e-04 - val_loss: 1.7792e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 23/100\n",
      "164/164 - 7s - loss: 2.5608e-04 - val_loss: 1.9999e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 24/100\n",
      "164/164 - 7s - loss: 2.6656e-04 - val_loss: 2.1278e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 25/100\n",
      "164/164 - 7s - loss: 2.7000e-04 - val_loss: 2.2593e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 26/100\n",
      "164/164 - 7s - loss: 2.7700e-04 - val_loss: 2.2617e-04 - 7s/epoch - 42ms/step\n",
      "Epoch 27/100\n",
      "164/164 - 7s - loss: 2.5478e-04 - val_loss: 2.1242e-04 - 7s/epoch - 43ms/step\n",
      "Epoch 28/100\n",
      "164/164 - 7s - loss: 2.2485e-04 - val_loss: 1.6986e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 29/100\n",
      "164/164 - 7s - loss: 1.9417e-04 - val_loss: 1.3951e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 30/100\n",
      "164/164 - 7s - loss: 1.7465e-04 - val_loss: 1.1630e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 31/100\n",
      "164/164 - 7s - loss: 1.6802e-04 - val_loss: 1.0595e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 32/100\n",
      "164/164 - 7s - loss: 1.6803e-04 - val_loss: 1.0585e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 33/100\n",
      "164/164 - 7s - loss: 1.7830e-04 - val_loss: 1.1321e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 34/100\n",
      "164/164 - 7s - loss: 1.8968e-04 - val_loss: 1.2837e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 35/100\n",
      "164/164 - 7s - loss: 2.1266e-04 - val_loss: 1.5406e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 36/100\n",
      "164/164 - 7s - loss: 2.4627e-04 - val_loss: 1.9633e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 37/100\n",
      "164/164 - 7s - loss: 2.9638e-04 - val_loss: 2.7953e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 38/100\n",
      "164/164 - 7s - loss: 3.2862e-04 - val_loss: 3.3705e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 39/100\n",
      "164/164 - 7s - loss: 2.9907e-04 - val_loss: 2.4072e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 40/100\n",
      "164/164 - 7s - loss: 1.5971e-04 - val_loss: 1.0462e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 41/100\n",
      "164/164 - 7s - loss: 9.6049e-05 - val_loss: 5.2132e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 42/100\n",
      "164/164 - 7s - loss: 7.2583e-05 - val_loss: 3.5998e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 43/100\n",
      "164/164 - 7s - loss: 6.8819e-05 - val_loss: 3.2497e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 44/100\n",
      "164/164 - 7s - loss: 7.3595e-05 - val_loss: 3.5696e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 45/100\n",
      "164/164 - 7s - loss: 8.6515e-05 - val_loss: 4.5607e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 46/100\n",
      "164/164 - 7s - loss: 1.0688e-04 - val_loss: 6.1400e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 47/100\n",
      "164/164 - 7s - loss: 1.4169e-04 - val_loss: 8.5258e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 48/100\n",
      "164/164 - 7s - loss: 1.9048e-04 - val_loss: 1.1983e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 49/100\n",
      "164/164 - 7s - loss: 2.4627e-04 - val_loss: 2.0486e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 50/100\n",
      "164/164 - 7s - loss: 3.3989e-04 - val_loss: 3.2490e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 51/100\n",
      "164/164 - 7s - loss: 2.7178e-04 - val_loss: 2.2971e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 52/100\n",
      "164/164 - 7s - loss: 1.3401e-04 - val_loss: 8.1444e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 53/100\n",
      "164/164 - 7s - loss: 7.3737e-05 - val_loss: 3.9071e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 54/100\n",
      "164/164 - 7s - loss: 5.6090e-05 - val_loss: 2.6919e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 55/100\n",
      "164/164 - 7s - loss: 5.3186e-05 - val_loss: 2.4089e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 56/100\n",
      "164/164 - 7s - loss: 5.6677e-05 - val_loss: 2.6343e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 57/100\n",
      "164/164 - 7s - loss: 6.5858e-05 - val_loss: 3.3252e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 58/100\n",
      "164/164 - 7s - loss: 8.3500e-05 - val_loss: 4.5830e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 59/100\n",
      "164/164 - 7s - loss: 1.1536e-04 - val_loss: 7.1789e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 60/100\n",
      "164/164 - 7s - loss: 1.6245e-04 - val_loss: 1.1035e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 61/100\n",
      "164/164 - 7s - loss: 2.2980e-04 - val_loss: 2.1149e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 62/100\n",
      "164/164 - 7s - loss: 3.2540e-04 - val_loss: 4.1011e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 63/100\n",
      "164/164 - 7s - loss: 2.6853e-04 - val_loss: 2.1051e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 64/100\n",
      "164/164 - 7s - loss: 1.1275e-04 - val_loss: 5.6073e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 65/100\n",
      "164/164 - 7s - loss: 5.6142e-05 - val_loss: 2.6568e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 66/100\n",
      "164/164 - 7s - loss: 4.3773e-05 - val_loss: 1.8894e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 67/100\n",
      "164/164 - 7s - loss: 4.1844e-05 - val_loss: 1.7211e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 68/100\n",
      "164/164 - 7s - loss: 4.4542e-05 - val_loss: 1.8854e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 69/100\n",
      "164/164 - 7s - loss: 5.1487e-05 - val_loss: 2.3907e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 70/100\n",
      "164/164 - 7s - loss: 6.3733e-05 - val_loss: 3.3526e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 71/100\n",
      "164/164 - 7s - loss: 8.3812e-05 - val_loss: 4.8469e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 72/100\n",
      "164/164 - 7s - loss: 1.1651e-04 - val_loss: 7.1253e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 73/100\n",
      "164/164 - 7s - loss: 1.6831e-04 - val_loss: 1.2062e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 74/100\n",
      "164/164 - 7s - loss: 2.2798e-04 - val_loss: 2.2872e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 75/100\n",
      "164/164 - 7s - loss: 2.3590e-04 - val_loss: 2.5006e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 76/100\n",
      "164/164 - 7s - loss: 1.4343e-04 - val_loss: 7.7050e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 77/100\n",
      "164/164 - 7s - loss: 5.7708e-05 - val_loss: 2.7574e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 78/100\n",
      "164/164 - 7s - loss: 4.1057e-05 - val_loss: 1.8495e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 79/100\n",
      "164/164 - 7s - loss: 3.8989e-05 - val_loss: 1.6928e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 80/100\n",
      "164/164 - 7s - loss: 4.1526e-05 - val_loss: 1.8598e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 81/100\n",
      "164/164 - 7s - loss: 4.8244e-05 - val_loss: 2.4406e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 82/100\n",
      "164/164 - 7s - loss: 6.0702e-05 - val_loss: 3.7305e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 83/100\n",
      "164/164 - 7s - loss: 8.6014e-05 - val_loss: 6.8241e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 84/100\n",
      "164/164 - 7s - loss: 1.4241e-04 - val_loss: 1.3372e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 85/100\n",
      "164/164 - 7s - loss: 2.4318e-04 - val_loss: 2.8427e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 86/100\n",
      "164/164 - 7s - loss: 2.8393e-04 - val_loss: 3.0810e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 87/100\n",
      "164/164 - 7s - loss: 1.3257e-04 - val_loss: 6.9606e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 88/100\n",
      "164/164 - 7s - loss: 5.2279e-05 - val_loss: 2.6529e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 89/100\n",
      "164/164 - 7s - loss: 3.7548e-05 - val_loss: 1.7073e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 90/100\n",
      "164/164 - 7s - loss: 3.4850e-05 - val_loss: 1.4671e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 91/100\n",
      "164/164 - 7s - loss: 3.6283e-05 - val_loss: 1.5329e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 92/100\n",
      "164/164 - 7s - loss: 4.0868e-05 - val_loss: 1.8860e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 93/100\n",
      "164/164 - 7s - loss: 4.9360e-05 - val_loss: 2.6321e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 94/100\n",
      "164/164 - 7s - loss: 6.3465e-05 - val_loss: 3.8488e-05 - 7s/epoch - 40ms/step\n",
      "Epoch 95/100\n",
      "164/164 - 7s - loss: 8.5444e-05 - val_loss: 5.5055e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 96/100\n",
      "164/164 - 7s - loss: 1.1531e-04 - val_loss: 8.0330e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 97/100\n",
      "164/164 - 7s - loss: 1.4938e-04 - val_loss: 1.2541e-04 - 7s/epoch - 40ms/step\n",
      "Epoch 98/100\n",
      "164/164 - 7s - loss: 1.7287e-04 - val_loss: 1.6383e-04 - 7s/epoch - 41ms/step\n",
      "Epoch 99/100\n",
      "164/164 - 7s - loss: 1.2265e-04 - val_loss: 9.4262e-05 - 7s/epoch - 41ms/step\n",
      "Epoch 100/100\n",
      "164/164 - 7s - loss: 6.9686e-05 - val_loss: 3.7637e-05 - 7s/epoch - 41ms/step\n"
     ]
    }
   ],
   "source": [
    "bilstms3 = []\n",
    "models3 = []\n",
    "for batch, epoch, neuron in hyperparam3:\n",
    "    model, bilstm = LSTMUnit.train_bilstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    bilstms3.append(bilstm)\n",
    "    models3.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "546cd3a7-bfcc-4077-9e56-6b8bfda87f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "65.71360537648472\n",
      "MAE\n",
      "58.98231454787343\n",
      "MAPE\n",
      "4.533615648765488\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "59.18008537114462\n",
      "MAE\n",
      "52.69087729084142\n",
      "MAPE\n",
      "4.067120221765923\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "76.00028663782034\n",
      "MAE\n",
      "69.91594391848292\n",
      "MAPE\n",
      "5.351988795703374\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "48.777337588826036\n",
      "MAE\n",
      "43.45865814730819\n",
      "MAPE\n",
      "3.356895310062998\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "50.3915384933195\n",
      "MAE\n",
      "45.04039189425001\n",
      "MAPE\n",
      "3.4855052933795547\n",
      "163/163 [==============================] - 3s 15ms/step\n",
      "(128, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "49.892040251234285\n",
      "MAE\n",
      "44.22958764625003\n",
      "MAPE\n",
      "3.4342917922863827\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "26.466785579089844\n",
      "MAE\n",
      "22.15359517309823\n",
      "MAPE\n",
      "1.7114938223947713\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "22.024061411814273\n",
      "MAE\n",
      "17.607944725718177\n",
      "MAPE\n",
      "1.3516446192546316\n",
      "163/163 [==============================] - 2s 15ms/step\n",
      "(128, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "29.141452178399177\n",
      "MAE\n",
      "25.48648995059958\n",
      "MAPE\n",
      "1.9430373783287083\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb3 = Workbook()\n",
    "ws3 = wb3.active\n",
    "for m in models3:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = LSTMUnit.predict(test_x2, m)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparam3[i])\n",
    "    print(\"Epoch: \"+ str(bilstms3[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].layer.units))\n",
    "    i = i+1\n",
    "    ws3['A'+str(i)] = 'BiLSTM'\n",
    "    ws3['B'+str(i)] = hyperparam3[i-1][0]\n",
    "    ws3['C'+str(i)] = hyperparam3[i-1][1]\n",
    "    ws3['D'+str(i)] = hyperparam3[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
    "    ws3['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
    "    print('MAE')\n",
    "    print(Evaluation.mae(inv_y,inv_yhat))\n",
    "    ws3['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
    "    print('MAPE')\n",
    "    print(Evaluation.mape(inv_y,inv_yhat))\n",
    "    ws3['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
    "    LSTMUnit.save_model(m, 1, 'ETH',hyperparam3[i-1])\n",
    "    with open('BiLSTM_ETH'+str(hyperparam3[i-1])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(bilstms3[i-1].history, f)\n",
    "wb3.save('BiLSTM_ETH_result3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d99b65f4-ade9-447a-9440-bab346a23910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.35310067, 0.35162768, 0.34770043, 0.15036013, 0.34664396],\n",
       "        [0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "        [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        ...,\n",
       "        [0.35695716, 0.3549118 , 0.35827089, 0.02554312, 0.35642272],\n",
       "        [0.35642247, 0.35363301, 0.35533021, 0.0359709 , 0.35359541],\n",
       "        [0.35359115, 0.35089064, 0.35262123, 0.05488511, 0.3519828 ]],\n",
       "\n",
       "       [[0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "        [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        [0.35186288, 0.35105233, 0.34876   , 0.06304256, 0.34708184],\n",
       "        ...,\n",
       "        [0.35642247, 0.35363301, 0.35533021, 0.0359709 , 0.35359541],\n",
       "        [0.35359115, 0.35089064, 0.35262123, 0.05488511, 0.3519828 ],\n",
       "        [0.35197866, 0.35126441, 0.35368502, 0.01896836, 0.35364383]],\n",
       "\n",
       "       [[0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        [0.35186288, 0.35105233, 0.34876   , 0.06304256, 0.34708184],\n",
       "        [0.34708226, 0.34721595, 0.34265955, 0.10696327, 0.34520188],\n",
       "        ...,\n",
       "        [0.35359115, 0.35089064, 0.35262123, 0.05488511, 0.3519828 ],\n",
       "        [0.35197866, 0.35126441, 0.35368502, 0.01896836, 0.35364383],\n",
       "        [0.35364167, 0.35142399, 0.35460557, 0.01667411, 0.3533912 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.23236423, 0.23020551, 0.23384781, 0.00805634, 0.23195771],\n",
       "        [0.23196426, 0.22960706, 0.23287039, 0.01628271, 0.23152403],\n",
       "        [0.23153062, 0.2291766 , 0.23343072, 0.00687752, 0.23125457],\n",
       "        ...,\n",
       "        [0.23245685, 0.22999343, 0.23450504, 0.00350383, 0.23220192],\n",
       "        [0.23220635, 0.23096355, 0.23454296, 0.00661101, 0.23284401],\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875]],\n",
       "\n",
       "       [[0.23196426, 0.22960706, 0.23287039, 0.01628271, 0.23152403],\n",
       "        [0.23153062, 0.2291766 , 0.23343072, 0.00687752, 0.23125457],\n",
       "        [0.23126328, 0.23039239, 0.23344547, 0.01020951, 0.23182508],\n",
       "        ...,\n",
       "        [0.23220635, 0.23096355, 0.23454296, 0.00661101, 0.23284401],\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875],\n",
       "        [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718]],\n",
       "\n",
       "       [[0.23153062, 0.2291766 , 0.23343072, 0.00687752, 0.23125457],\n",
       "        [0.23126328, 0.23039239, 0.23344547, 0.01020951, 0.23182508],\n",
       "        [0.23183164, 0.23066327, 0.23405004, 0.01194032, 0.23238928],\n",
       "        ...,\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875],\n",
       "        [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718],\n",
       "        [0.2323116 , 0.23001863, 0.23320743, 0.00977339, 0.23148404]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d452450-b304-46f7-ab22-8d1fa9393d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
