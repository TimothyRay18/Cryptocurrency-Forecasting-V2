{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ef9d1-2655-483e-9f50-0badccf17d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Skripsi import Preprocessing\n",
    "from Skripsi import Evaluation\n",
    "from Skripsi import LSTMUnit\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl.workbook import Workbook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ed0706-d5c2-4868-beee-6933c00b0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>16520.28</td>\n",
       "      <td>16551.24</td>\n",
       "      <td>16487.74</td>\n",
       "      <td>16542.40</td>\n",
       "      <td>8.217183e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>16567.49</td>\n",
       "      <td>16470.00</td>\n",
       "      <td>16520.81</td>\n",
       "      <td>1.106669e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>16568.19</td>\n",
       "      <td>16571.64</td>\n",
       "      <td>16544.12</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>5.992803e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>16574.97</td>\n",
       "      <td>16564.09</td>\n",
       "      <td>16568.60</td>\n",
       "      <td>4.344849e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>16577.78</td>\n",
       "      <td>16590.06</td>\n",
       "      <td>16565.10</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>6.704605e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>7217.27</td>\n",
       "      <td>3.379094e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>7225.01</td>\n",
       "      <td>5.667367e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>7242.85</td>\n",
       "      <td>4.736719e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>7216.27</td>\n",
       "      <td>6.365953e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>7177.02</td>\n",
       "      <td>3.675857e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date      Open      High       Low     Close  \\\n",
       "0      2022-12-31 23:00:00  16520.28  16551.24  16487.74  16542.40   \n",
       "1      2022-12-31 22:00:00  16548.28  16567.49  16470.00  16520.81   \n",
       "2      2022-12-31 21:00:00  16568.19  16571.64  16544.12  16548.28   \n",
       "3      2022-12-31 20:00:00  16570.14  16574.97  16564.09  16568.60   \n",
       "4      2022-12-31 19:00:00  16577.78  16590.06  16565.10  16570.14   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "26269  2020-01-01 04:00:00   7225.00   7230.00   7215.03   7217.27   \n",
       "26270  2020-01-01 03:00:00   7242.66   7245.00   7220.00   7225.01   \n",
       "26271  2020-01-01 02:00:00   7215.52   7244.87   7211.41   7242.85   \n",
       "26272  2020-01-01 01:00:00   7176.47   7230.00   7175.71   7216.27   \n",
       "26273  2020-01-01 00:00:00   7195.24   7196.25   7175.46   7177.02   \n",
       "\n",
       "        Volume USDT  \n",
       "0      8.217183e+07  \n",
       "1      1.106669e+08  \n",
       "2      5.992803e+07  \n",
       "3      4.344849e+07  \n",
       "4      6.704605e+07  \n",
       "...             ...  \n",
       "26269  3.379094e+06  \n",
       "26270  5.667367e+06  \n",
       "26271  4.736719e+06  \n",
       "26272  6.365953e+06  \n",
       "26273  3.675857e+06  \n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_dfd = pd.read_csv('../Dataset/Binance_BTCUSDT_1h.csv')\n",
    "btc_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc368c1b-a82f-4dbf-85c4-f19ebff7a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>16520.28</td>\n",
       "      <td>16551.24</td>\n",
       "      <td>16487.74</td>\n",
       "      <td>16542.40</td>\n",
       "      <td>8.217183e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>16567.49</td>\n",
       "      <td>16470.00</td>\n",
       "      <td>16520.81</td>\n",
       "      <td>1.106669e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>16568.19</td>\n",
       "      <td>16571.64</td>\n",
       "      <td>16544.12</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>5.992803e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>16574.97</td>\n",
       "      <td>16564.09</td>\n",
       "      <td>16568.60</td>\n",
       "      <td>4.344849e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>16577.78</td>\n",
       "      <td>16590.06</td>\n",
       "      <td>16565.10</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>6.704605e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>7217.27</td>\n",
       "      <td>3.379094e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>7225.01</td>\n",
       "      <td>5.667367e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>7242.85</td>\n",
       "      <td>4.736719e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>7216.27</td>\n",
       "      <td>6.365953e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>7177.02</td>\n",
       "      <td>3.675857e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date      Open      High       Low     Close  \\\n",
       "0      2022-12-31 23:00:00  16520.28  16551.24  16487.74  16542.40   \n",
       "1      2022-12-31 22:00:00  16548.28  16567.49  16470.00  16520.81   \n",
       "2      2022-12-31 21:00:00  16568.19  16571.64  16544.12  16548.28   \n",
       "3      2022-12-31 20:00:00  16570.14  16574.97  16564.09  16568.60   \n",
       "4      2022-12-31 19:00:00  16577.78  16590.06  16565.10  16570.14   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "26269  2020-01-01 04:00:00   7225.00   7230.00   7215.03   7217.27   \n",
       "26270  2020-01-01 03:00:00   7242.66   7245.00   7220.00   7225.01   \n",
       "26271  2020-01-01 02:00:00   7215.52   7244.87   7211.41   7242.85   \n",
       "26272  2020-01-01 01:00:00   7176.47   7230.00   7175.71   7216.27   \n",
       "26273  2020-01-01 00:00:00   7195.24   7196.25   7175.46   7177.02   \n",
       "\n",
       "        Volume USDT  \n",
       "0      8.217183e+07  \n",
       "1      1.106669e+08  \n",
       "2      5.992803e+07  \n",
       "3      4.344849e+07  \n",
       "4      6.704605e+07  \n",
       "...             ...  \n",
       "26269  3.379094e+06  \n",
       "26270  5.667367e+06  \n",
       "26271  4.736719e+06  \n",
       "26272  6.365953e+06  \n",
       "26273  3.675857e+06  \n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup = Preprocessing.handle_duplicate(btc_dfd)\n",
    "df_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41062755-9cca-4348-91bc-e80d46b79c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>7177.02</td>\n",
       "      <td>3.675857e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>7216.27</td>\n",
       "      <td>6.365953e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>7242.85</td>\n",
       "      <td>4.736719e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>7225.01</td>\n",
       "      <td>5.667367e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>7217.27</td>\n",
       "      <td>3.379094e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>16577.78</td>\n",
       "      <td>16590.06</td>\n",
       "      <td>16565.10</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>6.704605e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>16574.97</td>\n",
       "      <td>16564.09</td>\n",
       "      <td>16568.60</td>\n",
       "      <td>4.344849e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>16568.19</td>\n",
       "      <td>16571.64</td>\n",
       "      <td>16544.12</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>5.992803e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>16567.49</td>\n",
       "      <td>16470.00</td>\n",
       "      <td>16520.81</td>\n",
       "      <td>1.106669e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>16520.28</td>\n",
       "      <td>16551.24</td>\n",
       "      <td>16487.74</td>\n",
       "      <td>16542.40</td>\n",
       "      <td>8.217183e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date      Open      High       Low     Close  \\\n",
       "0      2020-01-01 00:00:00   7195.24   7196.25   7175.46   7177.02   \n",
       "1      2020-01-01 01:00:00   7176.47   7230.00   7175.71   7216.27   \n",
       "2      2020-01-01 02:00:00   7215.52   7244.87   7211.41   7242.85   \n",
       "3      2020-01-01 03:00:00   7242.66   7245.00   7220.00   7225.01   \n",
       "4      2020-01-01 04:00:00   7225.00   7230.00   7215.03   7217.27   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "26269  2022-12-31 19:00:00  16577.78  16590.06  16565.10  16570.14   \n",
       "26270  2022-12-31 20:00:00  16570.14  16574.97  16564.09  16568.60   \n",
       "26271  2022-12-31 21:00:00  16568.19  16571.64  16544.12  16548.28   \n",
       "26272  2022-12-31 22:00:00  16548.28  16567.49  16470.00  16520.81   \n",
       "26273  2022-12-31 23:00:00  16520.28  16551.24  16487.74  16542.40   \n",
       "\n",
       "        Volume USDT  \n",
       "0      3.675857e+06  \n",
       "1      6.365953e+06  \n",
       "2      4.736719e+06  \n",
       "3      5.667367e+06  \n",
       "4      3.379094e+06  \n",
       "...             ...  \n",
       "26269  6.704605e+07  \n",
       "26270  4.344849e+07  \n",
       "26271  5.992803e+07  \n",
       "26272  1.106669e+08  \n",
       "26273  8.217183e+07  \n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Preprocessing.sort_df(df_no_dup)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483f3731-9efb-47c6-af9c-6eadc95287e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume USDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>7177.02</td>\n",
       "      <td>3.675857e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>7216.27</td>\n",
       "      <td>6.365953e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>7242.85</td>\n",
       "      <td>4.736719e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>7225.01</td>\n",
       "      <td>5.667367e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>7217.27</td>\n",
       "      <td>3.379094e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>16577.78</td>\n",
       "      <td>16590.06</td>\n",
       "      <td>16565.10</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>6.704605e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>16574.97</td>\n",
       "      <td>16564.09</td>\n",
       "      <td>16568.60</td>\n",
       "      <td>4.344849e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>16568.19</td>\n",
       "      <td>16571.64</td>\n",
       "      <td>16544.12</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>5.992803e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>16567.49</td>\n",
       "      <td>16470.00</td>\n",
       "      <td>16520.81</td>\n",
       "      <td>1.106669e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>16520.28</td>\n",
       "      <td>16551.24</td>\n",
       "      <td>16487.74</td>\n",
       "      <td>16542.40</td>\n",
       "      <td>8.217183e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date      Open      High       Low     Close  \\\n",
       "0      2020-01-01 00:00:00   7195.24   7196.25   7175.46   7177.02   \n",
       "1      2020-01-01 01:00:00   7176.47   7230.00   7175.71   7216.27   \n",
       "2      2020-01-01 02:00:00   7215.52   7244.87   7211.41   7242.85   \n",
       "3      2020-01-01 03:00:00   7242.66   7245.00   7220.00   7225.01   \n",
       "4      2020-01-01 04:00:00   7225.00   7230.00   7215.03   7217.27   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "26269  2022-12-31 19:00:00  16577.78  16590.06  16565.10  16570.14   \n",
       "26270  2022-12-31 20:00:00  16570.14  16574.97  16564.09  16568.60   \n",
       "26271  2022-12-31 21:00:00  16568.19  16571.64  16544.12  16548.28   \n",
       "26272  2022-12-31 22:00:00  16548.28  16567.49  16470.00  16520.81   \n",
       "26273  2022-12-31 23:00:00  16520.28  16551.24  16487.74  16542.40   \n",
       "\n",
       "        Volume USDT  \n",
       "0      3.675857e+06  \n",
       "1      6.365953e+06  \n",
       "2      4.736719e+06  \n",
       "3      5.667367e+06  \n",
       "4      3.379094e+06  \n",
       "...             ...  \n",
       "26269  6.704605e+07  \n",
       "26270  4.344849e+07  \n",
       "26271  5.992803e+07  \n",
       "26272  1.106669e+08  \n",
       "26273  8.217183e+07  \n",
       "\n",
       "[26274 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss = Preprocessing.handle_missing_value(df)\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140ecfee-f8cf-45f6-b3c6-49e8e7458101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04750117, 0.0401654 , 0.05247223, 0.00122299, 0.04722846],\n",
       "       [0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "       [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "       ...,\n",
       "       [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245],\n",
       "       [0.19250079, 0.18570415, 0.19619691, 0.03681983, 0.19208658],\n",
       "       [0.19206671, 0.18545178, 0.19647123, 0.02733927, 0.19242129]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, scaler = Preprocessing.minmax_scale(miss)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42a7847-70b8-4487-a874-67e370666724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04750117, 0.0401654 , 0.05247223, 0.00122299, 0.04722846],\n",
       "       [0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "       [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "       ...,\n",
       "       [0.39451404, 0.38918512, 0.39751838, 0.01247029, 0.39344233],\n",
       "       [0.39342821, 0.38742771, 0.39264325, 0.02946575, 0.3886748 ],\n",
       "       [0.38866059, 0.38484765, 0.39034385, 0.03564371, 0.38670838]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = Preprocessing.splitting_data(x)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e525a6-83d0-4c8b-9875-33e0e15480ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38669404, 0.3808301 , 0.38809703, 0.0406164 , 0.38493033],\n",
       "       [0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "       [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "       ...,\n",
       "       [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245],\n",
       "       [0.19250079, 0.18570415, 0.19619691, 0.03681983, 0.19208658],\n",
       "       [0.19206671, 0.18545178, 0.19647123, 0.02733927, 0.19242129]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08213717-a303-4c9e-97bb-280204035109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = Preprocessing.create_dataset(train,50)\n",
    "test_X, test_y = Preprocessing.create_dataset(test,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff76bd7-16f2-4bf2-8a64-f1f6a1194661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.04750117, 0.0401654 , 0.05247223, 0.00122299, 0.04722846],\n",
       "        [0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "        [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "        ...,\n",
       "        [0.0440837 , 0.0367262 , 0.04898587, 0.00171689, 0.0439525 ],\n",
       "        [0.04393937, 0.03659683, 0.04841187, 0.00255609, 0.0435074 ],\n",
       "        [0.04349769, 0.03628001, 0.04787544, 0.00552241, 0.04276092]],\n",
       "\n",
       "       [[0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "        [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "        [0.04823632, 0.0409225 , 0.05316097, 0.00188558, 0.04797246],\n",
       "        ...,\n",
       "        [0.04393937, 0.03659683, 0.04841187, 0.00255609, 0.0435074 ],\n",
       "        [0.04349769, 0.03628001, 0.04787544, 0.00552241, 0.04276092],\n",
       "        [0.04274207, 0.03660196, 0.04776488, 0.00661765, 0.0438156 ]],\n",
       "\n",
       "       [[0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "        [0.04823632, 0.0409225 , 0.05316097, 0.00188558, 0.04797246],\n",
       "        [0.04796253, 0.04068955, 0.05308412, 0.00112425, 0.04785247],\n",
       "        ...,\n",
       "        [0.04349769, 0.03628001, 0.04787544, 0.00552241, 0.04276092],\n",
       "        [0.04274207, 0.03660196, 0.04776488, 0.00661765, 0.0438156 ],\n",
       "        [0.04381798, 0.03659512, 0.04883123, 0.00288294, 0.04374057]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.39161034, 0.38645737, 0.39382187, 0.01253338, 0.39273042],\n",
       "        [0.39271616, 0.38888026, 0.39639682, 0.01437157, 0.39464987],\n",
       "        [0.39463558, 0.38870182, 0.39817666, 0.01282607, 0.39494194],\n",
       "        ...,\n",
       "        [0.39492161, 0.38841109, 0.39572587, 0.02434051, 0.39144071],\n",
       "        [0.39142647, 0.3880059 , 0.39436169, 0.01783611, 0.39268484],\n",
       "        [0.39267058, 0.38939028, 0.39706577, 0.01464281, 0.39452832]],\n",
       "\n",
       "       [[0.39271616, 0.38888026, 0.39639682, 0.01437157, 0.39464987],\n",
       "        [0.39463558, 0.38870182, 0.39817666, 0.01282607, 0.39494194],\n",
       "        [0.39492765, 0.39192204, 0.398954  , 0.03097715, 0.39570129],\n",
       "        ...,\n",
       "        [0.39142647, 0.3880059 , 0.39436169, 0.01783611, 0.39268484],\n",
       "        [0.39267058, 0.38939028, 0.39706577, 0.01464281, 0.39452832],\n",
       "        [0.39451404, 0.38918512, 0.39751838, 0.01247029, 0.39344233]],\n",
       "\n",
       "       [[0.39463558, 0.38870182, 0.39817666, 0.01282607, 0.39494194],\n",
       "        [0.39492765, 0.39192204, 0.398954  , 0.03097715, 0.39570129],\n",
       "        [0.39568699, 0.3894847 , 0.39857128, 0.01219047, 0.39524596],\n",
       "        ...,\n",
       "        [0.39267058, 0.38939028, 0.39706577, 0.01464281, 0.39452832],\n",
       "        [0.39451404, 0.38918512, 0.39751838, 0.01247029, 0.39344233],\n",
       "        [0.39342821, 0.38742771, 0.39264325, 0.02946575, 0.3886748 ]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efa14c4-f85e-47c3-bc04-7f0d029d3a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0438156 , 0.04374057, 0.0477427 , ..., 0.39344233, 0.3886748 ,\n",
       "       0.38670838])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51dc56af-5903-45ab-a70b-556fb3f3d97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.38669404, 0.3808301 , 0.38809703, 0.0406164 , 0.38493033],\n",
       "        [0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "        [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        ...,\n",
       "        [0.38602478, 0.37948967, 0.38949337, 0.00759075, 0.38563804],\n",
       "        [0.38562372, 0.37916835, 0.3884063 , 0.00906337, 0.38440368],\n",
       "        [0.38438953, 0.3776341 , 0.38746628, 0.01179253, 0.38406695]],\n",
       "\n",
       "       [[0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "        [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        [0.38584929, 0.38055428, 0.38798971, 0.02809654, 0.38442601],\n",
       "        ...,\n",
       "        [0.38562372, 0.37916835, 0.3884063 , 0.00906337, 0.38440368],\n",
       "        [0.38438953, 0.3776341 , 0.38746628, 0.01179253, 0.38406695],\n",
       "        [0.38405265, 0.3787422 , 0.38803641, 0.0069225 , 0.38531015]],\n",
       "\n",
       "       [[0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        [0.38584929, 0.38055428, 0.38798971, 0.02809654, 0.38442601],\n",
       "        [0.38441201, 0.37958689, 0.38444598, 0.06968765, 0.38245246],\n",
       "        ...,\n",
       "        [0.38438953, 0.3776341 , 0.38746628, 0.01179253, 0.38406695],\n",
       "        [0.38405265, 0.3787422 , 0.38803641, 0.0069225 , 0.38531015],\n",
       "        [0.38529583, 0.37854201, 0.38863763, 0.00440172, 0.38463995]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.19382552, 0.18686256, 0.1980652 , 0.03789924, 0.19350651],\n",
       "        [0.19349484, 0.18649837, 0.19752011, 0.05415432, 0.19330249],\n",
       "        [0.19329082, 0.18644013, 0.19806427, 0.02648407, 0.19330714],\n",
       "        ...,\n",
       "        [0.19301503, 0.1860438 , 0.19777108, 0.01842876, 0.19296994],\n",
       "        [0.19295813, 0.18605467, 0.19766748, 0.02230679, 0.19285135],\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747]],\n",
       "\n",
       "       [[0.19349484, 0.18649837, 0.19752011, 0.05415432, 0.19330249],\n",
       "        [0.19329082, 0.18644013, 0.19806427, 0.02648407, 0.19330714],\n",
       "        [0.19329532, 0.18681472, 0.19813122, 0.03206729, 0.19361751],\n",
       "        ...,\n",
       "        [0.19295813, 0.18605467, 0.19766748, 0.02230679, 0.19285135],\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747],\n",
       "        [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245]],\n",
       "\n",
       "       [[0.19329082, 0.18644013, 0.19806427, 0.02648407, 0.19330714],\n",
       "        [0.19329532, 0.18681472, 0.19813122, 0.03206729, 0.19361751],\n",
       "        [0.19360584, 0.1870556 , 0.19839874, 0.03923131, 0.19383316],\n",
       "        ...,\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747],\n",
       "        [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245],\n",
       "        [0.19250079, 0.18570415, 0.19619691, 0.03681983, 0.19208658]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98152d5-e8c5-4645-90ea-876a042b25e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38531015, 0.38463995, 0.38622127, ..., 0.19251245, 0.19208658,\n",
       "       0.19242129])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80df0f9-fe70-44f0-bef3-b779d95da0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20969, 50, 5) (20969,) (5205, 50, 5) (5205,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43011a-1b18-4fef-b638-d84109a5347b",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6e3c5f-f40b-427b-bbf6-715de9fbfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 25, 50),\n",
       " (32, 25, 60),\n",
       " (32, 25, 100),\n",
       " (32, 50, 50),\n",
       " (32, 50, 60),\n",
       " (32, 50, 100),\n",
       " (32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100),\n",
       " (64, 25, 50),\n",
       " (64, 25, 60),\n",
       " (64, 25, 100),\n",
       " (64, 50, 50),\n",
       " (64, 50, 60),\n",
       " (64, 50, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100),\n",
       " (128, 25, 50),\n",
       " (128, 25, 60),\n",
       " (128, 25, 100),\n",
       " (128, 50, 50),\n",
       " (128, 50, 60),\n",
       " (128, 50, 100),\n",
       " (128, 100, 50),\n",
       " (128, 100, 60),\n",
       " (128, 100, 100)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = []\n",
    "batch = [32, 64, 128]\n",
    "epoch = [25, 50, 100]\n",
    "neuron = [50, 60, 100]\n",
    "for j in batch:\n",
    "    for k in epoch:\n",
    "        for l in neuron:\n",
    "            hyperparams.append((j,k,l))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c52fc162-d986-4cb9-9893-7619681dfc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 25, 50),\n",
       " (32, 25, 60),\n",
       " (32, 25, 100),\n",
       " (32, 50, 50),\n",
       " (32, 50, 60),\n",
       " (32, 50, 100),\n",
       " (32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam1 = hyperparams[:9]\n",
    "hyperparam2 = hyperparams[9:18]\n",
    "hyperparam3 = hyperparams[18:27]\n",
    "hyperparam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d42226bd-8cc7-4f34-bb16-195c46f1e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 25, 50),\n",
       " (64, 25, 60),\n",
       " (64, 25, 100),\n",
       " (64, 50, 50),\n",
       " (64, 50, 60),\n",
       " (64, 50, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed77be16-ab42-4b03-b115-2019aff75427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(128, 25, 50),\n",
       " (128, 25, 60),\n",
       " (128, 25, 100),\n",
       " (128, 50, 50),\n",
       " (128, 50, 60),\n",
       " (128, 50, 100),\n",
       " (128, 100, 50),\n",
       " (128, 100, 60),\n",
       " (128, 100, 100)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ffd8dc1-5eb8-4d7e-aba2-cab78df020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 08:50:09.923835: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-04 08:50:09.924141: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 08:50:10.212933: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-04-04 08:50:10.621401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:50:10.713467: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:50:11.260504: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:50:22.435570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:50:22.465241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 14s - loss: 3.8460e-04 - val_loss: 6.4969e-04 - 14s/epoch - 21ms/step\n",
      "Epoch 2/25\n",
      "656/656 - 11s - loss: 4.1427e-04 - val_loss: 3.2937e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 3/25\n",
      "656/656 - 11s - loss: 6.5358e-04 - val_loss: 7.4862e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 4/25\n",
      "656/656 - 11s - loss: 9.6728e-04 - val_loss: 0.0011 - 11s/epoch - 17ms/step\n",
      "Epoch 5/25\n",
      "656/656 - 11s - loss: 7.7478e-04 - val_loss: 7.5196e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 6/25\n",
      "656/656 - 11s - loss: 6.1291e-04 - val_loss: 4.5777e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 7/25\n",
      "656/656 - 11s - loss: 4.8931e-04 - val_loss: 2.5442e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 8/25\n",
      "656/656 - 11s - loss: 3.9912e-04 - val_loss: 1.3414e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 9/25\n",
      "656/656 - 11s - loss: 3.3603e-04 - val_loss: 7.3389e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 10/25\n",
      "656/656 - 11s - loss: 2.9157e-04 - val_loss: 4.7991e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 11/25\n",
      "656/656 - 11s - loss: 2.6078e-04 - val_loss: 3.9367e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 12/25\n",
      "656/656 - 11s - loss: 2.4246e-04 - val_loss: 3.9150e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 13/25\n",
      "656/656 - 11s - loss: 2.3258e-04 - val_loss: 4.1860e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 14/25\n",
      "656/656 - 12s - loss: 2.2781e-04 - val_loss: 4.7815e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 15/25\n",
      "656/656 - 13s - loss: 2.2883e-04 - val_loss: 5.1164e-05 - 13s/epoch - 20ms/step\n",
      "Epoch 16/25\n",
      "656/656 - 12s - loss: 2.1929e-04 - val_loss: 5.2140e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 17/25\n",
      "656/656 - 11s - loss: 2.1116e-04 - val_loss: 5.1291e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 18/25\n",
      "656/656 - 11s - loss: 2.0330e-04 - val_loss: 5.1104e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 19/25\n",
      "656/656 - 11s - loss: 1.9686e-04 - val_loss: 4.9512e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 20/25\n",
      "656/656 - 11s - loss: 1.9012e-04 - val_loss: 4.7482e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 21/25\n",
      "656/656 - 11s - loss: 1.8230e-04 - val_loss: 4.4549e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 22/25\n",
      "656/656 - 11s - loss: 1.7566e-04 - val_loss: 4.2820e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 23/25\n",
      "656/656 - 11s - loss: 1.6974e-04 - val_loss: 4.2440e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 24/25\n",
      "656/656 - 11s - loss: 1.6661e-04 - val_loss: 4.1425e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 25/25\n",
      "656/656 - 11s - loss: 1.6152e-04 - val_loss: 3.9411e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 08:54:58.258416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:54:58.340642: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:54:58.472623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:55:09.067486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:55:09.099837: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 1.4855e-04 - val_loss: 9.3905e-04 - 13s/epoch - 19ms/step\n",
      "Epoch 2/25\n",
      "656/656 - 12s - loss: 1.7020e-04 - val_loss: 5.6522e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 3/25\n",
      "656/656 - 13s - loss: 1.8219e-04 - val_loss: 3.8388e-04 - 13s/epoch - 20ms/step\n",
      "Epoch 4/25\n",
      "656/656 - 12s - loss: 2.2831e-04 - val_loss: 4.7629e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 5/25\n",
      "656/656 - 12s - loss: 3.4157e-04 - val_loss: 2.4862e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 6/25\n",
      "656/656 - 12s - loss: 5.3711e-04 - val_loss: 5.5946e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 7/25\n",
      "656/656 - 11s - loss: 8.3458e-04 - val_loss: 9.7987e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 8/25\n",
      "656/656 - 11s - loss: 7.2075e-04 - val_loss: 7.1573e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 9/25\n",
      "656/656 - 11s - loss: 5.8137e-04 - val_loss: 4.3060e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 10/25\n",
      "656/656 - 11s - loss: 4.6527e-04 - val_loss: 2.3863e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 11/25\n",
      "656/656 - 11s - loss: 3.8201e-04 - val_loss: 1.2402e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 12/25\n",
      "656/656 - 11s - loss: 3.2420e-04 - val_loss: 6.4876e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 13/25\n",
      "656/656 - 11s - loss: 2.8343e-04 - val_loss: 3.7855e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 14/25\n",
      "656/656 - 11s - loss: 2.5395e-04 - val_loss: 2.7339e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 15/25\n",
      "656/656 - 11s - loss: 2.3241e-04 - val_loss: 2.3812e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 16/25\n",
      "656/656 - 11s - loss: 2.1869e-04 - val_loss: 2.4106e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 17/25\n",
      "656/656 - 11s - loss: 2.0953e-04 - val_loss: 2.4090e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 18/25\n",
      "656/656 - 11s - loss: 2.0213e-04 - val_loss: 2.4874e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 19/25\n",
      "656/656 - 11s - loss: 1.9407e-04 - val_loss: 2.6126e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 20/25\n",
      "656/656 - 11s - loss: 1.9148e-04 - val_loss: 2.7293e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 21/25\n",
      "656/656 - 11s - loss: 1.8514e-04 - val_loss: 2.7727e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 22/25\n",
      "656/656 - 11s - loss: 1.7944e-04 - val_loss: 2.7665e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 23/25\n",
      "656/656 - 11s - loss: 1.7343e-04 - val_loss: 2.7510e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 24/25\n",
      "656/656 - 11s - loss: 1.6709e-04 - val_loss: 2.7382e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 25/25\n",
      "656/656 - 11s - loss: 1.6241e-04 - val_loss: 2.6695e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 08:59:43.580628: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:59:43.662462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:59:43.792205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:59:54.576350: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 08:59:54.606627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 2.3045e-04 - val_loss: 0.0013 - 13s/epoch - 20ms/step\n",
      "Epoch 2/25\n",
      "656/656 - 12s - loss: 2.3760e-04 - val_loss: 7.3789e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 3/25\n",
      "656/656 - 12s - loss: 2.1227e-04 - val_loss: 6.1522e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 4/25\n",
      "656/656 - 12s - loss: 2.8159e-04 - val_loss: 4.9415e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 5/25\n",
      "656/656 - 12s - loss: 3.5764e-04 - val_loss: 2.5948e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 6/25\n",
      "656/656 - 12s - loss: 5.0751e-04 - val_loss: 4.4566e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 7/25\n",
      "656/656 - 12s - loss: 8.5976e-04 - val_loss: 0.0011 - 12s/epoch - 18ms/step\n",
      "Epoch 8/25\n",
      "656/656 - 12s - loss: 8.5441e-04 - val_loss: 9.2403e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 9/25\n",
      "656/656 - 12s - loss: 7.1620e-04 - val_loss: 6.2501e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 10/25\n",
      "656/656 - 12s - loss: 5.7443e-04 - val_loss: 3.6960e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 11/25\n",
      "656/656 - 12s - loss: 4.5105e-04 - val_loss: 1.9733e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 12/25\n",
      "656/656 - 12s - loss: 3.6364e-04 - val_loss: 9.9151e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 13/25\n",
      "656/656 - 12s - loss: 3.0536e-04 - val_loss: 5.4133e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 14/25\n",
      "656/656 - 12s - loss: 2.6434e-04 - val_loss: 3.7040e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 15/25\n",
      "656/656 - 12s - loss: 2.3872e-04 - val_loss: 3.4329e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 16/25\n",
      "656/656 - 12s - loss: 2.2622e-04 - val_loss: 3.7857e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 17/25\n",
      "656/656 - 12s - loss: 2.2166e-04 - val_loss: 4.5128e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 18/25\n",
      "656/656 - 12s - loss: 2.2186e-04 - val_loss: 5.7282e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 19/25\n",
      "656/656 - 12s - loss: 2.2471e-04 - val_loss: 6.5846e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 20/25\n",
      "656/656 - 12s - loss: 2.1888e-04 - val_loss: 6.5387e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 21/25\n",
      "656/656 - 12s - loss: 2.0994e-04 - val_loss: 6.3001e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 22/25\n",
      "656/656 - 12s - loss: 1.9966e-04 - val_loss: 5.8419e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 23/25\n",
      "656/656 - 12s - loss: 1.8753e-04 - val_loss: 5.3408e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 24/25\n",
      "656/656 - 12s - loss: 1.7926e-04 - val_loss: 5.0042e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 25/25\n",
      "656/656 - 12s - loss: 1.7280e-04 - val_loss: 4.9503e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:04:36.258055: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:04:36.336312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:04:36.465653: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:04:47.046014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:04:47.076095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 4.1942e-04 - val_loss: 6.4029e-04 - 13s/epoch - 19ms/step\n",
      "Epoch 2/50\n",
      "656/656 - 11s - loss: 4.0011e-04 - val_loss: 3.6060e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 3/50\n",
      "656/656 - 11s - loss: 5.6573e-04 - val_loss: 6.8253e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 4/50\n",
      "656/656 - 12s - loss: 9.1112e-04 - val_loss: 0.0012 - 12s/epoch - 18ms/step\n",
      "Epoch 5/50\n",
      "656/656 - 11s - loss: 7.3015e-04 - val_loss: 8.3772e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "656/656 - 11s - loss: 5.5603e-04 - val_loss: 5.0267e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 7/50\n",
      "656/656 - 11s - loss: 4.3400e-04 - val_loss: 2.7623e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "656/656 - 11s - loss: 3.5214e-04 - val_loss: 1.5528e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "656/656 - 11s - loss: 2.9928e-04 - val_loss: 1.0225e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "656/656 - 11s - loss: 2.6718e-04 - val_loss: 8.5526e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 11/50\n",
      "656/656 - 11s - loss: 2.5154e-04 - val_loss: 8.4905e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "656/656 - 11s - loss: 2.4272e-04 - val_loss: 9.1149e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 13/50\n",
      "656/656 - 11s - loss: 2.3944e-04 - val_loss: 1.0117e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 14/50\n",
      "656/656 - 11s - loss: 2.3552e-04 - val_loss: 1.0700e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 15/50\n",
      "656/656 - 11s - loss: 2.2985e-04 - val_loss: 1.1285e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 16/50\n",
      "656/656 - 11s - loss: 2.2024e-04 - val_loss: 1.0993e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "656/656 - 11s - loss: 2.1277e-04 - val_loss: 1.0332e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 18/50\n",
      "656/656 - 11s - loss: 1.9994e-04 - val_loss: 9.1877e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "656/656 - 11s - loss: 1.8887e-04 - val_loss: 8.5740e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "656/656 - 11s - loss: 1.8126e-04 - val_loss: 8.1558e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 21/50\n",
      "656/656 - 11s - loss: 1.7259e-04 - val_loss: 7.8685e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 22/50\n",
      "656/656 - 11s - loss: 1.6977e-04 - val_loss: 7.7740e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "656/656 - 11s - loss: 1.6859e-04 - val_loss: 7.4259e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "656/656 - 11s - loss: 1.6496e-04 - val_loss: 7.3465e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 25/50\n",
      "656/656 - 11s - loss: 1.5856e-04 - val_loss: 6.6062e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 26/50\n",
      "656/656 - 11s - loss: 1.5122e-04 - val_loss: 5.9998e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "656/656 - 11s - loss: 1.4544e-04 - val_loss: 6.1227e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "656/656 - 11s - loss: 1.4140e-04 - val_loss: 5.7763e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 29/50\n",
      "656/656 - 11s - loss: 1.4035e-04 - val_loss: 5.8000e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 30/50\n",
      "656/656 - 12s - loss: 1.3835e-04 - val_loss: 5.5589e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 31/50\n",
      "656/656 - 11s - loss: 1.3749e-04 - val_loss: 6.5474e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 32/50\n",
      "656/656 - 11s - loss: 1.3398e-04 - val_loss: 5.5661e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 33/50\n",
      "656/656 - 12s - loss: 1.2983e-04 - val_loss: 5.3326e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 34/50\n",
      "656/656 - 12s - loss: 1.2554e-04 - val_loss: 4.7143e-05 - 12s/epoch - 19ms/step\n",
      "Epoch 35/50\n",
      "656/656 - 12s - loss: 1.2343e-04 - val_loss: 4.8870e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 36/50\n",
      "656/656 - 11s - loss: 1.2174e-04 - val_loss: 4.9656e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 37/50\n",
      "656/656 - 12s - loss: 1.2008e-04 - val_loss: 5.0426e-05 - 12s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "656/656 - 12s - loss: 1.1853e-04 - val_loss: 4.7313e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 39/50\n",
      "656/656 - 12s - loss: 1.1698e-04 - val_loss: 4.7821e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 40/50\n",
      "656/656 - 12s - loss: 1.1612e-04 - val_loss: 4.4672e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 41/50\n",
      "656/656 - 12s - loss: 1.1302e-04 - val_loss: 4.5737e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 42/50\n",
      "656/656 - 11s - loss: 1.1154e-04 - val_loss: 4.3641e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 43/50\n",
      "656/656 - 11s - loss: 1.0891e-04 - val_loss: 4.2384e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 44/50\n",
      "656/656 - 11s - loss: 1.0676e-04 - val_loss: 4.2249e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 45/50\n",
      "656/656 - 11s - loss: 1.0672e-04 - val_loss: 4.0332e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "656/656 - 11s - loss: 1.0540e-04 - val_loss: 4.2209e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 47/50\n",
      "656/656 - 11s - loss: 1.0462e-04 - val_loss: 4.1452e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 48/50\n",
      "656/656 - 11s - loss: 1.0250e-04 - val_loss: 4.0678e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "656/656 - 11s - loss: 1.0036e-04 - val_loss: 3.7839e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "656/656 - 11s - loss: 9.8950e-05 - val_loss: 3.8086e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:14:12.207537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:14:12.284756: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:14:12.420838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:14:22.851936: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:14:22.881854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 2.7013e-04 - val_loss: 6.7617e-04 - 13s/epoch - 19ms/step\n",
      "Epoch 2/50\n",
      "656/656 - 11s - loss: 2.5353e-04 - val_loss: 5.5015e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 3/50\n",
      "656/656 - 11s - loss: 3.7266e-04 - val_loss: 2.7393e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 4/50\n",
      "656/656 - 11s - loss: 5.6914e-04 - val_loss: 6.0003e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 5/50\n",
      "656/656 - 11s - loss: 9.7293e-04 - val_loss: 0.0013 - 11s/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "656/656 - 11s - loss: 8.6037e-04 - val_loss: 9.5019e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 7/50\n",
      "656/656 - 11s - loss: 7.0676e-04 - val_loss: 6.1857e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "656/656 - 11s - loss: 5.6461e-04 - val_loss: 3.6537e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "656/656 - 11s - loss: 4.6074e-04 - val_loss: 2.0712e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "656/656 - 11s - loss: 3.8504e-04 - val_loss: 1.1408e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 11/50\n",
      "656/656 - 11s - loss: 3.3135e-04 - val_loss: 6.5447e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "656/656 - 11s - loss: 2.9115e-04 - val_loss: 4.2660e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 13/50\n",
      "656/656 - 11s - loss: 2.6236e-04 - val_loss: 3.4161e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 14/50\n",
      "656/656 - 11s - loss: 2.4062e-04 - val_loss: 3.1300e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 15/50\n",
      "656/656 - 11s - loss: 2.2579e-04 - val_loss: 3.1354e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 16/50\n",
      "656/656 - 11s - loss: 2.1755e-04 - val_loss: 3.3648e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "656/656 - 11s - loss: 2.1124e-04 - val_loss: 3.7811e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 18/50\n",
      "656/656 - 11s - loss: 2.0751e-04 - val_loss: 4.0098e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "656/656 - 11s - loss: 2.0095e-04 - val_loss: 4.0900e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "656/656 - 11s - loss: 1.9311e-04 - val_loss: 4.0885e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 21/50\n",
      "656/656 - 11s - loss: 1.8610e-04 - val_loss: 4.0509e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 22/50\n",
      "656/656 - 11s - loss: 1.8029e-04 - val_loss: 3.9872e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "656/656 - 11s - loss: 1.7434e-04 - val_loss: 3.8964e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "656/656 - 11s - loss: 1.6921e-04 - val_loss: 3.8950e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "656/656 - 11s - loss: 1.6420e-04 - val_loss: 3.9208e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 26/50\n",
      "656/656 - 11s - loss: 1.6153e-04 - val_loss: 3.8991e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "656/656 - 11s - loss: 1.5650e-04 - val_loss: 3.7745e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "656/656 - 11s - loss: 1.5131e-04 - val_loss: 3.7344e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 29/50\n",
      "656/656 - 11s - loss: 1.4820e-04 - val_loss: 3.7700e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 30/50\n",
      "656/656 - 11s - loss: 1.4556e-04 - val_loss: 3.7208e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 31/50\n",
      "656/656 - 11s - loss: 1.4235e-04 - val_loss: 3.8267e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 32/50\n",
      "656/656 - 11s - loss: 1.4016e-04 - val_loss: 3.7512e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 33/50\n",
      "656/656 - 11s - loss: 1.3702e-04 - val_loss: 3.7729e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 34/50\n",
      "656/656 - 11s - loss: 1.3432e-04 - val_loss: 3.6470e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 35/50\n",
      "656/656 - 11s - loss: 1.3103e-04 - val_loss: 3.5775e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 36/50\n",
      "656/656 - 11s - loss: 1.2866e-04 - val_loss: 3.5969e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 37/50\n",
      "656/656 - 11s - loss: 1.2638e-04 - val_loss: 3.6179e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 38/50\n",
      "656/656 - 11s - loss: 1.2474e-04 - val_loss: 3.6873e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "656/656 - 11s - loss: 1.2302e-04 - val_loss: 3.7084e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 40/50\n",
      "656/656 - 11s - loss: 1.2139e-04 - val_loss: 3.6669e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 41/50\n",
      "656/656 - 11s - loss: 1.1911e-04 - val_loss: 3.6435e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 42/50\n",
      "656/656 - 11s - loss: 1.1741e-04 - val_loss: 3.6146e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 43/50\n",
      "656/656 - 11s - loss: 1.1531e-04 - val_loss: 3.6417e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 44/50\n",
      "656/656 - 11s - loss: 1.1398e-04 - val_loss: 3.5875e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 45/50\n",
      "656/656 - 11s - loss: 1.1198e-04 - val_loss: 3.5820e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "656/656 - 11s - loss: 1.1095e-04 - val_loss: 3.5841e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 47/50\n",
      "656/656 - 11s - loss: 1.0940e-04 - val_loss: 3.6154e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 48/50\n",
      "656/656 - 11s - loss: 1.0847e-04 - val_loss: 3.6182e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "656/656 - 11s - loss: 1.0676e-04 - val_loss: 3.5987e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "656/656 - 11s - loss: 1.0567e-04 - val_loss: 3.5976e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:23:39.290916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:23:39.367416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:23:39.499249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:23:50.213852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:23:50.244040: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 1.8314e-04 - val_loss: 0.0010 - 13s/epoch - 20ms/step\n",
      "Epoch 2/50\n",
      "656/656 - 12s - loss: 1.9442e-04 - val_loss: 9.0485e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 3/50\n",
      "656/656 - 12s - loss: 2.1706e-04 - val_loss: 5.9157e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 4/50\n",
      "656/656 - 12s - loss: 2.3453e-04 - val_loss: 6.4356e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 5/50\n",
      "656/656 - 12s - loss: 3.3006e-04 - val_loss: 2.8797e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 6/50\n",
      "656/656 - 12s - loss: 3.9651e-04 - val_loss: 2.5444e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 7/50\n",
      "656/656 - 12s - loss: 6.7035e-04 - val_loss: 7.4278e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 8/50\n",
      "656/656 - 12s - loss: 8.7050e-04 - val_loss: 0.0010 - 12s/epoch - 18ms/step\n",
      "Epoch 9/50\n",
      "656/656 - 12s - loss: 7.8033e-04 - val_loss: 7.8873e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 10/50\n",
      "656/656 - 12s - loss: 6.2058e-04 - val_loss: 4.9442e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 11/50\n",
      "656/656 - 12s - loss: 4.8446e-04 - val_loss: 2.7137e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 12/50\n",
      "656/656 - 12s - loss: 3.8502e-04 - val_loss: 1.3804e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 13/50\n",
      "656/656 - 12s - loss: 3.1843e-04 - val_loss: 7.3290e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 14/50\n",
      "656/656 - 12s - loss: 2.7271e-04 - val_loss: 4.6939e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 15/50\n",
      "656/656 - 12s - loss: 2.4016e-04 - val_loss: 3.8668e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 16/50\n",
      "656/656 - 12s - loss: 2.2250e-04 - val_loss: 4.1436e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 17/50\n",
      "656/656 - 12s - loss: 2.1462e-04 - val_loss: 4.9238e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 18/50\n",
      "656/656 - 12s - loss: 2.1326e-04 - val_loss: 6.2606e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 19/50\n",
      "656/656 - 12s - loss: 2.1692e-04 - val_loss: 7.6880e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 20/50\n",
      "656/656 - 12s - loss: 2.1734e-04 - val_loss: 8.5364e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 21/50\n",
      "656/656 - 12s - loss: 2.1285e-04 - val_loss: 8.5580e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 22/50\n",
      "656/656 - 12s - loss: 2.0484e-04 - val_loss: 7.8408e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 23/50\n",
      "656/656 - 12s - loss: 1.8998e-04 - val_loss: 6.4912e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 24/50\n",
      "656/656 - 12s - loss: 1.7705e-04 - val_loss: 5.7744e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 25/50\n",
      "656/656 - 12s - loss: 1.6791e-04 - val_loss: 5.4101e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 26/50\n",
      "656/656 - 12s - loss: 1.6241e-04 - val_loss: 5.4817e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 27/50\n",
      "656/656 - 12s - loss: 1.5983e-04 - val_loss: 5.7001e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 28/50\n",
      "656/656 - 12s - loss: 1.5800e-04 - val_loss: 6.1272e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 29/50\n",
      "656/656 - 12s - loss: 1.5693e-04 - val_loss: 6.3944e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 30/50\n",
      "656/656 - 12s - loss: 1.5373e-04 - val_loss: 6.2714e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 31/50\n",
      "656/656 - 12s - loss: 1.4885e-04 - val_loss: 5.7671e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 32/50\n",
      "656/656 - 12s - loss: 1.4334e-04 - val_loss: 5.4353e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 33/50\n",
      "656/656 - 12s - loss: 1.3846e-04 - val_loss: 5.2375e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 34/50\n",
      "656/656 - 12s - loss: 1.3470e-04 - val_loss: 5.1881e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 35/50\n",
      "656/656 - 12s - loss: 1.3148e-04 - val_loss: 5.3359e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 36/50\n",
      "656/656 - 12s - loss: 1.3144e-04 - val_loss: 5.5180e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 37/50\n",
      "656/656 - 12s - loss: 1.2805e-04 - val_loss: 5.4072e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 38/50\n",
      "656/656 - 12s - loss: 1.2643e-04 - val_loss: 5.2577e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 39/50\n",
      "656/656 - 12s - loss: 1.2303e-04 - val_loss: 5.0915e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 40/50\n",
      "656/656 - 12s - loss: 1.2023e-04 - val_loss: 5.0425e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 41/50\n",
      "656/656 - 12s - loss: 1.1877e-04 - val_loss: 5.1112e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 42/50\n",
      "656/656 - 12s - loss: 1.1769e-04 - val_loss: 5.1163e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 43/50\n",
      "656/656 - 12s - loss: 1.1662e-04 - val_loss: 5.1448e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 44/50\n",
      "656/656 - 12s - loss: 1.1515e-04 - val_loss: 5.1231e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 45/50\n",
      "656/656 - 12s - loss: 1.1348e-04 - val_loss: 5.0248e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 46/50\n",
      "656/656 - 12s - loss: 1.1142e-04 - val_loss: 4.9240e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 47/50\n",
      "656/656 - 12s - loss: 1.0942e-04 - val_loss: 4.7949e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 48/50\n",
      "656/656 - 12s - loss: 1.0768e-04 - val_loss: 4.7042e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 49/50\n",
      "656/656 - 12s - loss: 1.0624e-04 - val_loss: 4.6596e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 50/50\n",
      "656/656 - 12s - loss: 1.0518e-04 - val_loss: 4.6780e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:33:24.284608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:33:24.361114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:33:24.494021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:33:35.082047: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:33:35.112468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 3.0649e-04 - val_loss: 9.9224e-04 - 13s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "656/656 - 11s - loss: 2.3773e-04 - val_loss: 6.1332e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "656/656 - 12s - loss: 3.0463e-04 - val_loss: 3.3892e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "656/656 - 12s - loss: 3.8853e-04 - val_loss: 3.3496e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "656/656 - 11s - loss: 6.6186e-04 - val_loss: 8.6632e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "656/656 - 11s - loss: 7.7856e-04 - val_loss: 8.7800e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "656/656 - 11s - loss: 6.0946e-04 - val_loss: 5.6869e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "656/656 - 11s - loss: 4.7132e-04 - val_loss: 3.1347e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "656/656 - 11s - loss: 3.7302e-04 - val_loss: 1.5757e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "656/656 - 11s - loss: 3.0753e-04 - val_loss: 8.1470e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "656/656 - 11s - loss: 2.6408e-04 - val_loss: 5.1418e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "656/656 - 12s - loss: 2.3766e-04 - val_loss: 4.3258e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 13/100\n",
      "656/656 - 11s - loss: 2.2478e-04 - val_loss: 4.5589e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "656/656 - 11s - loss: 2.2071e-04 - val_loss: 5.0617e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "656/656 - 12s - loss: 2.1927e-04 - val_loss: 5.6927e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 16/100\n",
      "656/656 - 11s - loss: 2.1620e-04 - val_loss: 5.8797e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "656/656 - 11s - loss: 2.0745e-04 - val_loss: 5.8470e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "656/656 - 11s - loss: 1.9854e-04 - val_loss: 5.6109e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "656/656 - 11s - loss: 1.8956e-04 - val_loss: 5.3453e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "656/656 - 11s - loss: 1.8143e-04 - val_loss: 5.1742e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "656/656 - 11s - loss: 1.7892e-04 - val_loss: 5.3288e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "656/656 - 11s - loss: 1.7763e-04 - val_loss: 5.1527e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "656/656 - 11s - loss: 1.6940e-04 - val_loss: 4.7261e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 24/100\n",
      "656/656 - 11s - loss: 1.6270e-04 - val_loss: 4.3781e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "656/656 - 11s - loss: 1.5477e-04 - val_loss: 4.0075e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "656/656 - 11s - loss: 1.5053e-04 - val_loss: 4.0266e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "656/656 - 11s - loss: 1.4880e-04 - val_loss: 4.1265e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "656/656 - 11s - loss: 1.4801e-04 - val_loss: 4.2156e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "656/656 - 11s - loss: 1.4588e-04 - val_loss: 4.0678e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "656/656 - 11s - loss: 1.4178e-04 - val_loss: 3.8617e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "656/656 - 11s - loss: 1.3705e-04 - val_loss: 3.6060e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "656/656 - 11s - loss: 1.3273e-04 - val_loss: 3.5505e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "656/656 - 12s - loss: 1.3050e-04 - val_loss: 3.7090e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "656/656 - 11s - loss: 1.3016e-04 - val_loss: 3.7214e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "656/656 - 12s - loss: 1.2832e-04 - val_loss: 3.5558e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 36/100\n",
      "656/656 - 11s - loss: 1.2618e-04 - val_loss: 3.5298e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "656/656 - 11s - loss: 1.2295e-04 - val_loss: 3.3901e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "656/656 - 11s - loss: 1.2012e-04 - val_loss: 3.4349e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "656/656 - 11s - loss: 1.1824e-04 - val_loss: 3.4634e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "656/656 - 11s - loss: 1.1721e-04 - val_loss: 3.5045e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "656/656 - 12s - loss: 1.1627e-04 - val_loss: 3.3383e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 42/100\n",
      "656/656 - 11s - loss: 1.1473e-04 - val_loss: 3.3327e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "656/656 - 11s - loss: 1.1304e-04 - val_loss: 3.2655e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "656/656 - 11s - loss: 1.1071e-04 - val_loss: 3.2915e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "656/656 - 11s - loss: 1.0903e-04 - val_loss: 3.2555e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "656/656 - 11s - loss: 1.0744e-04 - val_loss: 3.2206e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "656/656 - 11s - loss: 1.0605e-04 - val_loss: 3.1490e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "656/656 - 11s - loss: 1.0483e-04 - val_loss: 3.1956e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "656/656 - 11s - loss: 1.0403e-04 - val_loss: 3.2224e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "656/656 - 11s - loss: 1.0291e-04 - val_loss: 3.2118e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "656/656 - 11s - loss: 1.0167e-04 - val_loss: 3.2056e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "656/656 - 11s - loss: 1.0045e-04 - val_loss: 3.1210e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "656/656 - 11s - loss: 9.9228e-05 - val_loss: 3.1078e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 54/100\n",
      "656/656 - 11s - loss: 9.8221e-05 - val_loss: 3.1133e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "656/656 - 11s - loss: 9.7196e-05 - val_loss: 3.1268e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "656/656 - 11s - loss: 9.6104e-05 - val_loss: 3.1098e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "656/656 - 11s - loss: 9.5016e-05 - val_loss: 3.0991e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "656/656 - 11s - loss: 9.4108e-05 - val_loss: 3.0897e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "656/656 - 11s - loss: 9.3185e-05 - val_loss: 3.0982e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "656/656 - 11s - loss: 9.2510e-05 - val_loss: 3.1035e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "656/656 - 11s - loss: 9.1622e-05 - val_loss: 3.1116e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "656/656 - 11s - loss: 9.0866e-05 - val_loss: 3.0781e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "656/656 - 11s - loss: 8.9784e-05 - val_loss: 3.0687e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "656/656 - 11s - loss: 8.9058e-05 - val_loss: 3.0486e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "656/656 - 11s - loss: 8.8076e-05 - val_loss: 3.0620e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "656/656 - 11s - loss: 8.7444e-05 - val_loss: 3.0606e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "656/656 - 11s - loss: 8.6783e-05 - val_loss: 3.0676e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "656/656 - 11s - loss: 8.6267e-05 - val_loss: 3.0628e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "656/656 - 11s - loss: 8.5564e-05 - val_loss: 3.0576e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "656/656 - 11s - loss: 8.4749e-05 - val_loss: 3.0397e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "656/656 - 11s - loss: 8.3962e-05 - val_loss: 3.0473e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "656/656 - 11s - loss: 8.3290e-05 - val_loss: 3.0345e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "656/656 - 11s - loss: 8.2523e-05 - val_loss: 3.0514e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "656/656 - 11s - loss: 8.1944e-05 - val_loss: 3.0545e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 75/100\n",
      "656/656 - 11s - loss: 8.1294e-05 - val_loss: 3.0749e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 76/100\n",
      "656/656 - 11s - loss: 8.0862e-05 - val_loss: 3.0731e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "656/656 - 11s - loss: 8.0202e-05 - val_loss: 3.0929e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "656/656 - 11s - loss: 7.9624e-05 - val_loss: 3.0909e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 79/100\n",
      "656/656 - 11s - loss: 7.8930e-05 - val_loss: 3.1143e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 80/100\n",
      "656/656 - 11s - loss: 7.8452e-05 - val_loss: 3.1216e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "656/656 - 12s - loss: 7.7718e-05 - val_loss: 3.1576e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 82/100\n",
      "656/656 - 11s - loss: 7.7331e-05 - val_loss: 3.1807e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 83/100\n",
      "656/656 - 11s - loss: 7.6715e-05 - val_loss: 3.2260e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 84/100\n",
      "656/656 - 11s - loss: 7.6390e-05 - val_loss: 3.2592e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "656/656 - 11s - loss: 7.5812e-05 - val_loss: 3.3092e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "656/656 - 12s - loss: 7.5442e-05 - val_loss: 3.3480e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 87/100\n",
      "656/656 - 11s - loss: 7.4825e-05 - val_loss: 3.4056e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "656/656 - 11s - loss: 7.4409e-05 - val_loss: 3.4511e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "656/656 - 11s - loss: 7.3846e-05 - val_loss: 3.5169e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "656/656 - 11s - loss: 7.3479e-05 - val_loss: 3.5665e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "656/656 - 11s - loss: 7.2978e-05 - val_loss: 3.6331e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 92/100\n",
      "656/656 - 11s - loss: 7.2635e-05 - val_loss: 3.6724e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "656/656 - 11s - loss: 7.2151e-05 - val_loss: 3.7273e-05 - 11s/epoch - 18ms/step\n",
      "Epoch 94/100\n",
      "656/656 - 11s - loss: 7.1796e-05 - val_loss: 3.7504e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "656/656 - 11s - loss: 7.1337e-05 - val_loss: 3.7911e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "656/656 - 11s - loss: 7.0982e-05 - val_loss: 3.7911e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "656/656 - 11s - loss: 7.0551e-05 - val_loss: 3.8116e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "656/656 - 11s - loss: 7.0205e-05 - val_loss: 3.7914e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "656/656 - 11s - loss: 6.9787e-05 - val_loss: 3.7910e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "656/656 - 11s - loss: 6.9447e-05 - val_loss: 3.7520e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:52:30.461623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:52:30.538582: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:52:30.680488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:52:41.217030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 09:52:41.248084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 2.2721e-04 - val_loss: 7.5822e-04 - 13s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "656/656 - 11s - loss: 1.9450e-04 - val_loss: 4.2394e-04 - 11s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "656/656 - 11s - loss: 2.1412e-04 - val_loss: 4.9800e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "656/656 - 11s - loss: 3.1854e-04 - val_loss: 2.7560e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "656/656 - 11s - loss: 4.2329e-04 - val_loss: 3.6375e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "656/656 - 11s - loss: 7.5812e-04 - val_loss: 0.0010 - 11s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "656/656 - 11s - loss: 8.0240e-04 - val_loss: 9.1195e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "656/656 - 11s - loss: 6.4138e-04 - val_loss: 5.7605e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "656/656 - 11s - loss: 4.9755e-04 - val_loss: 3.2146e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "656/656 - 11s - loss: 3.9703e-04 - val_loss: 1.6265e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "656/656 - 11s - loss: 3.2556e-04 - val_loss: 8.0145e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "656/656 - 11s - loss: 2.7760e-04 - val_loss: 4.5870e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "656/656 - 11s - loss: 2.4548e-04 - val_loss: 3.4820e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "656/656 - 11s - loss: 2.2611e-04 - val_loss: 3.4117e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "656/656 - 11s - loss: 2.1707e-04 - val_loss: 3.7134e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "656/656 - 11s - loss: 2.1267e-04 - val_loss: 4.3649e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "656/656 - 11s - loss: 2.1331e-04 - val_loss: 5.1117e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "656/656 - 11s - loss: 2.1319e-04 - val_loss: 5.6262e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "656/656 - 11s - loss: 2.0746e-04 - val_loss: 5.3433e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "656/656 - 11s - loss: 1.9307e-04 - val_loss: 4.6942e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "656/656 - 11s - loss: 1.8120e-04 - val_loss: 4.3409e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "656/656 - 11s - loss: 1.7297e-04 - val_loss: 4.0327e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "656/656 - 11s - loss: 1.6614e-04 - val_loss: 3.9984e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "656/656 - 11s - loss: 1.6228e-04 - val_loss: 4.0009e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "656/656 - 11s - loss: 1.5885e-04 - val_loss: 4.2813e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "656/656 - 11s - loss: 1.5748e-04 - val_loss: 4.1537e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "656/656 - 11s - loss: 1.5331e-04 - val_loss: 4.2365e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "656/656 - 11s - loss: 1.5037e-04 - val_loss: 4.1551e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "656/656 - 12s - loss: 1.4493e-04 - val_loss: 3.8938e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 30/100\n",
      "656/656 - 11s - loss: 1.4126e-04 - val_loss: 3.8177e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "656/656 - 11s - loss: 1.3901e-04 - val_loss: 3.7105e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "656/656 - 11s - loss: 1.3521e-04 - val_loss: 3.5675e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "656/656 - 11s - loss: 1.3136e-04 - val_loss: 3.5703e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "656/656 - 11s - loss: 1.2883e-04 - val_loss: 3.5277e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "656/656 - 11s - loss: 1.2710e-04 - val_loss: 3.5850e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "656/656 - 11s - loss: 1.2570e-04 - val_loss: 3.4871e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "656/656 - 11s - loss: 1.2349e-04 - val_loss: 3.5935e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "656/656 - 11s - loss: 1.2179e-04 - val_loss: 3.4477e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "656/656 - 11s - loss: 1.1896e-04 - val_loss: 3.5034e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "656/656 - 11s - loss: 1.1743e-04 - val_loss: 3.4298e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "656/656 - 11s - loss: 1.1514e-04 - val_loss: 3.4003e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "656/656 - 11s - loss: 1.1357e-04 - val_loss: 3.2560e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "656/656 - 11s - loss: 1.1176e-04 - val_loss: 3.3982e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "656/656 - 11s - loss: 1.1073e-04 - val_loss: 3.2912e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "656/656 - 11s - loss: 1.0902e-04 - val_loss: 3.3781e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "656/656 - 11s - loss: 1.0758e-04 - val_loss: 3.2291e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "656/656 - 11s - loss: 1.0539e-04 - val_loss: 3.2191e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "656/656 - 11s - loss: 1.0396e-04 - val_loss: 3.1491e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "656/656 - 11s - loss: 1.0292e-04 - val_loss: 3.2642e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "656/656 - 11s - loss: 1.0196e-04 - val_loss: 3.1408e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "656/656 - 11s - loss: 1.0022e-04 - val_loss: 3.1823e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "656/656 - 11s - loss: 9.9109e-05 - val_loss: 3.1029e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "656/656 - 11s - loss: 9.7805e-05 - val_loss: 3.2000e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 54/100\n",
      "656/656 - 11s - loss: 9.6928e-05 - val_loss: 3.1800e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "656/656 - 11s - loss: 9.6137e-05 - val_loss: 3.2665e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "656/656 - 11s - loss: 9.5566e-05 - val_loss: 3.1875e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "656/656 - 11s - loss: 9.3893e-05 - val_loss: 3.1604e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "656/656 - 11s - loss: 9.2586e-05 - val_loss: 3.0901e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "656/656 - 11s - loss: 9.1272e-05 - val_loss: 3.1711e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "656/656 - 11s - loss: 9.0503e-05 - val_loss: 3.1116e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "656/656 - 11s - loss: 8.9524e-05 - val_loss: 3.2197e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "656/656 - 11s - loss: 8.8960e-05 - val_loss: 3.1582e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "656/656 - 11s - loss: 8.8130e-05 - val_loss: 3.2644e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "656/656 - 11s - loss: 8.7612e-05 - val_loss: 3.2104e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "656/656 - 11s - loss: 8.6968e-05 - val_loss: 3.2882e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "656/656 - 11s - loss: 8.6134e-05 - val_loss: 3.2320e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "656/656 - 11s - loss: 8.5264e-05 - val_loss: 3.2690e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "656/656 - 11s - loss: 8.4324e-05 - val_loss: 3.1943e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "656/656 - 11s - loss: 8.3618e-05 - val_loss: 3.2643e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "656/656 - 11s - loss: 8.3091e-05 - val_loss: 3.2239e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "656/656 - 11s - loss: 8.2470e-05 - val_loss: 3.3305e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "656/656 - 11s - loss: 8.1923e-05 - val_loss: 3.2759e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "656/656 - 11s - loss: 8.1244e-05 - val_loss: 3.3446e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "656/656 - 11s - loss: 8.0525e-05 - val_loss: 3.2945e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "656/656 - 11s - loss: 7.9929e-05 - val_loss: 3.3651e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 76/100\n",
      "656/656 - 11s - loss: 7.9387e-05 - val_loss: 3.3449e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "656/656 - 11s - loss: 7.8907e-05 - val_loss: 3.4344e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "656/656 - 11s - loss: 7.8357e-05 - val_loss: 3.4034e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 79/100\n",
      "656/656 - 11s - loss: 7.7829e-05 - val_loss: 3.4760e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 80/100\n",
      "656/656 - 11s - loss: 7.7202e-05 - val_loss: 3.4485e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "656/656 - 11s - loss: 7.6726e-05 - val_loss: 3.5309e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 82/100\n",
      "656/656 - 11s - loss: 7.6181e-05 - val_loss: 3.5039e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 83/100\n",
      "656/656 - 11s - loss: 7.5854e-05 - val_loss: 3.5772e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 84/100\n",
      "656/656 - 11s - loss: 7.5403e-05 - val_loss: 3.5470e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "656/656 - 11s - loss: 7.4919e-05 - val_loss: 3.6154e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "656/656 - 11s - loss: 7.4403e-05 - val_loss: 3.5962e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "656/656 - 11s - loss: 7.3908e-05 - val_loss: 3.6604e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "656/656 - 11s - loss: 7.3439e-05 - val_loss: 3.6449e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "656/656 - 11s - loss: 7.3063e-05 - val_loss: 3.7170e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "656/656 - 11s - loss: 7.2636e-05 - val_loss: 3.7099e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "656/656 - 11s - loss: 7.2339e-05 - val_loss: 3.7659e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "656/656 - 11s - loss: 7.2001e-05 - val_loss: 3.7711e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 93/100\n",
      "656/656 - 11s - loss: 7.1617e-05 - val_loss: 3.8220e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "656/656 - 11s - loss: 7.1112e-05 - val_loss: 3.7982e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "656/656 - 11s - loss: 7.0674e-05 - val_loss: 3.8515e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "656/656 - 11s - loss: 7.0270e-05 - val_loss: 3.8614e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "656/656 - 11s - loss: 7.0001e-05 - val_loss: 3.9170e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "656/656 - 11s - loss: 6.9655e-05 - val_loss: 3.9228e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "656/656 - 11s - loss: 6.9411e-05 - val_loss: 3.9662e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "656/656 - 11s - loss: 6.9053e-05 - val_loss: 3.9659e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:11:22.898039: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:11:22.975828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:11:23.126876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:11:33.972513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:11:34.002971: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 - 13s - loss: 1.5476e-04 - val_loss: 0.0013 - 13s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "656/656 - 12s - loss: 1.7646e-04 - val_loss: 8.6618e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "656/656 - 12s - loss: 2.0476e-04 - val_loss: 6.9069e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "656/656 - 12s - loss: 1.8908e-04 - val_loss: 5.2377e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "656/656 - 12s - loss: 2.1672e-04 - val_loss: 5.5782e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "656/656 - 12s - loss: 2.9734e-04 - val_loss: 2.9551e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "656/656 - 12s - loss: 3.5274e-04 - val_loss: 2.4491e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 8/100\n",
      "656/656 - 12s - loss: 5.4066e-04 - val_loss: 5.7944e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "656/656 - 12s - loss: 8.2157e-04 - val_loss: 0.0011 - 12s/epoch - 18ms/step\n",
      "Epoch 10/100\n",
      "656/656 - 12s - loss: 7.5176e-04 - val_loss: 8.5070e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "656/656 - 12s - loss: 6.0153e-04 - val_loss: 5.4172e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 12/100\n",
      "656/656 - 12s - loss: 4.6872e-04 - val_loss: 2.9790e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 13/100\n",
      "656/656 - 12s - loss: 3.6739e-04 - val_loss: 1.5167e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 14/100\n",
      "656/656 - 12s - loss: 3.0437e-04 - val_loss: 8.4576e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 15/100\n",
      "656/656 - 12s - loss: 2.6286e-04 - val_loss: 5.8358e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 16/100\n",
      "656/656 - 12s - loss: 2.3624e-04 - val_loss: 5.2364e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "656/656 - 12s - loss: 2.2174e-04 - val_loss: 5.8369e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "656/656 - 12s - loss: 2.1822e-04 - val_loss: 7.1283e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 19/100\n",
      "656/656 - 12s - loss: 2.2035e-04 - val_loss: 8.9095e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "656/656 - 12s - loss: 2.2501e-04 - val_loss: 1.0510e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 21/100\n",
      "656/656 - 12s - loss: 2.2592e-04 - val_loss: 1.1148e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 22/100\n",
      "656/656 - 12s - loss: 2.1981e-04 - val_loss: 1.0218e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 23/100\n",
      "656/656 - 12s - loss: 2.0743e-04 - val_loss: 8.7326e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 24/100\n",
      "656/656 - 12s - loss: 1.9071e-04 - val_loss: 7.1758e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 25/100\n",
      "656/656 - 12s - loss: 1.7603e-04 - val_loss: 6.3041e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 26/100\n",
      "656/656 - 12s - loss: 1.6693e-04 - val_loss: 6.1627e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 27/100\n",
      "656/656 - 12s - loss: 1.6421e-04 - val_loss: 6.9003e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 28/100\n",
      "656/656 - 12s - loss: 1.6652e-04 - val_loss: 7.3380e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 29/100\n",
      "656/656 - 12s - loss: 1.6574e-04 - val_loss: 7.8115e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 30/100\n",
      "656/656 - 12s - loss: 1.6223e-04 - val_loss: 7.3860e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "656/656 - 12s - loss: 1.5446e-04 - val_loss: 6.7937e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "656/656 - 12s - loss: 1.4900e-04 - val_loss: 6.5612e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 33/100\n",
      "656/656 - 12s - loss: 1.4430e-04 - val_loss: 6.2622e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "656/656 - 12s - loss: 1.4034e-04 - val_loss: 6.1297e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "656/656 - 12s - loss: 1.3767e-04 - val_loss: 6.3858e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 36/100\n",
      "656/656 - 12s - loss: 1.3627e-04 - val_loss: 6.5509e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "656/656 - 12s - loss: 1.3631e-04 - val_loss: 6.4433e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 38/100\n",
      "656/656 - 12s - loss: 1.3227e-04 - val_loss: 6.3559e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "656/656 - 12s - loss: 1.2830e-04 - val_loss: 6.0920e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "656/656 - 12s - loss: 1.2483e-04 - val_loss: 5.9597e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "656/656 - 12s - loss: 1.2264e-04 - val_loss: 5.7814e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 42/100\n",
      "656/656 - 12s - loss: 1.2075e-04 - val_loss: 6.0154e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "656/656 - 12s - loss: 1.1949e-04 - val_loss: 5.9575e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "656/656 - 12s - loss: 1.1817e-04 - val_loss: 6.1572e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "656/656 - 12s - loss: 1.1659e-04 - val_loss: 5.9773e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 46/100\n",
      "656/656 - 12s - loss: 1.1458e-04 - val_loss: 5.9859e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 47/100\n",
      "656/656 - 12s - loss: 1.1287e-04 - val_loss: 5.8923e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 48/100\n",
      "656/656 - 12s - loss: 1.1093e-04 - val_loss: 5.8096e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 49/100\n",
      "656/656 - 12s - loss: 1.0937e-04 - val_loss: 5.8538e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "656/656 - 12s - loss: 1.0814e-04 - val_loss: 5.8698e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 51/100\n",
      "656/656 - 12s - loss: 1.0677e-04 - val_loss: 5.9639e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "656/656 - 12s - loss: 1.0574e-04 - val_loss: 6.0361e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "656/656 - 12s - loss: 1.0433e-04 - val_loss: 6.0772e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "656/656 - 12s - loss: 1.0316e-04 - val_loss: 6.1358e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "656/656 - 12s - loss: 1.0206e-04 - val_loss: 6.2068e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "656/656 - 12s - loss: 1.0095e-04 - val_loss: 6.2506e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 57/100\n",
      "656/656 - 12s - loss: 9.9845e-05 - val_loss: 6.3085e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 58/100\n",
      "656/656 - 12s - loss: 9.8764e-05 - val_loss: 6.3530e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "656/656 - 12s - loss: 9.7710e-05 - val_loss: 6.3866e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 60/100\n",
      "656/656 - 12s - loss: 9.6724e-05 - val_loss: 6.3959e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 61/100\n",
      "656/656 - 12s - loss: 9.5786e-05 - val_loss: 6.4374e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 62/100\n",
      "656/656 - 12s - loss: 9.4909e-05 - val_loss: 6.4715e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 63/100\n",
      "656/656 - 12s - loss: 9.4025e-05 - val_loss: 6.4671e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 64/100\n",
      "656/656 - 12s - loss: 9.3127e-05 - val_loss: 6.4800e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "656/656 - 12s - loss: 9.2168e-05 - val_loss: 6.4770e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 66/100\n",
      "656/656 - 12s - loss: 9.1251e-05 - val_loss: 6.4783e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 67/100\n",
      "656/656 - 12s - loss: 9.0405e-05 - val_loss: 6.4774e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 68/100\n",
      "656/656 - 12s - loss: 8.9627e-05 - val_loss: 6.5066e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 69/100\n",
      "656/656 - 12s - loss: 8.8879e-05 - val_loss: 6.5105e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 70/100\n",
      "656/656 - 12s - loss: 8.8068e-05 - val_loss: 6.5115e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "656/656 - 12s - loss: 8.7269e-05 - val_loss: 6.5112e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 72/100\n",
      "656/656 - 12s - loss: 8.6483e-05 - val_loss: 6.5354e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 73/100\n",
      "656/656 - 12s - loss: 8.5712e-05 - val_loss: 6.5673e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 74/100\n",
      "656/656 - 12s - loss: 8.5011e-05 - val_loss: 6.6307e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 75/100\n",
      "656/656 - 12s - loss: 8.4303e-05 - val_loss: 6.6943e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 76/100\n",
      "656/656 - 12s - loss: 8.3607e-05 - val_loss: 6.7960e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "656/656 - 12s - loss: 8.2951e-05 - val_loss: 6.9366e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 78/100\n",
      "656/656 - 12s - loss: 8.2340e-05 - val_loss: 7.1350e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 79/100\n",
      "656/656 - 12s - loss: 8.1699e-05 - val_loss: 7.3741e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 80/100\n",
      "656/656 - 12s - loss: 8.1055e-05 - val_loss: 7.6733e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 81/100\n",
      "656/656 - 12s - loss: 8.0444e-05 - val_loss: 8.0307e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 82/100\n",
      "656/656 - 12s - loss: 7.9877e-05 - val_loss: 8.3112e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "656/656 - 12s - loss: 7.9273e-05 - val_loss: 8.3724e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "656/656 - 12s - loss: 7.8643e-05 - val_loss: 8.2987e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "656/656 - 12s - loss: 7.8056e-05 - val_loss: 8.1765e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 86/100\n",
      "656/656 - 12s - loss: 7.7473e-05 - val_loss: 8.0294e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 87/100\n",
      "656/656 - 12s - loss: 7.6938e-05 - val_loss: 7.8632e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "656/656 - 12s - loss: 7.6413e-05 - val_loss: 7.7231e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "656/656 - 12s - loss: 7.5891e-05 - val_loss: 7.5455e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 90/100\n",
      "656/656 - 12s - loss: 7.5362e-05 - val_loss: 7.3569e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 91/100\n",
      "656/656 - 12s - loss: 7.4845e-05 - val_loss: 7.1615e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 92/100\n",
      "656/656 - 12s - loss: 7.4336e-05 - val_loss: 6.9621e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "656/656 - 12s - loss: 7.3844e-05 - val_loss: 6.7679e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 94/100\n",
      "656/656 - 12s - loss: 7.3373e-05 - val_loss: 6.5805e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 95/100\n",
      "656/656 - 12s - loss: 7.2910e-05 - val_loss: 6.4125e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 96/100\n",
      "656/656 - 12s - loss: 7.2436e-05 - val_loss: 6.2711e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 97/100\n",
      "656/656 - 12s - loss: 7.1968e-05 - val_loss: 6.1592e-05 - 12s/epoch - 19ms/step\n",
      "Epoch 98/100\n",
      "656/656 - 12s - loss: 7.1516e-05 - val_loss: 6.0648e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 99/100\n",
      "656/656 - 12s - loss: 7.1091e-05 - val_loss: 5.9908e-05 - 12s/epoch - 18ms/step\n",
      "Epoch 100/100\n",
      "656/656 - 12s - loss: 7.0689e-05 - val_loss: 5.9311e-05 - 12s/epoch - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "lstms1 = []\n",
    "models1 = []\n",
    "for batch, epoch, neuron in hyperparam1:\n",
    "    model, lstm = LSTMUnit.train_lstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    lstms1.append(lstm)\n",
    "    models1.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebe15d8d-6bc9-4220-a7db-48e4d4c7cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 8ms/step\n",
      "(32, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "404.93894939856665\n",
      "MAE\n",
      "343.6649172295271\n",
      "MAPE\n",
      "1.764408631992459\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(32, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "333.2710682537069\n",
      "MAE\n",
      "278.0390407961099\n",
      "MAPE\n",
      "1.4149529166748642\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(32, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "453.83106692816557\n",
      "MAE\n",
      "391.91225502071296\n",
      "MAPE\n",
      "2.0314485680164847\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(32, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "398.0717656769985\n",
      "MAE\n",
      "335.32131280769755\n",
      "MAPE\n",
      "1.735633664360191\n",
      "163/163 [==============================] - 1s 7ms/step\n",
      "(32, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "386.89078117163785\n",
      "MAE\n",
      "327.14556365574043\n",
      "MAPE\n",
      "1.6930921435565005\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(32, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "441.1755051853553\n",
      "MAE\n",
      "388.86814957823043\n",
      "MAPE\n",
      "2.0142165399526295\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(32, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "395.10418058397755\n",
      "MAE\n",
      "307.9466872898654\n",
      "MAPE\n",
      "1.581520030182397\n",
      "163/163 [==============================] - 1s 7ms/step\n",
      "(32, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "406.2086033697782\n",
      "MAE\n",
      "344.1892680115281\n",
      "MAPE\n",
      "1.7885393603906645\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(32, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "496.7610031985911\n",
      "MAE\n",
      "437.1187426978272\n",
      "MAPE\n",
      "2.2618395135082476\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb1 = Workbook()\n",
    "ws1 = wb1.active\n",
    "for m in models1:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = LSTMUnit.predict(test_x2, m)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparam1[i])\n",
    "    print(\"Epoch: \"+ str(lstms1[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].units))\n",
    "    i = i+1\n",
    "    ws1['A'+str(i)] = 'LSTM'\n",
    "    ws1['B'+str(i)] = hyperparam1[i-1][0]\n",
    "    ws1['C'+str(i)] = hyperparam1[i-1][1]\n",
    "    ws1['D'+str(i)] = hyperparam1[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
    "    ws1['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
    "    print('MAE')\n",
    "    print(Evaluation.mae(inv_y,inv_yhat))\n",
    "    ws1['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
    "    print('MAPE')\n",
    "    print(Evaluation.mape(inv_y,inv_yhat))\n",
    "    ws1['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
    "    LSTMUnit.save_model(m, 0, 'BTC',hyperparam1[i-1])\n",
    "    with open('LSTM_BTC'+str(hyperparam1[i-1])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(lstms1[i-1].history, f)\n",
    "wb1.save('LSTM_BTC_result1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b72569-a783-465c-b828-1a68e970e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:31:07.845232: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:31:07.927582: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:31:08.086239: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:31:14.038281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:31:14.068166: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 7s - loss: 5.2549e-04 - val_loss: 0.0012 - 7s/epoch - 23ms/step\n",
      "Epoch 2/25\n",
      "328/328 - 6s - loss: 5.9229e-04 - val_loss: 3.3261e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 3/25\n",
      "328/328 - 6s - loss: 3.6345e-04 - val_loss: 2.0216e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 4/25\n",
      "328/328 - 6s - loss: 2.7287e-04 - val_loss: 1.3098e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 5/25\n",
      "328/328 - 6s - loss: 2.0725e-04 - val_loss: 9.3910e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 6/25\n",
      "328/328 - 6s - loss: 1.5711e-04 - val_loss: 7.1406e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 7/25\n",
      "328/328 - 6s - loss: 1.2302e-04 - val_loss: 4.6939e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 8/25\n",
      "328/328 - 6s - loss: 1.0444e-04 - val_loss: 2.6268e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 9/25\n",
      "328/328 - 6s - loss: 9.6189e-05 - val_loss: 1.6575e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 10/25\n",
      "328/328 - 6s - loss: 9.2374e-05 - val_loss: 1.3558e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 11/25\n",
      "328/328 - 6s - loss: 9.0835e-05 - val_loss: 1.3796e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 12/25\n",
      "328/328 - 6s - loss: 9.1556e-05 - val_loss: 1.6113e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 13/25\n",
      "328/328 - 6s - loss: 9.2658e-05 - val_loss: 1.9619e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 14/25\n",
      "328/328 - 6s - loss: 9.2989e-05 - val_loss: 2.3274e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 15/25\n",
      "328/328 - 6s - loss: 9.0196e-05 - val_loss: 2.4971e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 16/25\n",
      "328/328 - 6s - loss: 8.6094e-05 - val_loss: 2.5322e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 17/25\n",
      "328/328 - 6s - loss: 8.2569e-05 - val_loss: 2.5649e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 18/25\n",
      "328/328 - 6s - loss: 8.0690e-05 - val_loss: 2.7050e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 19/25\n",
      "328/328 - 6s - loss: 7.9601e-05 - val_loss: 2.8781e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 20/25\n",
      "328/328 - 6s - loss: 7.7806e-05 - val_loss: 2.9550e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 21/25\n",
      "328/328 - 6s - loss: 7.5663e-05 - val_loss: 3.0328e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 22/25\n",
      "328/328 - 6s - loss: 7.3964e-05 - val_loss: 3.0291e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 23/25\n",
      "328/328 - 6s - loss: 7.2631e-05 - val_loss: 3.1913e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 24/25\n",
      "328/328 - 6s - loss: 7.1594e-05 - val_loss: 3.2139e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 25/25\n",
      "328/328 - 6s - loss: 6.9108e-05 - val_loss: 3.0621e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:33:38.150906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:33:38.237812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:33:38.394805: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:33:43.998921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:33:44.029420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 7s - loss: 2.4114e-04 - val_loss: 1.4588e-04 - 7s/epoch - 22ms/step\n",
      "Epoch 2/25\n",
      "328/328 - 6s - loss: 6.2847e-04 - val_loss: 3.5771e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 3/25\n",
      "328/328 - 6s - loss: 3.6998e-04 - val_loss: 1.8635e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 4/25\n",
      "328/328 - 6s - loss: 2.5080e-04 - val_loss: 1.3261e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 5/25\n",
      "328/328 - 6s - loss: 1.8488e-04 - val_loss: 1.0327e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 6/25\n",
      "328/328 - 6s - loss: 1.4209e-04 - val_loss: 7.0260e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 7/25\n",
      "328/328 - 6s - loss: 1.1886e-04 - val_loss: 4.0305e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 8/25\n",
      "328/328 - 6s - loss: 1.0890e-04 - val_loss: 2.4785e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 9/25\n",
      "328/328 - 6s - loss: 1.0447e-04 - val_loss: 1.8883e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 10/25\n",
      "328/328 - 6s - loss: 1.0238e-04 - val_loss: 1.8029e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 11/25\n",
      "328/328 - 6s - loss: 1.0236e-04 - val_loss: 2.0451e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 12/25\n",
      "328/328 - 6s - loss: 1.0348e-04 - val_loss: 2.5239e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 13/25\n",
      "328/328 - 6s - loss: 1.0346e-04 - val_loss: 3.0394e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 14/25\n",
      "328/328 - 6s - loss: 1.0062e-04 - val_loss: 3.2422e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 15/25\n",
      "328/328 - 6s - loss: 9.6390e-05 - val_loss: 3.3354e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 16/25\n",
      "328/328 - 6s - loss: 9.1676e-05 - val_loss: 3.2509e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 17/25\n",
      "328/328 - 6s - loss: 8.8548e-05 - val_loss: 3.4059e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 18/25\n",
      "328/328 - 6s - loss: 8.6369e-05 - val_loss: 3.4113e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 19/25\n",
      "328/328 - 6s - loss: 8.3571e-05 - val_loss: 3.4585e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 20/25\n",
      "328/328 - 6s - loss: 8.1507e-05 - val_loss: 3.4916e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 21/25\n",
      "328/328 - 6s - loss: 8.0152e-05 - val_loss: 3.6237e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 22/25\n",
      "328/328 - 6s - loss: 8.0577e-05 - val_loss: 4.0420e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 23/25\n",
      "328/328 - 6s - loss: 7.8507e-05 - val_loss: 3.7801e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 24/25\n",
      "328/328 - 6s - loss: 7.3525e-05 - val_loss: 3.3318e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 25/25\n",
      "328/328 - 6s - loss: 6.9729e-05 - val_loss: 3.1054e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:36:01.503031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:36:01.589962: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:36:01.753479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:36:08.248096: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:36:08.278837: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 8s - loss: 2.9042e-04 - val_loss: 3.3351e-04 - 8s/epoch - 25ms/step\n",
      "Epoch 2/25\n",
      "328/328 - 7s - loss: 7.3189e-04 - val_loss: 8.5026e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 3/25\n",
      "328/328 - 7s - loss: 7.0589e-04 - val_loss: 6.0367e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 4/25\n",
      "328/328 - 7s - loss: 4.6699e-04 - val_loss: 4.4581e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 5/25\n",
      "328/328 - 7s - loss: 3.7006e-04 - val_loss: 3.1958e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 6/25\n",
      "328/328 - 7s - loss: 3.0230e-04 - val_loss: 2.1525e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 7/25\n",
      "328/328 - 7s - loss: 2.4579e-04 - val_loss: 1.3833e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 8/25\n",
      "328/328 - 7s - loss: 1.9430e-04 - val_loss: 9.2912e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 9/25\n",
      "328/328 - 7s - loss: 1.4905e-04 - val_loss: 7.1022e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 10/25\n",
      "328/328 - 7s - loss: 1.1295e-04 - val_loss: 5.3853e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 11/25\n",
      "328/328 - 7s - loss: 8.9980e-05 - val_loss: 3.0961e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 12/25\n",
      "328/328 - 7s - loss: 7.9939e-05 - val_loss: 1.5678e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 13/25\n",
      "328/328 - 7s - loss: 7.7192e-05 - val_loss: 1.0334e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 14/25\n",
      "328/328 - 7s - loss: 7.7661e-05 - val_loss: 9.9794e-06 - 7s/epoch - 20ms/step\n",
      "Epoch 15/25\n",
      "328/328 - 7s - loss: 8.1027e-05 - val_loss: 1.2827e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 16/25\n",
      "328/328 - 7s - loss: 8.5760e-05 - val_loss: 1.9845e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 17/25\n",
      "328/328 - 7s - loss: 9.3091e-05 - val_loss: 2.9059e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 18/25\n",
      "328/328 - 7s - loss: 9.3017e-05 - val_loss: 3.2933e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 19/25\n",
      "328/328 - 7s - loss: 8.6995e-05 - val_loss: 3.0140e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 20/25\n",
      "328/328 - 7s - loss: 7.9571e-05 - val_loss: 2.7533e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 21/25\n",
      "328/328 - 7s - loss: 7.5454e-05 - val_loss: 2.7616e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 22/25\n",
      "328/328 - 7s - loss: 7.6478e-05 - val_loss: 3.3366e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 23/25\n",
      "328/328 - 7s - loss: 8.2750e-05 - val_loss: 5.1647e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 24/25\n",
      "328/328 - 7s - loss: 9.1260e-05 - val_loss: 6.1587e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 25/25\n",
      "328/328 - 7s - loss: 7.9364e-05 - val_loss: 4.3384e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:38:50.453008: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:38:50.537755: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:38:50.684454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:38:56.557176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:38:56.587411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 7s - loss: 6.5344e-04 - val_loss: 3.7994e-04 - 7s/epoch - 23ms/step\n",
      "Epoch 2/50\n",
      "328/328 - 6s - loss: 4.6747e-04 - val_loss: 1.9952e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 3/50\n",
      "328/328 - 6s - loss: 3.3294e-04 - val_loss: 1.2361e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 4/50\n",
      "328/328 - 6s - loss: 2.5230e-04 - val_loss: 8.4078e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 5/50\n",
      "328/328 - 6s - loss: 1.9223e-04 - val_loss: 6.3274e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 6/50\n",
      "328/328 - 6s - loss: 1.4995e-04 - val_loss: 4.5618e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 7/50\n",
      "328/328 - 6s - loss: 1.2467e-04 - val_loss: 2.8629e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 8/50\n",
      "328/328 - 6s - loss: 1.1176e-04 - val_loss: 1.8661e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 9/50\n",
      "328/328 - 6s - loss: 1.0486e-04 - val_loss: 1.4644e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 10/50\n",
      "328/328 - 6s - loss: 1.0069e-04 - val_loss: 1.3746e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 11/50\n",
      "328/328 - 6s - loss: 9.8421e-05 - val_loss: 1.4540e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 12/50\n",
      "328/328 - 6s - loss: 9.8390e-05 - val_loss: 1.7034e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 13/50\n",
      "328/328 - 6s - loss: 9.8136e-05 - val_loss: 2.0114e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 14/50\n",
      "328/328 - 6s - loss: 9.6384e-05 - val_loss: 2.2616e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 15/50\n",
      "328/328 - 6s - loss: 9.3059e-05 - val_loss: 2.4062e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 16/50\n",
      "328/328 - 6s - loss: 8.9214e-05 - val_loss: 2.4690e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 17/50\n",
      "328/328 - 6s - loss: 8.6169e-05 - val_loss: 2.5559e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 18/50\n",
      "328/328 - 6s - loss: 8.4929e-05 - val_loss: 2.7732e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 19/50\n",
      "328/328 - 6s - loss: 8.3296e-05 - val_loss: 2.8803e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 20/50\n",
      "328/328 - 6s - loss: 8.0971e-05 - val_loss: 2.9119e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 21/50\n",
      "328/328 - 6s - loss: 7.8756e-05 - val_loss: 2.9415e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 22/50\n",
      "328/328 - 6s - loss: 7.6872e-05 - val_loss: 2.9969e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 23/50\n",
      "328/328 - 6s - loss: 7.5446e-05 - val_loss: 3.0395e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 24/50\n",
      "328/328 - 6s - loss: 7.4354e-05 - val_loss: 3.0927e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 25/50\n",
      "328/328 - 6s - loss: 7.3355e-05 - val_loss: 3.1717e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 26/50\n",
      "328/328 - 6s - loss: 7.1346e-05 - val_loss: 2.9691e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 27/50\n",
      "328/328 - 6s - loss: 6.8235e-05 - val_loss: 2.7373e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 28/50\n",
      "328/328 - 6s - loss: 6.5984e-05 - val_loss: 2.6340e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 29/50\n",
      "328/328 - 6s - loss: 6.5155e-05 - val_loss: 2.6310e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 30/50\n",
      "328/328 - 6s - loss: 6.5329e-05 - val_loss: 2.7124e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 31/50\n",
      "328/328 - 6s - loss: 6.5982e-05 - val_loss: 2.8376e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 32/50\n",
      "328/328 - 6s - loss: 6.5853e-05 - val_loss: 2.9157e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 33/50\n",
      "328/328 - 6s - loss: 6.3463e-05 - val_loss: 2.5946e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 34/50\n",
      "328/328 - 6s - loss: 5.9905e-05 - val_loss: 2.3252e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 35/50\n",
      "328/328 - 6s - loss: 5.8499e-05 - val_loss: 2.3057e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 36/50\n",
      "328/328 - 6s - loss: 5.9490e-05 - val_loss: 2.4747e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 37/50\n",
      "328/328 - 6s - loss: 6.0993e-05 - val_loss: 2.6269e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 38/50\n",
      "328/328 - 6s - loss: 6.0583e-05 - val_loss: 2.5610e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 39/50\n",
      "328/328 - 6s - loss: 5.8618e-05 - val_loss: 2.4321e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 40/50\n",
      "328/328 - 6s - loss: 5.6742e-05 - val_loss: 2.2932e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 41/50\n",
      "328/328 - 6s - loss: 5.5596e-05 - val_loss: 2.2738e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 42/50\n",
      "328/328 - 6s - loss: 5.5670e-05 - val_loss: 2.3220e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 43/50\n",
      "328/328 - 6s - loss: 5.6096e-05 - val_loss: 2.3908e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 44/50\n",
      "328/328 - 6s - loss: 5.6164e-05 - val_loss: 2.4305e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 45/50\n",
      "328/328 - 6s - loss: 5.5355e-05 - val_loss: 2.3628e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 46/50\n",
      "328/328 - 6s - loss: 5.4035e-05 - val_loss: 2.2906e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 47/50\n",
      "328/328 - 6s - loss: 5.3060e-05 - val_loss: 2.2386e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 48/50\n",
      "328/328 - 6s - loss: 5.2905e-05 - val_loss: 2.2663e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 49/50\n",
      "328/328 - 6s - loss: 5.3178e-05 - val_loss: 2.3555e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 50/50\n",
      "328/328 - 6s - loss: 5.3209e-05 - val_loss: 2.3676e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:43:50.822834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:43:50.905540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:43:51.082219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:43:56.765995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:43:56.796596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 7s - loss: 2.0385e-04 - val_loss: 1.1098e-04 - 7s/epoch - 22ms/step\n",
      "Epoch 2/50\n",
      "328/328 - 6s - loss: 5.4346e-04 - val_loss: 7.6879e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 3/50\n",
      "328/328 - 6s - loss: 5.5650e-04 - val_loss: 2.6296e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 4/50\n",
      "328/328 - 6s - loss: 3.3687e-04 - val_loss: 1.5267e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 5/50\n",
      "328/328 - 6s - loss: 2.5313e-04 - val_loss: 9.1823e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "328/328 - 6s - loss: 1.9338e-04 - val_loss: 6.2489e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 7/50\n",
      "328/328 - 6s - loss: 1.4754e-04 - val_loss: 4.8989e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "328/328 - 6s - loss: 1.1676e-04 - val_loss: 3.5209e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "328/328 - 6s - loss: 1.0074e-04 - val_loss: 2.1369e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "328/328 - 6s - loss: 9.4604e-05 - val_loss: 1.4290e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 11/50\n",
      "328/328 - 6s - loss: 9.2373e-05 - val_loss: 1.1913e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "328/328 - 6s - loss: 9.1463e-05 - val_loss: 1.1902e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 13/50\n",
      "328/328 - 6s - loss: 9.2004e-05 - val_loss: 1.3616e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 14/50\n",
      "328/328 - 6s - loss: 9.3670e-05 - val_loss: 1.7450e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 15/50\n",
      "328/328 - 6s - loss: 9.5707e-05 - val_loss: 2.2153e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 16/50\n",
      "328/328 - 6s - loss: 9.5044e-05 - val_loss: 2.6478e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "328/328 - 6s - loss: 9.2115e-05 - val_loss: 2.8228e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 18/50\n",
      "328/328 - 6s - loss: 8.8137e-05 - val_loss: 2.8872e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "328/328 - 6s - loss: 8.5160e-05 - val_loss: 2.9274e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 20/50\n",
      "328/328 - 6s - loss: 8.3665e-05 - val_loss: 3.1604e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 21/50\n",
      "328/328 - 6s - loss: 8.3300e-05 - val_loss: 3.3924e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 22/50\n",
      "328/328 - 6s - loss: 8.1473e-05 - val_loss: 3.4383e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 23/50\n",
      "328/328 - 6s - loss: 7.8250e-05 - val_loss: 3.2822e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "328/328 - 6s - loss: 7.5399e-05 - val_loss: 3.2924e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "328/328 - 6s - loss: 7.4034e-05 - val_loss: 3.2885e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 26/50\n",
      "328/328 - 6s - loss: 7.3318e-05 - val_loss: 3.3337e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "328/328 - 6s - loss: 7.2995e-05 - val_loss: 3.6130e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "328/328 - 6s - loss: 7.2846e-05 - val_loss: 3.6093e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 29/50\n",
      "328/328 - 6s - loss: 7.0034e-05 - val_loss: 3.4101e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 30/50\n",
      "328/328 - 6s - loss: 6.7269e-05 - val_loss: 3.2451e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 31/50\n",
      "328/328 - 6s - loss: 6.5552e-05 - val_loss: 3.1237e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 32/50\n",
      "328/328 - 6s - loss: 6.4644e-05 - val_loss: 3.0576e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 33/50\n",
      "328/328 - 6s - loss: 6.5009e-05 - val_loss: 3.2847e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 34/50\n",
      "328/328 - 6s - loss: 6.5570e-05 - val_loss: 3.3170e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 35/50\n",
      "328/328 - 6s - loss: 6.4426e-05 - val_loss: 3.2088e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 36/50\n",
      "328/328 - 6s - loss: 6.2483e-05 - val_loss: 3.0370e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 37/50\n",
      "328/328 - 6s - loss: 6.0704e-05 - val_loss: 2.9001e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 38/50\n",
      "328/328 - 6s - loss: 5.9855e-05 - val_loss: 2.9201e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 39/50\n",
      "328/328 - 6s - loss: 6.0683e-05 - val_loss: 3.0766e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 40/50\n",
      "328/328 - 6s - loss: 6.0878e-05 - val_loss: 3.0729e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 41/50\n",
      "328/328 - 6s - loss: 6.0296e-05 - val_loss: 3.1700e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 42/50\n",
      "328/328 - 6s - loss: 5.9228e-05 - val_loss: 2.9458e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 43/50\n",
      "328/328 - 6s - loss: 5.6603e-05 - val_loss: 2.6628e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 44/50\n",
      "328/328 - 6s - loss: 5.5380e-05 - val_loss: 2.6691e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 45/50\n",
      "328/328 - 6s - loss: 5.5693e-05 - val_loss: 2.7131e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "328/328 - 6s - loss: 5.6857e-05 - val_loss: 2.9466e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 47/50\n",
      "328/328 - 6s - loss: 5.7505e-05 - val_loss: 2.9906e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 48/50\n",
      "328/328 - 6s - loss: 5.6080e-05 - val_loss: 2.7932e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "328/328 - 6s - loss: 5.3636e-05 - val_loss: 2.5554e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "328/328 - 6s - loss: 5.1810e-05 - val_loss: 2.4009e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:48:38.839462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:48:38.922142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:48:39.109806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:48:45.770261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:48:45.800764: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 8s - loss: 2.3215e-04 - val_loss: 2.7024e-04 - 8s/epoch - 26ms/step\n",
      "Epoch 2/50\n",
      "328/328 - 7s - loss: 3.3945e-04 - val_loss: 8.7133e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 3/50\n",
      "328/328 - 7s - loss: 6.8453e-04 - val_loss: 7.4931e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 4/50\n",
      "328/328 - 7s - loss: 5.3811e-04 - val_loss: 5.1204e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 5/50\n",
      "328/328 - 7s - loss: 3.8309e-04 - val_loss: 3.4515e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 6/50\n",
      "328/328 - 7s - loss: 2.7549e-04 - val_loss: 2.2964e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 7/50\n",
      "328/328 - 7s - loss: 2.0747e-04 - val_loss: 1.5988e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 8/50\n",
      "328/328 - 7s - loss: 1.5161e-04 - val_loss: 1.2335e-04 - 7s/epoch - 21ms/step\n",
      "Epoch 9/50\n",
      "328/328 - 7s - loss: 1.1064e-04 - val_loss: 8.5330e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 10/50\n",
      "328/328 - 7s - loss: 8.6134e-05 - val_loss: 4.1708e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 11/50\n",
      "328/328 - 7s - loss: 7.6735e-05 - val_loss: 1.9545e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 12/50\n",
      "328/328 - 7s - loss: 7.5668e-05 - val_loss: 1.3848e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 13/50\n",
      "328/328 - 7s - loss: 8.0028e-05 - val_loss: 1.6189e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 14/50\n",
      "328/328 - 7s - loss: 8.9746e-05 - val_loss: 2.5674e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 15/50\n",
      "328/328 - 7s - loss: 9.9786e-05 - val_loss: 3.9480e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 16/50\n",
      "328/328 - 7s - loss: 1.0166e-04 - val_loss: 4.3837e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 17/50\n",
      "328/328 - 7s - loss: 9.3760e-05 - val_loss: 3.9972e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 18/50\n",
      "328/328 - 7s - loss: 8.7859e-05 - val_loss: 4.1492e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 19/50\n",
      "328/328 - 7s - loss: 8.6694e-05 - val_loss: 4.2855e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 20/50\n",
      "328/328 - 7s - loss: 8.6063e-05 - val_loss: 4.7756e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 21/50\n",
      "328/328 - 7s - loss: 8.7532e-05 - val_loss: 5.4143e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 22/50\n",
      "328/328 - 7s - loss: 8.5374e-05 - val_loss: 5.2013e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 23/50\n",
      "328/328 - 7s - loss: 7.6656e-05 - val_loss: 4.2350e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 24/50\n",
      "328/328 - 7s - loss: 7.0391e-05 - val_loss: 3.7001e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 25/50\n",
      "328/328 - 7s - loss: 7.0305e-05 - val_loss: 4.0241e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 26/50\n",
      "328/328 - 7s - loss: 7.5730e-05 - val_loss: 5.8146e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 27/50\n",
      "328/328 - 7s - loss: 9.0702e-05 - val_loss: 9.6556e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 28/50\n",
      "328/328 - 7s - loss: 9.5602e-05 - val_loss: 9.1699e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 29/50\n",
      "328/328 - 7s - loss: 7.3231e-05 - val_loss: 4.6217e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 30/50\n",
      "328/328 - 7s - loss: 5.5316e-05 - val_loss: 2.6936e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 31/50\n",
      "328/328 - 7s - loss: 4.9888e-05 - val_loss: 2.2876e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 32/50\n",
      "328/328 - 7s - loss: 5.5090e-05 - val_loss: 3.2835e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 33/50\n",
      "328/328 - 7s - loss: 7.3427e-05 - val_loss: 7.1178e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 34/50\n",
      "328/328 - 7s - loss: 9.5391e-05 - val_loss: 1.1126e-04 - 7s/epoch - 21ms/step\n",
      "Epoch 35/50\n",
      "328/328 - 7s - loss: 8.2937e-05 - val_loss: 7.1490e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 36/50\n",
      "328/328 - 7s - loss: 5.9405e-05 - val_loss: 3.5363e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 37/50\n",
      "328/328 - 7s - loss: 4.7899e-05 - val_loss: 2.2490e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 38/50\n",
      "328/328 - 7s - loss: 4.6157e-05 - val_loss: 2.3384e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 39/50\n",
      "328/328 - 7s - loss: 5.4489e-05 - val_loss: 3.7677e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 40/50\n",
      "328/328 - 7s - loss: 7.3232e-05 - val_loss: 7.6213e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 41/50\n",
      "328/328 - 7s - loss: 8.5182e-05 - val_loss: 8.7785e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 42/50\n",
      "328/328 - 7s - loss: 6.7719e-05 - val_loss: 5.1441e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 43/50\n",
      "328/328 - 7s - loss: 5.0477e-05 - val_loss: 2.6175e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 44/50\n",
      "328/328 - 7s - loss: 4.3866e-05 - val_loss: 2.1254e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 45/50\n",
      "328/328 - 7s - loss: 4.6116e-05 - val_loss: 2.6556e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 46/50\n",
      "328/328 - 7s - loss: 5.7021e-05 - val_loss: 4.5735e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 47/50\n",
      "328/328 - 7s - loss: 7.4810e-05 - val_loss: 7.8932e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 48/50\n",
      "328/328 - 7s - loss: 7.2096e-05 - val_loss: 6.2441e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 49/50\n",
      "328/328 - 7s - loss: 5.6601e-05 - val_loss: 3.6756e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 50/50\n",
      "328/328 - 7s - loss: 4.4461e-05 - val_loss: 2.1583e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 10:54:16.602796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:54:16.682071: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:54:16.881488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:54:23.017209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 10:54:23.047924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 8s - loss: 6.7891e-04 - val_loss: 7.1279e-04 - 8s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "328/328 - 6s - loss: 6.0901e-04 - val_loss: 4.1827e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "328/328 - 6s - loss: 3.9308e-04 - val_loss: 2.6937e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "328/328 - 6s - loss: 3.2091e-04 - val_loss: 1.6982e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "328/328 - 6s - loss: 2.6356e-04 - val_loss: 1.0400e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "328/328 - 6s - loss: 2.1364e-04 - val_loss: 6.6251e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "328/328 - 6s - loss: 1.6984e-04 - val_loss: 4.8538e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 8/100\n",
      "328/328 - 6s - loss: 1.3414e-04 - val_loss: 3.9688e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "328/328 - 6s - loss: 1.0971e-04 - val_loss: 2.9192e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 10/100\n",
      "328/328 - 6s - loss: 9.6833e-05 - val_loss: 1.8987e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "328/328 - 6s - loss: 9.1558e-05 - val_loss: 1.3847e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 12/100\n",
      "328/328 - 6s - loss: 8.9284e-05 - val_loss: 1.2163e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 13/100\n",
      "328/328 - 6s - loss: 8.8956e-05 - val_loss: 1.2704e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 14/100\n",
      "328/328 - 6s - loss: 8.8337e-05 - val_loss: 1.3786e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 15/100\n",
      "328/328 - 6s - loss: 9.0512e-05 - val_loss: 1.8146e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 16/100\n",
      "328/328 - 6s - loss: 8.9273e-05 - val_loss: 1.9496e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "328/328 - 6s - loss: 8.5337e-05 - val_loss: 2.0752e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "328/328 - 6s - loss: 8.2396e-05 - val_loss: 2.2213e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 19/100\n",
      "328/328 - 6s - loss: 7.9883e-05 - val_loss: 2.3230e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "328/328 - 6s - loss: 7.7419e-05 - val_loss: 2.4172e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 21/100\n",
      "328/328 - 6s - loss: 7.5458e-05 - val_loss: 2.5325e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 22/100\n",
      "328/328 - 6s - loss: 7.4761e-05 - val_loss: 2.8892e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 23/100\n",
      "328/328 - 6s - loss: 7.4960e-05 - val_loss: 3.0308e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 24/100\n",
      "328/328 - 6s - loss: 7.1371e-05 - val_loss: 2.9064e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 25/100\n",
      "328/328 - 6s - loss: 6.8097e-05 - val_loss: 2.8413e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 26/100\n",
      "328/328 - 6s - loss: 6.6725e-05 - val_loss: 2.9003e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 27/100\n",
      "328/328 - 6s - loss: 6.6652e-05 - val_loss: 3.1312e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 28/100\n",
      "328/328 - 6s - loss: 6.7302e-05 - val_loss: 3.4228e-05 - 6s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "328/328 - 6s - loss: 6.6331e-05 - val_loss: 3.3622e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 30/100\n",
      "328/328 - 6s - loss: 6.3353e-05 - val_loss: 3.1825e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "328/328 - 6s - loss: 6.1107e-05 - val_loss: 3.0091e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "328/328 - 6s - loss: 5.9780e-05 - val_loss: 2.9416e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 33/100\n",
      "328/328 - 6s - loss: 5.9900e-05 - val_loss: 3.0792e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "328/328 - 6s - loss: 6.1123e-05 - val_loss: 3.3277e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "328/328 - 6s - loss: 6.2247e-05 - val_loss: 3.6107e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 36/100\n",
      "328/328 - 6s - loss: 6.0592e-05 - val_loss: 3.2949e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "328/328 - 6s - loss: 5.6352e-05 - val_loss: 2.7733e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 38/100\n",
      "328/328 - 6s - loss: 5.2907e-05 - val_loss: 2.4321e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "328/328 - 6s - loss: 5.2809e-05 - val_loss: 2.5494e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "328/328 - 6s - loss: 5.5402e-05 - val_loss: 2.8880e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "328/328 - 6s - loss: 5.8985e-05 - val_loss: 3.4949e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 42/100\n",
      "328/328 - 6s - loss: 6.0454e-05 - val_loss: 3.5811e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "328/328 - 6s - loss: 5.5777e-05 - val_loss: 2.8082e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "328/328 - 6s - loss: 4.9370e-05 - val_loss: 2.1523e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "328/328 - 6s - loss: 4.6822e-05 - val_loss: 2.0435e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 46/100\n",
      "328/328 - 6s - loss: 4.8837e-05 - val_loss: 2.3834e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 47/100\n",
      "328/328 - 6s - loss: 5.4637e-05 - val_loss: 3.2949e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 48/100\n",
      "328/328 - 6s - loss: 5.9778e-05 - val_loss: 3.7442e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 49/100\n",
      "328/328 - 6s - loss: 5.5064e-05 - val_loss: 2.8606e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "328/328 - 6s - loss: 4.7848e-05 - val_loss: 2.1264e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 51/100\n",
      "328/328 - 6s - loss: 4.4580e-05 - val_loss: 1.9317e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "328/328 - 6s - loss: 4.5562e-05 - val_loss: 2.1734e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "328/328 - 6s - loss: 4.9989e-05 - val_loss: 2.7757e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "328/328 - 6s - loss: 5.5956e-05 - val_loss: 3.5085e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "328/328 - 6s - loss: 5.4570e-05 - val_loss: 3.0038e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "328/328 - 6s - loss: 4.7640e-05 - val_loss: 2.2121e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 57/100\n",
      "328/328 - 6s - loss: 4.3296e-05 - val_loss: 1.8716e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 58/100\n",
      "328/328 - 6s - loss: 4.3039e-05 - val_loss: 1.9802e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "328/328 - 6s - loss: 4.6248e-05 - val_loss: 2.4320e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 60/100\n",
      "328/328 - 6s - loss: 5.1221e-05 - val_loss: 3.0669e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 61/100\n",
      "328/328 - 6s - loss: 5.3186e-05 - val_loss: 3.1526e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 62/100\n",
      "328/328 - 6s - loss: 4.8952e-05 - val_loss: 2.4969e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 63/100\n",
      "328/328 - 6s - loss: 4.3791e-05 - val_loss: 1.9646e-05 - 6s/epoch - 19ms/step\n",
      "Epoch 64/100\n",
      "328/328 - 6s - loss: 4.1567e-05 - val_loss: 1.8578e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "328/328 - 6s - loss: 4.2839e-05 - val_loss: 2.1126e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 66/100\n",
      "328/328 - 6s - loss: 4.6777e-05 - val_loss: 2.6511e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 67/100\n",
      "328/328 - 6s - loss: 5.0807e-05 - val_loss: 3.1446e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 68/100\n",
      "328/328 - 6s - loss: 4.9406e-05 - val_loss: 2.7158e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 69/100\n",
      "328/328 - 6s - loss: 4.4231e-05 - val_loss: 2.0924e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 70/100\n",
      "328/328 - 6s - loss: 4.0875e-05 - val_loss: 1.8274e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "328/328 - 6s - loss: 4.0749e-05 - val_loss: 1.9462e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 72/100\n",
      "328/328 - 6s - loss: 4.3701e-05 - val_loss: 2.3969e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 73/100\n",
      "328/328 - 6s - loss: 4.7997e-05 - val_loss: 2.9371e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 74/100\n",
      "328/328 - 6s - loss: 4.8878e-05 - val_loss: 2.8537e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 75/100\n",
      "328/328 - 6s - loss: 4.5131e-05 - val_loss: 2.2983e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 76/100\n",
      "328/328 - 6s - loss: 4.1229e-05 - val_loss: 1.8997e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "328/328 - 6s - loss: 3.9739e-05 - val_loss: 1.8517e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 78/100\n",
      "328/328 - 6s - loss: 4.1103e-05 - val_loss: 2.1223e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 79/100\n",
      "328/328 - 6s - loss: 4.4581e-05 - val_loss: 2.6292e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 80/100\n",
      "328/328 - 6s - loss: 4.7528e-05 - val_loss: 2.9598e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 81/100\n",
      "328/328 - 6s - loss: 4.6071e-05 - val_loss: 2.5582e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 82/100\n",
      "328/328 - 6s - loss: 4.2111e-05 - val_loss: 2.0679e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "328/328 - 6s - loss: 3.9266e-05 - val_loss: 1.8076e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "328/328 - 6s - loss: 3.8959e-05 - val_loss: 1.8916e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "328/328 - 6s - loss: 4.1289e-05 - val_loss: 2.2551e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 86/100\n",
      "328/328 - 6s - loss: 4.4728e-05 - val_loss: 2.7380e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 87/100\n",
      "328/328 - 6s - loss: 4.5954e-05 - val_loss: 2.7590e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "328/328 - 6s - loss: 4.3267e-05 - val_loss: 2.3107e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "328/328 - 6s - loss: 3.9999e-05 - val_loss: 1.9295e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 90/100\n",
      "328/328 - 6s - loss: 3.8342e-05 - val_loss: 1.8351e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 91/100\n",
      "328/328 - 6s - loss: 3.9123e-05 - val_loss: 2.0255e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 92/100\n",
      "328/328 - 6s - loss: 4.1697e-05 - val_loss: 2.3989e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "328/328 - 6s - loss: 4.4120e-05 - val_loss: 2.7285e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 94/100\n",
      "328/328 - 6s - loss: 4.3848e-05 - val_loss: 2.5398e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 95/100\n",
      "328/328 - 6s - loss: 4.0902e-05 - val_loss: 2.1056e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 96/100\n",
      "328/328 - 6s - loss: 3.8386e-05 - val_loss: 1.8626e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 97/100\n",
      "328/328 - 6s - loss: 3.7897e-05 - val_loss: 1.9060e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 98/100\n",
      "328/328 - 6s - loss: 3.9471e-05 - val_loss: 2.1625e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 99/100\n",
      "328/328 - 6s - loss: 4.1857e-05 - val_loss: 2.5015e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 100/100\n",
      "328/328 - 6s - loss: 4.3190e-05 - val_loss: 2.6762e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:04:19.746165: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:04:19.832568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:04:20.027346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:04:25.825510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:04:25.856790: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 7s - loss: 3.4958e-04 - val_loss: 4.7544e-04 - 7s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "328/328 - 6s - loss: 6.2697e-04 - val_loss: 3.2509e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "328/328 - 6s - loss: 3.9470e-04 - val_loss: 1.4962e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "328/328 - 6s - loss: 2.8087e-04 - val_loss: 8.3745e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "328/328 - 6s - loss: 2.1300e-04 - val_loss: 5.5832e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "328/328 - 6s - loss: 1.6440e-04 - val_loss: 4.4167e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "328/328 - 6s - loss: 1.3237e-04 - val_loss: 3.4006e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "328/328 - 6s - loss: 1.1511e-04 - val_loss: 2.3656e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "328/328 - 6s - loss: 1.0741e-04 - val_loss: 1.7512e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 10/100\n",
      "328/328 - 6s - loss: 1.0347e-04 - val_loss: 1.4739e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "328/328 - 6s - loss: 1.0035e-04 - val_loss: 1.3833e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "328/328 - 6s - loss: 9.7690e-05 - val_loss: 1.4212e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "328/328 - 6s - loss: 9.6164e-05 - val_loss: 1.6073e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "328/328 - 6s - loss: 9.4920e-05 - val_loss: 1.8582e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "328/328 - 6s - loss: 9.3981e-05 - val_loss: 2.1989e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "328/328 - 6s - loss: 9.2210e-05 - val_loss: 2.5031e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "328/328 - 6s - loss: 9.0682e-05 - val_loss: 2.8589e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "328/328 - 6s - loss: 8.7413e-05 - val_loss: 2.9032e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "328/328 - 6s - loss: 8.3691e-05 - val_loss: 2.9637e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "328/328 - 6s - loss: 8.1781e-05 - val_loss: 3.1289e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "328/328 - 6s - loss: 8.0983e-05 - val_loss: 3.4738e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "328/328 - 6s - loss: 8.1051e-05 - val_loss: 3.8070e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "328/328 - 6s - loss: 7.9084e-05 - val_loss: 3.7801e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "328/328 - 6s - loss: 7.4899e-05 - val_loss: 3.4933e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "328/328 - 6s - loss: 7.1268e-05 - val_loss: 3.3339e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "328/328 - 6s - loss: 7.0058e-05 - val_loss: 3.3911e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "328/328 - 6s - loss: 7.0645e-05 - val_loss: 3.6359e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "328/328 - 6s - loss: 7.1951e-05 - val_loss: 4.1294e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "328/328 - 6s - loss: 7.1460e-05 - val_loss: 4.0641e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "328/328 - 6s - loss: 6.6916e-05 - val_loss: 3.4574e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "328/328 - 6s - loss: 6.2419e-05 - val_loss: 3.1303e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "328/328 - 6s - loss: 6.1555e-05 - val_loss: 3.1245e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "328/328 - 6s - loss: 6.4154e-05 - val_loss: 3.6876e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "328/328 - 6s - loss: 6.7397e-05 - val_loss: 4.1877e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "328/328 - 6s - loss: 6.6461e-05 - val_loss: 3.8975e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "328/328 - 6s - loss: 6.0937e-05 - val_loss: 3.1172e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "328/328 - 6s - loss: 5.6166e-05 - val_loss: 2.6926e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "328/328 - 6s - loss: 5.5027e-05 - val_loss: 2.6879e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "328/328 - 6s - loss: 5.7504e-05 - val_loss: 3.0790e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "328/328 - 6s - loss: 6.1617e-05 - val_loss: 3.6992e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "328/328 - 6s - loss: 6.2722e-05 - val_loss: 3.6744e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "328/328 - 6s - loss: 5.8006e-05 - val_loss: 2.9022e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "328/328 - 6s - loss: 5.2925e-05 - val_loss: 2.4754e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "328/328 - 6s - loss: 5.1278e-05 - val_loss: 2.4371e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "328/328 - 6s - loss: 5.2937e-05 - val_loss: 2.6894e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "328/328 - 6s - loss: 5.6399e-05 - val_loss: 3.2294e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "328/328 - 6s - loss: 5.9104e-05 - val_loss: 3.4473e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "328/328 - 6s - loss: 5.6354e-05 - val_loss: 2.9807e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "328/328 - 6s - loss: 5.1272e-05 - val_loss: 2.3709e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "328/328 - 6s - loss: 4.8344e-05 - val_loss: 2.2148e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 51/100\n",
      "328/328 - 6s - loss: 4.8919e-05 - val_loss: 2.3683e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "328/328 - 6s - loss: 5.1958e-05 - val_loss: 2.8606e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "328/328 - 6s - loss: 5.4965e-05 - val_loss: 2.9949e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 54/100\n",
      "328/328 - 6s - loss: 5.3698e-05 - val_loss: 2.8966e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "328/328 - 6s - loss: 5.0432e-05 - val_loss: 2.4140e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "328/328 - 6s - loss: 4.7414e-05 - val_loss: 2.1996e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 57/100\n",
      "328/328 - 6s - loss: 4.6918e-05 - val_loss: 2.2249e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 58/100\n",
      "328/328 - 6s - loss: 4.8363e-05 - val_loss: 2.4229e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "328/328 - 6s - loss: 5.0710e-05 - val_loss: 2.7721e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 60/100\n",
      "328/328 - 6s - loss: 5.1700e-05 - val_loss: 2.7368e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 61/100\n",
      "328/328 - 6s - loss: 4.9036e-05 - val_loss: 2.3611e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 62/100\n",
      "328/328 - 6s - loss: 4.5833e-05 - val_loss: 2.0505e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "328/328 - 6s - loss: 4.4417e-05 - val_loss: 1.9978e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "328/328 - 6s - loss: 4.5461e-05 - val_loss: 2.2049e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "328/328 - 6s - loss: 4.8494e-05 - val_loss: 2.5777e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "328/328 - 6s - loss: 5.0245e-05 - val_loss: 2.7185e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "328/328 - 6s - loss: 4.8427e-05 - val_loss: 2.3939e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 68/100\n",
      "328/328 - 6s - loss: 4.4765e-05 - val_loss: 1.9911e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "328/328 - 6s - loss: 4.2658e-05 - val_loss: 1.8837e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "328/328 - 6s - loss: 4.3112e-05 - val_loss: 2.0089e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "328/328 - 6s - loss: 4.5526e-05 - val_loss: 2.3153e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "328/328 - 6s - loss: 4.8150e-05 - val_loss: 2.6613e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "328/328 - 6s - loss: 4.7941e-05 - val_loss: 2.4342e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "328/328 - 6s - loss: 4.4472e-05 - val_loss: 2.0639e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "328/328 - 6s - loss: 4.1887e-05 - val_loss: 1.8343e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 76/100\n",
      "328/328 - 6s - loss: 4.1463e-05 - val_loss: 1.8989e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "328/328 - 6s - loss: 4.3356e-05 - val_loss: 2.1660e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "328/328 - 6s - loss: 4.5862e-05 - val_loss: 2.4508e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 79/100\n",
      "328/328 - 6s - loss: 4.6684e-05 - val_loss: 2.4835e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 80/100\n",
      "328/328 - 6s - loss: 4.4402e-05 - val_loss: 2.1067e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "328/328 - 6s - loss: 4.1315e-05 - val_loss: 1.8226e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 82/100\n",
      "328/328 - 6s - loss: 4.0160e-05 - val_loss: 1.7843e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 83/100\n",
      "328/328 - 6s - loss: 4.1414e-05 - val_loss: 2.0224e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 84/100\n",
      "328/328 - 6s - loss: 4.4238e-05 - val_loss: 2.4162e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "328/328 - 6s - loss: 4.6056e-05 - val_loss: 2.5155e-05 - 6s/epoch - 18ms/step\n",
      "Epoch 86/100\n",
      "328/328 - 6s - loss: 4.4348e-05 - val_loss: 2.2493e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "328/328 - 6s - loss: 4.1223e-05 - val_loss: 1.8725e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "328/328 - 6s - loss: 3.9204e-05 - val_loss: 1.7296e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "328/328 - 6s - loss: 3.9513e-05 - val_loss: 1.8540e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "328/328 - 6s - loss: 4.1780e-05 - val_loss: 2.1692e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "328/328 - 6s - loss: 4.4511e-05 - val_loss: 2.5526e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "328/328 - 6s - loss: 4.5095e-05 - val_loss: 2.4983e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 93/100\n",
      "328/328 - 6s - loss: 4.2016e-05 - val_loss: 2.0434e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "328/328 - 6s - loss: 3.8818e-05 - val_loss: 1.7230e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "328/328 - 6s - loss: 3.7812e-05 - val_loss: 1.7085e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "328/328 - 6s - loss: 3.9384e-05 - val_loss: 1.9728e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "328/328 - 6s - loss: 4.2518e-05 - val_loss: 2.3998e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "328/328 - 6s - loss: 4.4381e-05 - val_loss: 2.5818e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "328/328 - 6s - loss: 4.2546e-05 - val_loss: 2.2112e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "328/328 - 6s - loss: 3.9250e-05 - val_loss: 1.8349e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:13:55.181017: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:13:55.261150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:13:55.466370: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:14:02.106695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:14:02.136761: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 - 8s - loss: 2.8002e-04 - val_loss: 3.2943e-04 - 8s/epoch - 26ms/step\n",
      "Epoch 2/100\n",
      "328/328 - 7s - loss: 7.5999e-04 - val_loss: 8.6793e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "328/328 - 7s - loss: 6.7005e-04 - val_loss: 6.3077e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 4/100\n",
      "328/328 - 7s - loss: 4.5868e-04 - val_loss: 4.6728e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 5/100\n",
      "328/328 - 7s - loss: 3.6300e-04 - val_loss: 3.3440e-04 - 7s/epoch - 21ms/step\n",
      "Epoch 6/100\n",
      "328/328 - 7s - loss: 2.9384e-04 - val_loss: 2.2725e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "328/328 - 7s - loss: 2.3361e-04 - val_loss: 1.5513e-04 - 7s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "328/328 - 7s - loss: 1.7919e-04 - val_loss: 1.1610e-04 - 7s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "328/328 - 7s - loss: 1.3471e-04 - val_loss: 8.9997e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "328/328 - 7s - loss: 1.0292e-04 - val_loss: 5.6003e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 11/100\n",
      "328/328 - 7s - loss: 8.6363e-05 - val_loss: 2.6921e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "328/328 - 7s - loss: 8.1135e-05 - val_loss: 1.4852e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 13/100\n",
      "328/328 - 7s - loss: 8.1042e-05 - val_loss: 1.2165e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 14/100\n",
      "328/328 - 7s - loss: 8.5063e-05 - val_loss: 1.5315e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 15/100\n",
      "328/328 - 7s - loss: 9.0876e-05 - val_loss: 2.1527e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 16/100\n",
      "328/328 - 7s - loss: 9.6157e-05 - val_loss: 3.0259e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 17/100\n",
      "328/328 - 7s - loss: 9.9095e-05 - val_loss: 3.8967e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 18/100\n",
      "328/328 - 7s - loss: 9.6448e-05 - val_loss: 3.7823e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 19/100\n",
      "328/328 - 7s - loss: 8.7305e-05 - val_loss: 3.2748e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "328/328 - 7s - loss: 7.9630e-05 - val_loss: 2.8244e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 21/100\n",
      "328/328 - 7s - loss: 7.8045e-05 - val_loss: 3.2372e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "328/328 - 7s - loss: 8.3863e-05 - val_loss: 4.5125e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "328/328 - 7s - loss: 8.8100e-05 - val_loss: 5.1397e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 24/100\n",
      "328/328 - 7s - loss: 8.1951e-05 - val_loss: 4.4165e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "328/328 - 7s - loss: 7.2471e-05 - val_loss: 3.3842e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "328/328 - 7s - loss: 6.6187e-05 - val_loss: 2.8868e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 27/100\n",
      "328/328 - 7s - loss: 6.4914e-05 - val_loss: 2.9758e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 28/100\n",
      "328/328 - 7s - loss: 6.9315e-05 - val_loss: 4.0379e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 29/100\n",
      "328/328 - 7s - loss: 7.6982e-05 - val_loss: 5.2656e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 30/100\n",
      "328/328 - 7s - loss: 7.7154e-05 - val_loss: 5.1952e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 31/100\n",
      "328/328 - 7s - loss: 6.8376e-05 - val_loss: 3.8161e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 32/100\n",
      "328/328 - 7s - loss: 6.0282e-05 - val_loss: 2.9212e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "328/328 - 7s - loss: 5.9157e-05 - val_loss: 3.1514e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 34/100\n",
      "328/328 - 7s - loss: 6.1847e-05 - val_loss: 3.5154e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 35/100\n",
      "328/328 - 7s - loss: 6.7218e-05 - val_loss: 4.7442e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 36/100\n",
      "328/328 - 7s - loss: 6.8320e-05 - val_loss: 4.4229e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 37/100\n",
      "328/328 - 7s - loss: 6.1844e-05 - val_loss: 3.4700e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 38/100\n",
      "328/328 - 7s - loss: 5.8540e-05 - val_loss: 3.4704e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "328/328 - 7s - loss: 5.6928e-05 - val_loss: 3.0250e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "328/328 - 7s - loss: 5.6011e-05 - val_loss: 3.1206e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 41/100\n",
      "328/328 - 7s - loss: 5.6606e-05 - val_loss: 3.1698e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "328/328 - 7s - loss: 5.9043e-05 - val_loss: 3.8288e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 43/100\n",
      "328/328 - 7s - loss: 5.9920e-05 - val_loss: 3.7052e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 44/100\n",
      "328/328 - 7s - loss: 5.7474e-05 - val_loss: 3.5081e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 45/100\n",
      "328/328 - 7s - loss: 5.4122e-05 - val_loss: 2.9898e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 46/100\n",
      "328/328 - 7s - loss: 5.2594e-05 - val_loss: 2.9594e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 47/100\n",
      "328/328 - 7s - loss: 5.2043e-05 - val_loss: 2.9048e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 48/100\n",
      "328/328 - 7s - loss: 5.4072e-05 - val_loss: 3.4623e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 49/100\n",
      "328/328 - 7s - loss: 5.6258e-05 - val_loss: 3.5877e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 50/100\n",
      "328/328 - 7s - loss: 5.4674e-05 - val_loss: 3.3294e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "328/328 - 7s - loss: 5.3794e-05 - val_loss: 3.4670e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 52/100\n",
      "328/328 - 7s - loss: 5.0867e-05 - val_loss: 2.7525e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "328/328 - 7s - loss: 4.8607e-05 - val_loss: 2.6897e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 54/100\n",
      "328/328 - 7s - loss: 4.8166e-05 - val_loss: 2.6318e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 55/100\n",
      "328/328 - 7s - loss: 5.0134e-05 - val_loss: 3.1145e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 56/100\n",
      "328/328 - 7s - loss: 5.1958e-05 - val_loss: 3.3326e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "328/328 - 7s - loss: 5.3239e-05 - val_loss: 3.5654e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 58/100\n",
      "328/328 - 7s - loss: 4.9884e-05 - val_loss: 2.8644e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "328/328 - 7s - loss: 4.6339e-05 - val_loss: 2.5045e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 60/100\n",
      "328/328 - 7s - loss: 4.4677e-05 - val_loss: 2.4135e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 61/100\n",
      "328/328 - 7s - loss: 4.6248e-05 - val_loss: 2.7814e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 62/100\n",
      "328/328 - 7s - loss: 4.9334e-05 - val_loss: 3.2190e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 63/100\n",
      "328/328 - 7s - loss: 5.2092e-05 - val_loss: 3.8261e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "328/328 - 7s - loss: 5.0911e-05 - val_loss: 3.3543e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 65/100\n",
      "328/328 - 7s - loss: 4.6406e-05 - val_loss: 2.6908e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 66/100\n",
      "328/328 - 7s - loss: 4.2723e-05 - val_loss: 2.2491e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 67/100\n",
      "328/328 - 7s - loss: 4.1402e-05 - val_loss: 2.1966e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 68/100\n",
      "328/328 - 7s - loss: 4.3846e-05 - val_loss: 2.7218e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 69/100\n",
      "328/328 - 7s - loss: 4.8571e-05 - val_loss: 3.4949e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 70/100\n",
      "328/328 - 7s - loss: 5.2213e-05 - val_loss: 4.0320e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 71/100\n",
      "328/328 - 7s - loss: 4.7285e-05 - val_loss: 2.8910e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 72/100\n",
      "328/328 - 7s - loss: 4.1120e-05 - val_loss: 2.1962e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 73/100\n",
      "328/328 - 7s - loss: 3.9089e-05 - val_loss: 2.0515e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 74/100\n",
      "328/328 - 7s - loss: 4.0978e-05 - val_loss: 2.4564e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 75/100\n",
      "328/328 - 7s - loss: 4.6007e-05 - val_loss: 3.2981e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 76/100\n",
      "328/328 - 7s - loss: 5.0579e-05 - val_loss: 3.9490e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 77/100\n",
      "328/328 - 7s - loss: 4.7364e-05 - val_loss: 3.1626e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 78/100\n",
      "328/328 - 7s - loss: 4.1564e-05 - val_loss: 2.3217e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 79/100\n",
      "328/328 - 7s - loss: 3.8414e-05 - val_loss: 2.0237e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 80/100\n",
      "328/328 - 7s - loss: 3.9006e-05 - val_loss: 2.2336e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 81/100\n",
      "328/328 - 7s - loss: 4.2946e-05 - val_loss: 2.9409e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "328/328 - 7s - loss: 4.7373e-05 - val_loss: 3.5299e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 83/100\n",
      "328/328 - 7s - loss: 4.6674e-05 - val_loss: 3.2867e-05 - 7s/epoch - 21ms/step\n",
      "Epoch 84/100\n",
      "328/328 - 7s - loss: 4.1861e-05 - val_loss: 2.4534e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 85/100\n",
      "328/328 - 7s - loss: 3.8325e-05 - val_loss: 2.0919e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 86/100\n",
      "328/328 - 7s - loss: 3.8167e-05 - val_loss: 2.1773e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 87/100\n",
      "328/328 - 7s - loss: 4.1045e-05 - val_loss: 2.7071e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 88/100\n",
      "328/328 - 7s - loss: 4.4838e-05 - val_loss: 3.2991e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 89/100\n",
      "328/328 - 7s - loss: 4.5626e-05 - val_loss: 3.2611e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 90/100\n",
      "328/328 - 7s - loss: 4.1698e-05 - val_loss: 2.5450e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 91/100\n",
      "328/328 - 7s - loss: 3.8240e-05 - val_loss: 2.1258e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 92/100\n",
      "328/328 - 7s - loss: 3.7387e-05 - val_loss: 2.1180e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 93/100\n",
      "328/328 - 7s - loss: 3.9320e-05 - val_loss: 2.5172e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 94/100\n",
      "328/328 - 7s - loss: 4.2901e-05 - val_loss: 3.1021e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 95/100\n",
      "328/328 - 7s - loss: 4.4395e-05 - val_loss: 3.1890e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 96/100\n",
      "328/328 - 7s - loss: 4.1869e-05 - val_loss: 2.7275e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "328/328 - 7s - loss: 3.8535e-05 - val_loss: 2.1907e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "328/328 - 7s - loss: 3.6673e-05 - val_loss: 2.0561e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "328/328 - 7s - loss: 3.7637e-05 - val_loss: 2.2800e-05 - 7s/epoch - 20ms/step\n",
      "Epoch 100/100\n",
      "328/328 - 7s - loss: 4.0699e-05 - val_loss: 2.8470e-05 - 7s/epoch - 20ms/step\n"
     ]
    }
   ],
   "source": [
    "lstms2 = []\n",
    "models2 = []\n",
    "for batch, epoch, neuron in hyperparam2:\n",
    "    model, lstm = LSTMUnit.train_lstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    lstms2.append(lstm)\n",
    "    models2.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ecec446-1f6b-4f7c-8a44-e9c3caf29c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "356.9328889510239\n",
      "MAE\n",
      "304.1010632204618\n",
      "MAPE\n",
      "1.5928514228878161\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "359.45034341680923\n",
      "MAE\n",
      "309.2315395428081\n",
      "MAPE\n",
      "1.6193136133219523\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "424.8578107788535\n",
      "MAE\n",
      "376.9279493050554\n",
      "MAPE\n",
      "1.971545738547625\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "313.85600928332093\n",
      "MAE\n",
      "263.27748007474815\n",
      "MAPE\n",
      "1.3787624963085103\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "316.0566504841478\n",
      "MAE\n",
      "269.57736923631177\n",
      "MAPE\n",
      "1.411252954862071\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "299.66338592999915\n",
      "MAE\n",
      "257.2941130598588\n",
      "MAPE\n",
      "1.3411034424104857\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "333.68977012530473\n",
      "MAE\n",
      "283.02699759846365\n",
      "MAPE\n",
      "1.483246714869039\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "276.30223814764406\n",
      "MAE\n",
      "232.38963245977428\n",
      "MAPE\n",
      "1.2107839925392994\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(64, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "344.16850575017816\n",
      "MAE\n",
      "297.9145095986441\n",
      "MAPE\n",
      "1.5592258823025917\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb2 = Workbook()\n",
    "ws2 = wb2.active\n",
    "for m in models2:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = LSTMUnit.predict(test_x2, m)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparam2[i])\n",
    "    print(\"Epoch: \"+ str(lstms2[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].units))\n",
    "    i = i+1\n",
    "    ws2['A'+str(i)] = 'LSTM'\n",
    "    ws2['B'+str(i)] = hyperparam2[i-1][0]\n",
    "    ws2['C'+str(i)] = hyperparam2[i-1][1]\n",
    "    ws2['D'+str(i)] = hyperparam2[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
    "    ws2['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
    "    print('MAE')\n",
    "    print(Evaluation.mae(inv_y,inv_yhat))\n",
    "    ws2['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
    "    print('MAPE')\n",
    "    print(Evaluation.mape(inv_y,inv_yhat))\n",
    "    ws2['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
    "    LSTMUnit.save_model(m, 0, 'BTC',hyperparam2[i-1])\n",
    "    with open('LSTM_BTC'+str(hyperparam2[i-1])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(lstms2[i-1].history, f)\n",
    "wb2.save('LSTM_BTC_result2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "784abd2d-2770-44d6-b780-c4229562b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:25:23.554965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:25:23.645816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:25:23.856083: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:25:27.622234: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:25:27.656576: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 9.8583e-04 - val_loss: 8.5878e-04 - 5s/epoch - 31ms/step\n",
      "Epoch 2/25\n",
      "164/164 - 3s - loss: 0.0010 - val_loss: 0.0034 - 3s/epoch - 21ms/step\n",
      "Epoch 3/25\n",
      "164/164 - 3s - loss: 0.0015 - val_loss: 0.0046 - 3s/epoch - 21ms/step\n",
      "Epoch 4/25\n",
      "164/164 - 3s - loss: 0.0017 - val_loss: 0.0073 - 3s/epoch - 21ms/step\n",
      "Epoch 5/25\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0075 - 3s/epoch - 21ms/step\n",
      "Epoch 6/25\n",
      "164/164 - 3s - loss: 0.0020 - val_loss: 0.0080 - 3s/epoch - 21ms/step\n",
      "Epoch 7/25\n",
      "164/164 - 3s - loss: 0.0024 - val_loss: 0.0075 - 3s/epoch - 21ms/step\n",
      "Epoch 8/25\n",
      "164/164 - 3s - loss: 0.0026 - val_loss: 0.0056 - 3s/epoch - 21ms/step\n",
      "Epoch 9/25\n",
      "164/164 - 3s - loss: 0.0026 - val_loss: 0.0028 - 3s/epoch - 21ms/step\n",
      "Epoch 10/25\n",
      "164/164 - 3s - loss: 0.0020 - val_loss: 9.9947e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 11/25\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 2.3483e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 12/25\n",
      "164/164 - 3s - loss: 0.0010 - val_loss: 7.0982e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 13/25\n",
      "164/164 - 3s - loss: 7.5142e-04 - val_loss: 6.2273e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 14/25\n",
      "164/164 - 3s - loss: 5.7949e-04 - val_loss: 6.3225e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 15/25\n",
      "164/164 - 3s - loss: 4.6362e-04 - val_loss: 5.4274e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 16/25\n",
      "164/164 - 3s - loss: 3.8938e-04 - val_loss: 4.3874e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 17/25\n",
      "164/164 - 3s - loss: 3.4806e-04 - val_loss: 4.3878e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 18/25\n",
      "164/164 - 3s - loss: 3.3418e-04 - val_loss: 6.5592e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 19/25\n",
      "164/164 - 3s - loss: 3.4453e-04 - val_loss: 1.1921e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 20/25\n",
      "164/164 - 3s - loss: 3.7736e-04 - val_loss: 2.1252e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 21/25\n",
      "164/164 - 3s - loss: 4.3164e-04 - val_loss: 3.4752e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 22/25\n",
      "164/164 - 3s - loss: 5.0583e-04 - val_loss: 5.1338e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 23/25\n",
      "164/164 - 3s - loss: 5.9414e-04 - val_loss: 6.7018e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 24/25\n",
      "164/164 - 3s - loss: 6.8505e-04 - val_loss: 7.8013e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 25/25\n",
      "164/164 - 3s - loss: 7.8259e-04 - val_loss: 8.8387e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:26:50.832850: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:26:50.922538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:26:51.138875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:26:54.811304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:26:54.842011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 3.8332e-04 - val_loss: 1.8848e-04 - 5s/epoch - 31ms/step\n",
      "Epoch 2/25\n",
      "164/164 - 3s - loss: 1.8833e-04 - val_loss: 2.4565e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 3/25\n",
      "164/164 - 3s - loss: 2.3210e-04 - val_loss: 3.8624e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 4/25\n",
      "164/164 - 3s - loss: 3.4307e-04 - val_loss: 7.9432e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 5/25\n",
      "164/164 - 3s - loss: 6.8678e-04 - val_loss: 0.0020 - 3s/epoch - 20ms/step\n",
      "Epoch 6/25\n",
      "164/164 - 3s - loss: 0.0010 - val_loss: 0.0028 - 3s/epoch - 20ms/step\n",
      "Epoch 7/25\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 0.0035 - 3s/epoch - 20ms/step\n",
      "Epoch 8/25\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0052 - 3s/epoch - 20ms/step\n",
      "Epoch 9/25\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 0.0052 - 3s/epoch - 20ms/step\n",
      "Epoch 10/25\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0048 - 3s/epoch - 20ms/step\n",
      "Epoch 11/25\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 0.0046 - 3s/epoch - 20ms/step\n",
      "Epoch 12/25\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 0.0042 - 3s/epoch - 20ms/step\n",
      "Epoch 13/25\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 0.0041 - 3s/epoch - 20ms/step\n",
      "Epoch 14/25\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0040 - 3s/epoch - 20ms/step\n",
      "Epoch 15/25\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 0.0036 - 3s/epoch - 20ms/step\n",
      "Epoch 16/25\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 0.0026 - 3s/epoch - 20ms/step\n",
      "Epoch 17/25\n",
      "164/164 - 3s - loss: 0.0015 - val_loss: 0.0014 - 3s/epoch - 20ms/step\n",
      "Epoch 18/25\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 5.4404e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 19/25\n",
      "164/164 - 3s - loss: 0.0010 - val_loss: 1.2738e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 20/25\n",
      "164/164 - 3s - loss: 7.6984e-04 - val_loss: 5.8182e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 21/25\n",
      "164/164 - 3s - loss: 5.7914e-04 - val_loss: 6.4431e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 22/25\n",
      "164/164 - 3s - loss: 4.4537e-04 - val_loss: 6.6167e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 23/25\n",
      "164/164 - 3s - loss: 3.5625e-04 - val_loss: 5.5251e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 24/25\n",
      "164/164 - 3s - loss: 3.0039e-04 - val_loss: 4.0948e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 25/25\n",
      "164/164 - 3s - loss: 2.7065e-04 - val_loss: 3.4145e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:28:15.949705: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:28:16.055852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:28:16.266264: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:28:20.140380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:28:20.172569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 6s - loss: 5.4614e-04 - val_loss: 4.1197e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 2/25\n",
      "164/164 - 3s - loss: 3.1492e-04 - val_loss: 6.7419e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 3/25\n",
      "164/164 - 3s - loss: 6.0704e-04 - val_loss: 0.0011 - 3s/epoch - 21ms/step\n",
      "Epoch 4/25\n",
      "164/164 - 4s - loss: 0.0011 - val_loss: 0.0035 - 4s/epoch - 22ms/step\n",
      "Epoch 5/25\n",
      "164/164 - 3s - loss: 0.0015 - val_loss: 0.0036 - 3s/epoch - 21ms/step\n",
      "Epoch 6/25\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 0.0039 - 3s/epoch - 21ms/step\n",
      "Epoch 7/25\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 0.0045 - 3s/epoch - 21ms/step\n",
      "Epoch 8/25\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0049 - 3s/epoch - 21ms/step\n",
      "Epoch 9/25\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 0.0045 - 3s/epoch - 21ms/step\n",
      "Epoch 10/25\n",
      "164/164 - 4s - loss: 0.0011 - val_loss: 0.0043 - 4s/epoch - 22ms/step\n",
      "Epoch 11/25\n",
      "164/164 - 3s - loss: 0.0010 - val_loss: 0.0039 - 3s/epoch - 21ms/step\n",
      "Epoch 12/25\n",
      "164/164 - 3s - loss: 9.9813e-04 - val_loss: 0.0040 - 3s/epoch - 21ms/step\n",
      "Epoch 13/25\n",
      "164/164 - 3s - loss: 0.0010 - val_loss: 0.0040 - 3s/epoch - 21ms/step\n",
      "Epoch 14/25\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 0.0042 - 3s/epoch - 21ms/step\n",
      "Epoch 15/25\n",
      "164/164 - 4s - loss: 0.0012 - val_loss: 0.0044 - 4s/epoch - 22ms/step\n",
      "Epoch 16/25\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0047 - 4s/epoch - 22ms/step\n",
      "Epoch 17/25\n",
      "164/164 - 3s - loss: 0.0017 - val_loss: 0.0044 - 3s/epoch - 21ms/step\n",
      "Epoch 18/25\n",
      "164/164 - 3s - loss: 0.0019 - val_loss: 0.0036 - 3s/epoch - 21ms/step\n",
      "Epoch 19/25\n",
      "164/164 - 3s - loss: 0.0019 - val_loss: 0.0022 - 3s/epoch - 21ms/step\n",
      "Epoch 20/25\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 0.0010 - 3s/epoch - 21ms/step\n",
      "Epoch 21/25\n",
      "164/164 - 4s - loss: 0.0012 - val_loss: 2.8657e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 22/25\n",
      "164/164 - 4s - loss: 8.6598e-04 - val_loss: 8.4765e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 23/25\n",
      "164/164 - 3s - loss: 6.5619e-04 - val_loss: 5.2374e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 24/25\n",
      "164/164 - 3s - loss: 5.2214e-04 - val_loss: 4.4839e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 25/25\n",
      "164/164 - 3s - loss: 4.3036e-04 - val_loss: 4.0794e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:29:45.094885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:29:45.182217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:29:45.373031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:29:49.118463: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:29:49.149749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 5.9923e-04 - val_loss: 3.2067e-04 - 5s/epoch - 31ms/step\n",
      "Epoch 2/50\n",
      "164/164 - 3s - loss: 3.4136e-04 - val_loss: 5.4893e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 3/50\n",
      "164/164 - 3s - loss: 6.8104e-04 - val_loss: 0.0017 - 3s/epoch - 21ms/step\n",
      "Epoch 4/50\n",
      "164/164 - 3s - loss: 9.9455e-04 - val_loss: 0.0026 - 3s/epoch - 21ms/step\n",
      "Epoch 5/50\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 0.0030 - 3s/epoch - 21ms/step\n",
      "Epoch 6/50\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 0.0047 - 3s/epoch - 21ms/step\n",
      "Epoch 7/50\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0047 - 3s/epoch - 21ms/step\n",
      "Epoch 8/50\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0051 - 3s/epoch - 21ms/step\n",
      "Epoch 9/50\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 0.0054 - 3s/epoch - 21ms/step\n",
      "Epoch 10/50\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 0.0052 - 3s/epoch - 21ms/step\n",
      "Epoch 11/50\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 0.0048 - 3s/epoch - 21ms/step\n",
      "Epoch 12/50\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0038 - 3s/epoch - 21ms/step\n",
      "Epoch 13/50\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0024 - 3s/epoch - 21ms/step\n",
      "Epoch 14/50\n",
      "164/164 - 3s - loss: 0.0015 - val_loss: 0.0011 - 3s/epoch - 21ms/step\n",
      "Epoch 15/50\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 3.4744e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 16/50\n",
      "164/164 - 3s - loss: 9.0590e-04 - val_loss: 9.8413e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 17/50\n",
      "164/164 - 3s - loss: 7.0443e-04 - val_loss: 5.8891e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 18/50\n",
      "164/164 - 3s - loss: 5.5786e-04 - val_loss: 5.6520e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 19/50\n",
      "164/164 - 3s - loss: 4.5520e-04 - val_loss: 5.3896e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 20/50\n",
      "164/164 - 3s - loss: 3.8591e-04 - val_loss: 4.7633e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 21/50\n",
      "164/164 - 4s - loss: 3.4346e-04 - val_loss: 4.5062e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 22/50\n",
      "164/164 - 3s - loss: 3.2344e-04 - val_loss: 5.4575e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 23/50\n",
      "164/164 - 3s - loss: 3.2274e-04 - val_loss: 8.3274e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 24/50\n",
      "164/164 - 3s - loss: 3.3910e-04 - val_loss: 1.3635e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 25/50\n",
      "164/164 - 3s - loss: 3.7087e-04 - val_loss: 2.1633e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 26/50\n",
      "164/164 - 3s - loss: 4.1664e-04 - val_loss: 3.2080e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 27/50\n",
      "164/164 - 3s - loss: 4.7420e-04 - val_loss: 4.3720e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 28/50\n",
      "164/164 - 3s - loss: 5.3764e-04 - val_loss: 5.2912e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 29/50\n",
      "164/164 - 3s - loss: 6.0712e-04 - val_loss: 6.2110e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 30/50\n",
      "164/164 - 3s - loss: 6.7121e-04 - val_loss: 7.0425e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 31/50\n",
      "164/164 - 3s - loss: 7.8585e-04 - val_loss: 9.3429e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 32/50\n",
      "164/164 - 3s - loss: 8.6622e-04 - val_loss: 7.6541e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 33/50\n",
      "164/164 - 3s - loss: 8.2757e-04 - val_loss: 4.2638e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 34/50\n",
      "164/164 - 3s - loss: 6.8128e-04 - val_loss: 1.5080e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 35/50\n",
      "164/164 - 3s - loss: 5.2954e-04 - val_loss: 7.1159e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 36/50\n",
      "164/164 - 3s - loss: 4.1779e-04 - val_loss: 7.5168e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 37/50\n",
      "164/164 - 3s - loss: 3.4295e-04 - val_loss: 8.0105e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 38/50\n",
      "164/164 - 3s - loss: 2.9495e-04 - val_loss: 7.1902e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 39/50\n",
      "164/164 - 3s - loss: 2.6724e-04 - val_loss: 5.8997e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 40/50\n",
      "164/164 - 3s - loss: 2.5679e-04 - val_loss: 5.3267e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 41/50\n",
      "164/164 - 3s - loss: 2.6183e-04 - val_loss: 6.5527e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 42/50\n",
      "164/164 - 3s - loss: 2.8118e-04 - val_loss: 1.0429e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 43/50\n",
      "164/164 - 3s - loss: 3.1394e-04 - val_loss: 1.6952e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 44/50\n",
      "164/164 - 3s - loss: 3.5671e-04 - val_loss: 2.3620e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 45/50\n",
      "164/164 - 3s - loss: 4.1102e-04 - val_loss: 3.4546e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 46/50\n",
      "164/164 - 3s - loss: 4.7305e-04 - val_loss: 4.4778e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 47/50\n",
      "164/164 - 3s - loss: 5.7424e-04 - val_loss: 6.4228e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 48/50\n",
      "164/164 - 3s - loss: 6.1037e-04 - val_loss: 4.9921e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 49/50\n",
      "164/164 - 3s - loss: 6.1445e-04 - val_loss: 3.7054e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 50/50\n",
      "164/164 - 3s - loss: 5.4675e-04 - val_loss: 1.7580e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:32:38.521768: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:32:38.607789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:32:38.808993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:32:42.439982: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:32:42.470538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 4.9837e-04 - val_loss: 3.0074e-04 - 5s/epoch - 30ms/step\n",
      "Epoch 2/50\n",
      "164/164 - 3s - loss: 5.7996e-04 - val_loss: 8.3691e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 3/50\n",
      "164/164 - 3s - loss: 9.6723e-04 - val_loss: 0.0027 - 3s/epoch - 20ms/step\n",
      "Epoch 4/50\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0036 - 3s/epoch - 20ms/step\n",
      "Epoch 5/50\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 0.0058 - 3s/epoch - 21ms/step\n",
      "Epoch 6/50\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 0.0062 - 3s/epoch - 20ms/step\n",
      "Epoch 7/50\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 0.0067 - 3s/epoch - 20ms/step\n",
      "Epoch 8/50\n",
      "164/164 - 3s - loss: 0.0017 - val_loss: 0.0066 - 3s/epoch - 20ms/step\n",
      "Epoch 9/50\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0061 - 3s/epoch - 20ms/step\n",
      "Epoch 10/50\n",
      "164/164 - 3s - loss: 0.0021 - val_loss: 0.0051 - 3s/epoch - 20ms/step\n",
      "Epoch 11/50\n",
      "164/164 - 3s - loss: 0.0021 - val_loss: 0.0033 - 3s/epoch - 20ms/step\n",
      "Epoch 12/50\n",
      "164/164 - 3s - loss: 0.0020 - val_loss: 0.0016 - 3s/epoch - 20ms/step\n",
      "Epoch 13/50\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 4.6980e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 14/50\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 1.0318e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 15/50\n",
      "164/164 - 3s - loss: 8.2022e-04 - val_loss: 7.1485e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 16/50\n",
      "164/164 - 3s - loss: 6.1622e-04 - val_loss: 8.1517e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 17/50\n",
      "164/164 - 3s - loss: 4.7962e-04 - val_loss: 7.3382e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 18/50\n",
      "164/164 - 3s - loss: 3.9240e-04 - val_loss: 5.5551e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 19/50\n",
      "164/164 - 3s - loss: 3.4266e-04 - val_loss: 4.3538e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 20/50\n",
      "164/164 - 3s - loss: 3.2273e-04 - val_loss: 5.0382e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 21/50\n",
      "164/164 - 3s - loss: 3.2796e-04 - val_loss: 8.6130e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 22/50\n",
      "164/164 - 3s - loss: 3.5571e-04 - val_loss: 1.5777e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 23/50\n",
      "164/164 - 3s - loss: 4.0445e-04 - val_loss: 2.6808e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 24/50\n",
      "164/164 - 3s - loss: 4.7281e-04 - val_loss: 4.1119e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 25/50\n",
      "164/164 - 3s - loss: 5.5752e-04 - val_loss: 5.6046e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 26/50\n",
      "164/164 - 3s - loss: 6.5103e-04 - val_loss: 6.6940e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 27/50\n",
      "164/164 - 3s - loss: 7.4535e-04 - val_loss: 7.4766e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 28/50\n",
      "164/164 - 3s - loss: 8.2998e-04 - val_loss: 7.5560e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 29/50\n",
      "164/164 - 3s - loss: 8.5998e-04 - val_loss: 6.7719e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 30/50\n",
      "164/164 - 3s - loss: 8.8634e-04 - val_loss: 5.4630e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 31/50\n",
      "164/164 - 3s - loss: 8.2586e-04 - val_loss: 2.6054e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 32/50\n",
      "164/164 - 3s - loss: 6.6324e-04 - val_loss: 9.6466e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 33/50\n",
      "164/164 - 3s - loss: 5.0702e-04 - val_loss: 7.6160e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 34/50\n",
      "164/164 - 3s - loss: 4.0131e-04 - val_loss: 8.6128e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 35/50\n",
      "164/164 - 3s - loss: 3.3489e-04 - val_loss: 7.9685e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 36/50\n",
      "164/164 - 3s - loss: 2.9644e-04 - val_loss: 6.4046e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 37/50\n",
      "164/164 - 3s - loss: 2.7968e-04 - val_loss: 5.4002e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 38/50\n",
      "164/164 - 3s - loss: 2.8143e-04 - val_loss: 6.1358e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 39/50\n",
      "164/164 - 3s - loss: 3.0001e-04 - val_loss: 9.4641e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 40/50\n",
      "164/164 - 3s - loss: 3.3436e-04 - val_loss: 1.5746e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 41/50\n",
      "164/164 - 3s - loss: 3.8265e-04 - val_loss: 2.3626e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 42/50\n",
      "164/164 - 3s - loss: 4.4356e-04 - val_loss: 3.0702e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 43/50\n",
      "164/164 - 3s - loss: 5.0459e-04 - val_loss: 3.7332e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 44/50\n",
      "164/164 - 3s - loss: 6.1379e-04 - val_loss: 6.4806e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 45/50\n",
      "164/164 - 3s - loss: 7.3134e-04 - val_loss: 6.9817e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 46/50\n",
      "164/164 - 3s - loss: 7.8721e-04 - val_loss: 4.5717e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 47/50\n",
      "164/164 - 3s - loss: 6.8064e-04 - val_loss: 1.7328e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 48/50\n",
      "164/164 - 3s - loss: 5.1901e-04 - val_loss: 6.7548e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 49/50\n",
      "164/164 - 3s - loss: 3.7890e-04 - val_loss: 8.5578e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 50/50\n",
      "164/164 - 3s - loss: 2.8105e-04 - val_loss: 1.1045e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:35:26.257351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:35:26.336942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:35:26.540680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:35:30.322345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:35:30.353749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 5.6854e-04 - val_loss: 4.1953e-04 - 5s/epoch - 32ms/step\n",
      "Epoch 2/50\n",
      "164/164 - 4s - loss: 3.1695e-04 - val_loss: 6.7165e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 3/50\n",
      "164/164 - 3s - loss: 5.2515e-04 - val_loss: 0.0010 - 3s/epoch - 21ms/step\n",
      "Epoch 4/50\n",
      "164/164 - 4s - loss: 0.0011 - val_loss: 0.0038 - 4s/epoch - 22ms/step\n",
      "Epoch 5/50\n",
      "164/164 - 4s - loss: 0.0016 - val_loss: 0.0039 - 4s/epoch - 22ms/step\n",
      "Epoch 6/50\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0046 - 3s/epoch - 21ms/step\n",
      "Epoch 7/50\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0048 - 4s/epoch - 22ms/step\n",
      "Epoch 8/50\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0054 - 4s/epoch - 21ms/step\n",
      "Epoch 9/50\n",
      "164/164 - 4s - loss: 0.0013 - val_loss: 0.0051 - 4s/epoch - 22ms/step\n",
      "Epoch 10/50\n",
      "164/164 - 4s - loss: 0.0012 - val_loss: 0.0046 - 4s/epoch - 22ms/step\n",
      "Epoch 11/50\n",
      "164/164 - 4s - loss: 0.0011 - val_loss: 0.0043 - 4s/epoch - 22ms/step\n",
      "Epoch 12/50\n",
      "164/164 - 4s - loss: 0.0011 - val_loss: 0.0044 - 4s/epoch - 21ms/step\n",
      "Epoch 13/50\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 0.0045 - 3s/epoch - 21ms/step\n",
      "Epoch 14/50\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 0.0046 - 3s/epoch - 21ms/step\n",
      "Epoch 15/50\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0047 - 4s/epoch - 21ms/step\n",
      "Epoch 16/50\n",
      "164/164 - 3s - loss: 0.0017 - val_loss: 0.0047 - 3s/epoch - 21ms/step\n",
      "Epoch 17/50\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0038 - 3s/epoch - 21ms/step\n",
      "Epoch 18/50\n",
      "164/164 - 3s - loss: 0.0019 - val_loss: 0.0027 - 3s/epoch - 21ms/step\n",
      "Epoch 19/50\n",
      "164/164 - 4s - loss: 0.0017 - val_loss: 0.0014 - 4s/epoch - 21ms/step\n",
      "Epoch 20/50\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 4.9471e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 21/50\n",
      "164/164 - 4s - loss: 0.0011 - val_loss: 1.3175e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 22/50\n",
      "164/164 - 3s - loss: 8.1768e-04 - val_loss: 6.6484e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 23/50\n",
      "164/164 - 3s - loss: 6.3944e-04 - val_loss: 5.5017e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 24/50\n",
      "164/164 - 4s - loss: 5.1015e-04 - val_loss: 4.9031e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 25/50\n",
      "164/164 - 3s - loss: 4.1968e-04 - val_loss: 4.4627e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 26/50\n",
      "164/164 - 3s - loss: 3.6385e-04 - val_loss: 4.7445e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 27/50\n",
      "164/164 - 3s - loss: 3.3559e-04 - val_loss: 6.4027e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 28/50\n",
      "164/164 - 4s - loss: 3.2942e-04 - val_loss: 9.9341e-05 - 4s/epoch - 22ms/step\n",
      "Epoch 29/50\n",
      "164/164 - 4s - loss: 3.4069e-04 - val_loss: 1.5623e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 30/50\n",
      "164/164 - 4s - loss: 3.6596e-04 - val_loss: 2.3606e-04 - 4s/epoch - 22ms/step\n",
      "Epoch 31/50\n",
      "164/164 - 4s - loss: 4.0293e-04 - val_loss: 3.3827e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 32/50\n",
      "164/164 - 3s - loss: 4.4988e-04 - val_loss: 4.5679e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 33/50\n",
      "164/164 - 4s - loss: 5.0430e-04 - val_loss: 5.7404e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 34/50\n",
      "164/164 - 3s - loss: 5.6374e-04 - val_loss: 6.7470e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 35/50\n",
      "164/164 - 4s - loss: 6.2550e-04 - val_loss: 7.5066e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 36/50\n",
      "164/164 - 3s - loss: 6.8286e-04 - val_loss: 7.8634e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 37/50\n",
      "164/164 - 3s - loss: 7.6423e-04 - val_loss: 9.4045e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 38/50\n",
      "164/164 - 3s - loss: 8.1173e-04 - val_loss: 9.3085e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 39/50\n",
      "164/164 - 4s - loss: 8.0741e-04 - val_loss: 6.5963e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 40/50\n",
      "164/164 - 3s - loss: 7.0403e-04 - val_loss: 3.4077e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 41/50\n",
      "164/164 - 3s - loss: 5.7963e-04 - val_loss: 1.4263e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 42/50\n",
      "164/164 - 4s - loss: 4.7181e-04 - val_loss: 7.7627e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 43/50\n",
      "164/164 - 3s - loss: 3.9856e-04 - val_loss: 6.7804e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 44/50\n",
      "164/164 - 4s - loss: 3.5107e-04 - val_loss: 6.4231e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 45/50\n",
      "164/164 - 3s - loss: 3.2078e-04 - val_loss: 6.1272e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 46/50\n",
      "164/164 - 4s - loss: 3.0453e-04 - val_loss: 6.3841e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 47/50\n",
      "164/164 - 3s - loss: 3.0086e-04 - val_loss: 7.8374e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 48/50\n",
      "164/164 - 3s - loss: 3.0884e-04 - val_loss: 1.0887e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 49/50\n",
      "164/164 - 3s - loss: 3.2832e-04 - val_loss: 1.5298e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 50/50\n",
      "164/164 - 3s - loss: 3.5893e-04 - val_loss: 2.1847e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:38:23.389340: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:38:23.467742: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:38:23.671241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:38:27.523400: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:38:27.554617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 7.8473e-04 - val_loss: 6.7783e-04 - 5s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "164/164 - 3s - loss: 8.0284e-04 - val_loss: 0.0026 - 3s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 0.0029 - 3s/epoch - 21ms/step\n",
      "Epoch 4/100\n",
      "164/164 - 3s - loss: 0.0013 - val_loss: 0.0046 - 3s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0057 - 4s/epoch - 22ms/step\n",
      "Epoch 6/100\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0056 - 4s/epoch - 21ms/step\n",
      "Epoch 7/100\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 0.0057 - 3s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "164/164 - 3s - loss: 0.0015 - val_loss: 0.0059 - 3s/epoch - 21ms/step\n",
      "Epoch 9/100\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0058 - 3s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "164/164 - 3s - loss: 0.0020 - val_loss: 0.0046 - 3s/epoch - 21ms/step\n",
      "Epoch 11/100\n",
      "164/164 - 3s - loss: 0.0021 - val_loss: 0.0028 - 3s/epoch - 21ms/step\n",
      "Epoch 12/100\n",
      "164/164 - 3s - loss: 0.0019 - val_loss: 0.0011 - 3s/epoch - 21ms/step\n",
      "Epoch 13/100\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 2.2767e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 14/100\n",
      "164/164 - 3s - loss: 9.6334e-04 - val_loss: 6.8867e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 15/100\n",
      "164/164 - 3s - loss: 7.0360e-04 - val_loss: 6.8945e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 16/100\n",
      "164/164 - 3s - loss: 5.3603e-04 - val_loss: 6.8386e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 17/100\n",
      "164/164 - 3s - loss: 4.2917e-04 - val_loss: 5.5218e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 18/100\n",
      "164/164 - 3s - loss: 3.6533e-04 - val_loss: 4.3556e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 19/100\n",
      "164/164 - 3s - loss: 3.3396e-04 - val_loss: 4.6187e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "164/164 - 3s - loss: 3.2852e-04 - val_loss: 7.2270e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 21/100\n",
      "164/164 - 3s - loss: 3.4505e-04 - val_loss: 1.2765e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "164/164 - 3s - loss: 3.8091e-04 - val_loss: 2.1419e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "164/164 - 3s - loss: 4.3369e-04 - val_loss: 3.2755e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 24/100\n",
      "164/164 - 3s - loss: 5.0014e-04 - val_loss: 4.5253e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "164/164 - 3s - loss: 5.7276e-04 - val_loss: 5.4837e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 26/100\n",
      "164/164 - 3s - loss: 6.4269e-04 - val_loss: 6.3676e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 27/100\n",
      "164/164 - 3s - loss: 7.3683e-04 - val_loss: 6.8977e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 28/100\n",
      "164/164 - 3s - loss: 8.0511e-04 - val_loss: 6.5235e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 29/100\n",
      "164/164 - 3s - loss: 7.9704e-04 - val_loss: 4.5828e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 30/100\n",
      "164/164 - 3s - loss: 7.2169e-04 - val_loss: 2.6298e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 31/100\n",
      "164/164 - 3s - loss: 6.1101e-04 - val_loss: 1.3276e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 32/100\n",
      "164/164 - 3s - loss: 5.0538e-04 - val_loss: 8.2512e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "164/164 - 3s - loss: 4.2656e-04 - val_loss: 7.1186e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "164/164 - 3s - loss: 3.7476e-04 - val_loss: 6.7803e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "164/164 - 3s - loss: 3.4419e-04 - val_loss: 6.7402e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 36/100\n",
      "164/164 - 3s - loss: 3.3090e-04 - val_loss: 7.4039e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 37/100\n",
      "164/164 - 3s - loss: 3.3211e-04 - val_loss: 9.2101e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 38/100\n",
      "164/164 - 3s - loss: 3.4550e-04 - val_loss: 1.2333e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 39/100\n",
      "164/164 - 3s - loss: 3.6780e-04 - val_loss: 1.6159e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "164/164 - 3s - loss: 3.9503e-04 - val_loss: 2.0435e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 41/100\n",
      "164/164 - 3s - loss: 4.4829e-04 - val_loss: 2.8376e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "164/164 - 3s - loss: 5.0549e-04 - val_loss: 3.4645e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 43/100\n",
      "164/164 - 3s - loss: 5.5768e-04 - val_loss: 3.9750e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 44/100\n",
      "164/164 - 3s - loss: 6.0120e-04 - val_loss: 4.1441e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 45/100\n",
      "164/164 - 3s - loss: 5.8941e-04 - val_loss: 2.7304e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 46/100\n",
      "164/164 - 3s - loss: 5.2366e-04 - val_loss: 1.3468e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 47/100\n",
      "164/164 - 3s - loss: 4.2429e-04 - val_loss: 7.5333e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 48/100\n",
      "164/164 - 3s - loss: 3.4336e-04 - val_loss: 6.6396e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 49/100\n",
      "164/164 - 3s - loss: 2.9005e-04 - val_loss: 6.4669e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 50/100\n",
      "164/164 - 3s - loss: 2.5882e-04 - val_loss: 5.9240e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "164/164 - 3s - loss: 2.4450e-04 - val_loss: 5.5189e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 52/100\n",
      "164/164 - 3s - loss: 2.4418e-04 - val_loss: 5.9948e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "164/164 - 3s - loss: 2.5621e-04 - val_loss: 7.9741e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 54/100\n",
      "164/164 - 3s - loss: 2.7879e-04 - val_loss: 1.1492e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 55/100\n",
      "164/164 - 3s - loss: 3.0945e-04 - val_loss: 1.5222e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 56/100\n",
      "164/164 - 3s - loss: 3.4627e-04 - val_loss: 2.0608e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "164/164 - 3s - loss: 4.0559e-04 - val_loss: 3.0913e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 58/100\n",
      "164/164 - 3s - loss: 4.5015e-04 - val_loss: 3.0615e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "164/164 - 3s - loss: 4.8819e-04 - val_loss: 3.1186e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 60/100\n",
      "164/164 - 3s - loss: 4.9675e-04 - val_loss: 2.4198e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 61/100\n",
      "164/164 - 3s - loss: 4.6086e-04 - val_loss: 1.3362e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 62/100\n",
      "164/164 - 3s - loss: 3.8116e-04 - val_loss: 7.0577e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 63/100\n",
      "164/164 - 3s - loss: 3.0178e-04 - val_loss: 6.2784e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 64/100\n",
      "164/164 - 3s - loss: 2.4529e-04 - val_loss: 6.6309e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 65/100\n",
      "164/164 - 3s - loss: 2.1103e-04 - val_loss: 6.1224e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "164/164 - 3s - loss: 1.9366e-04 - val_loss: 5.0676e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 67/100\n",
      "164/164 - 3s - loss: 1.8985e-04 - val_loss: 4.4755e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "164/164 - 3s - loss: 1.9864e-04 - val_loss: 5.1771e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 69/100\n",
      "164/164 - 3s - loss: 2.1986e-04 - val_loss: 7.6179e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 70/100\n",
      "164/164 - 3s - loss: 2.5010e-04 - val_loss: 1.1504e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 71/100\n",
      "164/164 - 3s - loss: 2.8584e-04 - val_loss: 1.4769e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 72/100\n",
      "164/164 - 3s - loss: 3.3808e-04 - val_loss: 2.6940e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 73/100\n",
      "164/164 - 3s - loss: 4.0247e-04 - val_loss: 3.4329e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 74/100\n",
      "164/164 - 3s - loss: 4.7315e-04 - val_loss: 3.9991e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 75/100\n",
      "164/164 - 3s - loss: 5.1324e-04 - val_loss: 2.6981e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 76/100\n",
      "164/164 - 3s - loss: 4.6408e-04 - val_loss: 1.1278e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 77/100\n",
      "164/164 - 3s - loss: 3.5470e-04 - val_loss: 6.1262e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "164/164 - 3s - loss: 2.5390e-04 - val_loss: 9.0397e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 79/100\n",
      "164/164 - 3s - loss: 1.9000e-04 - val_loss: 1.0298e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 80/100\n",
      "164/164 - 3s - loss: 1.5357e-04 - val_loss: 8.5844e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 81/100\n",
      "164/164 - 3s - loss: 1.3537e-04 - val_loss: 5.6770e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 82/100\n",
      "164/164 - 3s - loss: 1.3074e-04 - val_loss: 3.4809e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 83/100\n",
      "164/164 - 3s - loss: 1.3875e-04 - val_loss: 3.3743e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 84/100\n",
      "164/164 - 3s - loss: 1.5923e-04 - val_loss: 5.2844e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 85/100\n",
      "164/164 - 3s - loss: 1.8956e-04 - val_loss: 9.3669e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 86/100\n",
      "164/164 - 3s - loss: 2.3124e-04 - val_loss: 1.5919e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 87/100\n",
      "164/164 - 3s - loss: 2.8310e-04 - val_loss: 2.2666e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 88/100\n",
      "164/164 - 3s - loss: 3.5001e-04 - val_loss: 4.2571e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 89/100\n",
      "164/164 - 3s - loss: 4.4830e-04 - val_loss: 4.6624e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 90/100\n",
      "164/164 - 3s - loss: 4.7691e-04 - val_loss: 2.8049e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 91/100\n",
      "164/164 - 3s - loss: 4.3362e-04 - val_loss: 1.0696e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 92/100\n",
      "164/164 - 3s - loss: 3.3362e-04 - val_loss: 5.2502e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 93/100\n",
      "164/164 - 3s - loss: 2.3370e-04 - val_loss: 8.4306e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 94/100\n",
      "164/164 - 3s - loss: 1.6945e-04 - val_loss: 1.0042e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 95/100\n",
      "164/164 - 3s - loss: 1.3357e-04 - val_loss: 8.3202e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 96/100\n",
      "164/164 - 3s - loss: 1.1562e-04 - val_loss: 5.2294e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 97/100\n",
      "164/164 - 3s - loss: 1.1058e-04 - val_loss: 2.8752e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 98/100\n",
      "164/164 - 3s - loss: 1.1727e-04 - val_loss: 2.6772e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 99/100\n",
      "164/164 - 3s - loss: 1.3495e-04 - val_loss: 4.3297e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 100/100\n",
      "164/164 - 3s - loss: 1.6206e-04 - val_loss: 7.9139e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:44:09.540072: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:44:09.620951: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:44:09.884723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:44:13.565779: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:44:13.597200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 5.1707e-04 - val_loss: 1.3887e-04 - 5s/epoch - 31ms/step\n",
      "Epoch 2/100\n",
      "164/164 - 3s - loss: 4.9297e-04 - val_loss: 4.2974e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "164/164 - 3s - loss: 9.8703e-04 - val_loss: 0.0029 - 3s/epoch - 20ms/step\n",
      "Epoch 4/100\n",
      "164/164 - 3s - loss: 0.0015 - val_loss: 0.0038 - 3s/epoch - 20ms/step\n",
      "Epoch 5/100\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 0.0065 - 3s/epoch - 20ms/step\n",
      "Epoch 6/100\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0075 - 3s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "164/164 - 3s - loss: 0.0018 - val_loss: 0.0072 - 3s/epoch - 20ms/step\n",
      "Epoch 8/100\n",
      "164/164 - 3s - loss: 0.0020 - val_loss: 0.0072 - 3s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "164/164 - 3s - loss: 0.0023 - val_loss: 0.0060 - 3s/epoch - 20ms/step\n",
      "Epoch 10/100\n",
      "164/164 - 3s - loss: 0.0025 - val_loss: 0.0036 - 3s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "164/164 - 3s - loss: 0.0021 - val_loss: 0.0015 - 3s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "164/164 - 3s - loss: 0.0016 - val_loss: 4.3153e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "164/164 - 3s - loss: 0.0011 - val_loss: 9.5582e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 14/100\n",
      "164/164 - 3s - loss: 8.1836e-04 - val_loss: 8.1441e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 15/100\n",
      "164/164 - 3s - loss: 6.1169e-04 - val_loss: 9.4346e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 16/100\n",
      "164/164 - 3s - loss: 4.7882e-04 - val_loss: 8.4558e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 17/100\n",
      "164/164 - 3s - loss: 3.9618e-04 - val_loss: 6.4358e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 18/100\n",
      "164/164 - 3s - loss: 3.5128e-04 - val_loss: 5.1136e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 19/100\n",
      "164/164 - 3s - loss: 3.3665e-04 - val_loss: 5.8730e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 20/100\n",
      "164/164 - 3s - loss: 3.4790e-04 - val_loss: 9.7416e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 21/100\n",
      "164/164 - 3s - loss: 3.8257e-04 - val_loss: 1.7403e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 22/100\n",
      "164/164 - 3s - loss: 4.3916e-04 - val_loss: 2.9060e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 23/100\n",
      "164/164 - 3s - loss: 5.1603e-04 - val_loss: 4.3782e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 24/100\n",
      "164/164 - 3s - loss: 6.0825e-04 - val_loss: 5.7887e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "164/164 - 3s - loss: 7.0335e-04 - val_loss: 6.6542e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "164/164 - 3s - loss: 8.0381e-04 - val_loss: 7.4313e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "164/164 - 3s - loss: 8.8229e-04 - val_loss: 7.1918e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 28/100\n",
      "164/164 - 3s - loss: 9.4022e-04 - val_loss: 6.4233e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 29/100\n",
      "164/164 - 3s - loss: 9.0863e-04 - val_loss: 3.7578e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 30/100\n",
      "164/164 - 3s - loss: 7.6291e-04 - val_loss: 1.5551e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 31/100\n",
      "164/164 - 3s - loss: 6.0151e-04 - val_loss: 8.7981e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 32/100\n",
      "164/164 - 3s - loss: 4.7769e-04 - val_loss: 8.8526e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 33/100\n",
      "164/164 - 3s - loss: 3.9546e-04 - val_loss: 8.8818e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 34/100\n",
      "164/164 - 3s - loss: 3.4577e-04 - val_loss: 7.8307e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 35/100\n",
      "164/164 - 3s - loss: 3.2047e-04 - val_loss: 6.7789e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 36/100\n",
      "164/164 - 3s - loss: 3.1512e-04 - val_loss: 6.8819e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 37/100\n",
      "164/164 - 3s - loss: 3.2703e-04 - val_loss: 8.9623e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 38/100\n",
      "164/164 - 3s - loss: 3.5434e-04 - val_loss: 1.3474e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "164/164 - 3s - loss: 3.9477e-04 - val_loss: 1.9991e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 40/100\n",
      "164/164 - 3s - loss: 4.4402e-04 - val_loss: 2.6238e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 41/100\n",
      "164/164 - 3s - loss: 5.0440e-04 - val_loss: 3.2498e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 42/100\n",
      "164/164 - 3s - loss: 5.8545e-04 - val_loss: 4.8935e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 43/100\n",
      "164/164 - 3s - loss: 6.6345e-04 - val_loss: 5.9611e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 44/100\n",
      "164/164 - 3s - loss: 7.2982e-04 - val_loss: 4.8435e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 45/100\n",
      "164/164 - 3s - loss: 6.7792e-04 - val_loss: 2.3059e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 46/100\n",
      "164/164 - 3s - loss: 5.6675e-04 - val_loss: 1.1432e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 47/100\n",
      "164/164 - 3s - loss: 4.4158e-04 - val_loss: 7.3323e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 48/100\n",
      "164/164 - 3s - loss: 3.4328e-04 - val_loss: 8.5259e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 49/100\n",
      "164/164 - 3s - loss: 2.8188e-04 - val_loss: 8.8883e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 50/100\n",
      "164/164 - 3s - loss: 2.4726e-04 - val_loss: 7.5211e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 51/100\n",
      "164/164 - 3s - loss: 2.3174e-04 - val_loss: 5.7674e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 52/100\n",
      "164/164 - 3s - loss: 2.3198e-04 - val_loss: 5.0399e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 53/100\n",
      "164/164 - 3s - loss: 2.4708e-04 - val_loss: 6.4601e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 54/100\n",
      "164/164 - 3s - loss: 2.7750e-04 - val_loss: 1.0659e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 55/100\n",
      "164/164 - 3s - loss: 3.2027e-04 - val_loss: 1.5786e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 56/100\n",
      "164/164 - 3s - loss: 3.7868e-04 - val_loss: 2.7428e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "164/164 - 3s - loss: 4.2336e-04 - val_loss: 2.6989e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 58/100\n",
      "164/164 - 3s - loss: 5.3835e-04 - val_loss: 5.5730e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "164/164 - 3s - loss: 6.2220e-04 - val_loss: 5.4579e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 60/100\n",
      "164/164 - 3s - loss: 6.4894e-04 - val_loss: 3.2041e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "164/164 - 3s - loss: 5.4883e-04 - val_loss: 1.2032e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 62/100\n",
      "164/164 - 3s - loss: 4.2231e-04 - val_loss: 6.4648e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 63/100\n",
      "164/164 - 3s - loss: 3.0933e-04 - val_loss: 9.0955e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "164/164 - 3s - loss: 2.3825e-04 - val_loss: 1.0634e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 65/100\n",
      "164/164 - 3s - loss: 1.9797e-04 - val_loss: 9.2409e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 66/100\n",
      "164/164 - 3s - loss: 1.7703e-04 - val_loss: 6.4698e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 67/100\n",
      "164/164 - 3s - loss: 1.7092e-04 - val_loss: 4.1288e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 68/100\n",
      "164/164 - 3s - loss: 1.7827e-04 - val_loss: 3.6606e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 69/100\n",
      "164/164 - 3s - loss: 1.9981e-04 - val_loss: 5.8425e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 70/100\n",
      "164/164 - 3s - loss: 2.3526e-04 - val_loss: 1.0570e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 71/100\n",
      "164/164 - 3s - loss: 2.8070e-04 - val_loss: 1.7414e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 72/100\n",
      "164/164 - 3s - loss: 3.2828e-04 - val_loss: 2.3799e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 73/100\n",
      "164/164 - 3s - loss: 4.0325e-04 - val_loss: 3.7936e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 74/100\n",
      "164/164 - 3s - loss: 4.8487e-04 - val_loss: 5.8627e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 75/100\n",
      "164/164 - 3s - loss: 5.5175e-04 - val_loss: 4.0521e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 76/100\n",
      "164/164 - 3s - loss: 5.4380e-04 - val_loss: 2.3315e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 77/100\n",
      "164/164 - 3s - loss: 4.5898e-04 - val_loss: 7.7756e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 78/100\n",
      "164/164 - 3s - loss: 3.4430e-04 - val_loss: 5.7459e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 79/100\n",
      "164/164 - 3s - loss: 2.5206e-04 - val_loss: 8.8928e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 80/100\n",
      "164/164 - 3s - loss: 1.9438e-04 - val_loss: 9.9710e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 81/100\n",
      "164/164 - 3s - loss: 1.6135e-04 - val_loss: 8.2536e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "164/164 - 3s - loss: 1.4448e-04 - val_loss: 5.3613e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 83/100\n",
      "164/164 - 3s - loss: 1.4047e-04 - val_loss: 3.0394e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 84/100\n",
      "164/164 - 3s - loss: 1.4847e-04 - val_loss: 2.7745e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 85/100\n",
      "164/164 - 3s - loss: 1.6907e-04 - val_loss: 4.7979e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 86/100\n",
      "164/164 - 3s - loss: 2.0065e-04 - val_loss: 8.8959e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 87/100\n",
      "164/164 - 3s - loss: 2.4224e-04 - val_loss: 1.5196e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 88/100\n",
      "164/164 - 3s - loss: 2.9911e-04 - val_loss: 2.6127e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 89/100\n",
      "164/164 - 3s - loss: 3.7110e-04 - val_loss: 4.4171e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 90/100\n",
      "164/164 - 3s - loss: 4.2773e-04 - val_loss: 4.4846e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 91/100\n",
      "164/164 - 3s - loss: 4.8222e-04 - val_loss: 3.6798e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 92/100\n",
      "164/164 - 3s - loss: 4.3028e-04 - val_loss: 1.4850e-04 - 3s/epoch - 20ms/step\n",
      "Epoch 93/100\n",
      "164/164 - 3s - loss: 3.6705e-04 - val_loss: 6.7233e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 94/100\n",
      "164/164 - 3s - loss: 3.0123e-04 - val_loss: 5.3585e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 95/100\n",
      "164/164 - 3s - loss: 2.3412e-04 - val_loss: 7.5785e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 96/100\n",
      "164/164 - 3s - loss: 1.8342e-04 - val_loss: 8.5827e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "164/164 - 3s - loss: 1.5277e-04 - val_loss: 7.3904e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "164/164 - 3s - loss: 1.3703e-04 - val_loss: 4.9180e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "164/164 - 3s - loss: 1.3325e-04 - val_loss: 2.8119e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 100/100\n",
      "164/164 - 3s - loss: 1.4091e-04 - val_loss: 2.6439e-05 - 3s/epoch - 20ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:49:43.843012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:49:43.927864: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:49:44.153371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:49:48.122723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-04 11:49:48.154132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 5s - loss: 5.5517e-04 - val_loss: 4.8977e-04 - 5s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "164/164 - 4s - loss: 3.9311e-04 - val_loss: 8.3820e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "164/164 - 4s - loss: 8.8259e-04 - val_loss: 0.0024 - 4s/epoch - 22ms/step\n",
      "Epoch 4/100\n",
      "164/164 - 4s - loss: 0.0015 - val_loss: 0.0037 - 4s/epoch - 22ms/step\n",
      "Epoch 5/100\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0045 - 4s/epoch - 22ms/step\n",
      "Epoch 6/100\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 0.0057 - 4s/epoch - 22ms/step\n",
      "Epoch 7/100\n",
      "164/164 - 3s - loss: 0.0015 - val_loss: 0.0061 - 3s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "164/164 - 4s - loss: 0.0015 - val_loss: 0.0058 - 4s/epoch - 21ms/step\n",
      "Epoch 9/100\n",
      "164/164 - 4s - loss: 0.0013 - val_loss: 0.0053 - 4s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "164/164 - 3s - loss: 0.0012 - val_loss: 0.0050 - 3s/epoch - 21ms/step\n",
      "Epoch 11/100\n",
      "164/164 - 4s - loss: 0.0012 - val_loss: 0.0047 - 4s/epoch - 23ms/step\n",
      "Epoch 12/100\n",
      "164/164 - 4s - loss: 0.0013 - val_loss: 0.0048 - 4s/epoch - 22ms/step\n",
      "Epoch 13/100\n",
      "164/164 - 3s - loss: 0.0014 - val_loss: 0.0048 - 3s/epoch - 21ms/step\n",
      "Epoch 14/100\n",
      "164/164 - 3s - loss: 0.0017 - val_loss: 0.0046 - 3s/epoch - 21ms/step\n",
      "Epoch 15/100\n",
      "164/164 - 3s - loss: 0.0019 - val_loss: 0.0039 - 3s/epoch - 21ms/step\n",
      "Epoch 16/100\n",
      "164/164 - 3s - loss: 0.0020 - val_loss: 0.0025 - 3s/epoch - 21ms/step\n",
      "Epoch 17/100\n",
      "164/164 - 3s - loss: 0.0017 - val_loss: 0.0011 - 3s/epoch - 21ms/step\n",
      "Epoch 18/100\n",
      "164/164 - 4s - loss: 0.0014 - val_loss: 3.2696e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 19/100\n",
      "164/164 - 3s - loss: 9.6781e-04 - val_loss: 8.3982e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "164/164 - 3s - loss: 7.0893e-04 - val_loss: 5.8359e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 21/100\n",
      "164/164 - 3s - loss: 5.4398e-04 - val_loss: 5.6579e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "164/164 - 4s - loss: 4.3426e-04 - val_loss: 4.6267e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "164/164 - 4s - loss: 3.6341e-04 - val_loss: 3.7157e-05 - 4s/epoch - 22ms/step\n",
      "Epoch 24/100\n",
      "164/164 - 4s - loss: 3.2605e-04 - val_loss: 4.0969e-05 - 4s/epoch - 22ms/step\n",
      "Epoch 25/100\n",
      "164/164 - 4s - loss: 3.1660e-04 - val_loss: 6.8144e-05 - 4s/epoch - 22ms/step\n",
      "Epoch 26/100\n",
      "164/164 - 4s - loss: 3.3017e-04 - val_loss: 1.2583e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 27/100\n",
      "164/164 - 4s - loss: 3.6272e-04 - val_loss: 2.1588e-04 - 4s/epoch - 22ms/step\n",
      "Epoch 28/100\n",
      "164/164 - 4s - loss: 4.1091e-04 - val_loss: 3.3262e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 29/100\n",
      "164/164 - 4s - loss: 4.7086e-04 - val_loss: 4.5811e-04 - 4s/epoch - 22ms/step\n",
      "Epoch 30/100\n",
      "164/164 - 4s - loss: 5.3894e-04 - val_loss: 5.7341e-04 - 4s/epoch - 21ms/step\n",
      "Epoch 31/100\n",
      "164/164 - 3s - loss: 6.1351e-04 - val_loss: 6.7404e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 32/100\n",
      "164/164 - 3s - loss: 6.8664e-04 - val_loss: 7.4887e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "164/164 - 3s - loss: 7.6379e-04 - val_loss: 8.3314e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "164/164 - 3s - loss: 8.4186e-04 - val_loss: 9.9357e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "164/164 - 3s - loss: 9.1459e-04 - val_loss: 8.4030e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 36/100\n",
      "164/164 - 3s - loss: 8.7488e-04 - val_loss: 4.7343e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 37/100\n",
      "164/164 - 3s - loss: 7.1310e-04 - val_loss: 1.5996e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 38/100\n",
      "164/164 - 3s - loss: 5.3242e-04 - val_loss: 6.8082e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 39/100\n",
      "164/164 - 4s - loss: 4.0474e-04 - val_loss: 7.9583e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "164/164 - 3s - loss: 3.3130e-04 - val_loss: 7.4543e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 41/100\n",
      "164/164 - 3s - loss: 2.9029e-04 - val_loss: 5.7424e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "164/164 - 3s - loss: 2.7301e-04 - val_loss: 4.8563e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 43/100\n",
      "164/164 - 3s - loss: 2.7427e-04 - val_loss: 6.1229e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 44/100\n",
      "164/164 - 3s - loss: 2.9082e-04 - val_loss: 9.8579e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 45/100\n",
      "164/164 - 3s - loss: 3.1886e-04 - val_loss: 1.5106e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 46/100\n",
      "164/164 - 3s - loss: 3.5369e-04 - val_loss: 2.1028e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 47/100\n",
      "164/164 - 3s - loss: 3.9348e-04 - val_loss: 2.5384e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 48/100\n",
      "164/164 - 3s - loss: 4.4871e-04 - val_loss: 3.6815e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 49/100\n",
      "164/164 - 3s - loss: 4.9960e-04 - val_loss: 4.5767e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 50/100\n",
      "164/164 - 3s - loss: 5.8062e-04 - val_loss: 5.2799e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "164/164 - 3s - loss: 6.0747e-04 - val_loss: 4.5646e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 52/100\n",
      "164/164 - 3s - loss: 6.0483e-04 - val_loss: 3.1329e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "164/164 - 3s - loss: 5.4666e-04 - val_loss: 1.5164e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 54/100\n",
      "164/164 - 3s - loss: 4.5041e-04 - val_loss: 6.6289e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 55/100\n",
      "164/164 - 3s - loss: 3.5080e-04 - val_loss: 6.9799e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 56/100\n",
      "164/164 - 3s - loss: 2.8641e-04 - val_loss: 6.8650e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "164/164 - 3s - loss: 2.4893e-04 - val_loss: 5.3170e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 58/100\n",
      "164/164 - 3s - loss: 2.3146e-04 - val_loss: 4.2013e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "164/164 - 3s - loss: 2.3051e-04 - val_loss: 4.5877e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 60/100\n",
      "164/164 - 3s - loss: 2.4221e-04 - val_loss: 6.7276e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 61/100\n",
      "164/164 - 3s - loss: 2.6414e-04 - val_loss: 1.0454e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 62/100\n",
      "164/164 - 3s - loss: 2.9333e-04 - val_loss: 1.3896e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 63/100\n",
      "164/164 - 3s - loss: 3.2805e-04 - val_loss: 1.8731e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 64/100\n",
      "164/164 - 3s - loss: 3.7654e-04 - val_loss: 2.8262e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 65/100\n",
      "164/164 - 3s - loss: 4.5405e-04 - val_loss: 4.4143e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "164/164 - 3s - loss: 5.0802e-04 - val_loss: 4.0322e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 67/100\n",
      "164/164 - 3s - loss: 5.0197e-04 - val_loss: 2.0341e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "164/164 - 3s - loss: 4.5871e-04 - val_loss: 1.1296e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 69/100\n",
      "164/164 - 3s - loss: 3.7963e-04 - val_loss: 6.0551e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 70/100\n",
      "164/164 - 3s - loss: 2.9704e-04 - val_loss: 6.8028e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 71/100\n",
      "164/164 - 3s - loss: 2.3768e-04 - val_loss: 7.0023e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 72/100\n",
      "164/164 - 3s - loss: 2.0406e-04 - val_loss: 5.3141e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 73/100\n",
      "164/164 - 3s - loss: 1.8976e-04 - val_loss: 3.7385e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 74/100\n",
      "164/164 - 3s - loss: 1.9074e-04 - val_loss: 3.7470e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 75/100\n",
      "164/164 - 3s - loss: 2.0290e-04 - val_loss: 5.4807e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 76/100\n",
      "164/164 - 3s - loss: 2.2560e-04 - val_loss: 8.5164e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 77/100\n",
      "164/164 - 3s - loss: 2.5067e-04 - val_loss: 1.0653e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "164/164 - 3s - loss: 2.8368e-04 - val_loss: 1.4964e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 79/100\n",
      "164/164 - 3s - loss: 3.2707e-04 - val_loss: 2.4796e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 80/100\n",
      "164/164 - 3s - loss: 3.7453e-04 - val_loss: 3.0246e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 81/100\n",
      "164/164 - 3s - loss: 4.2122e-04 - val_loss: 2.6582e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 82/100\n",
      "164/164 - 3s - loss: 4.1012e-04 - val_loss: 1.2484e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 83/100\n",
      "164/164 - 3s - loss: 3.5219e-04 - val_loss: 6.0628e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 84/100\n",
      "164/164 - 3s - loss: 2.8550e-04 - val_loss: 4.9251e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 85/100\n",
      "164/164 - 3s - loss: 2.3093e-04 - val_loss: 5.0611e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 86/100\n",
      "164/164 - 3s - loss: 1.9727e-04 - val_loss: 4.3276e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 87/100\n",
      "164/164 - 3s - loss: 1.8074e-04 - val_loss: 3.3108e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 88/100\n",
      "164/164 - 3s - loss: 1.7791e-04 - val_loss: 3.2450e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 89/100\n",
      "164/164 - 3s - loss: 1.8542e-04 - val_loss: 4.4489e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 90/100\n",
      "164/164 - 3s - loss: 2.0169e-04 - val_loss: 6.2145e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 91/100\n",
      "164/164 - 4s - loss: 2.2223e-04 - val_loss: 9.2090e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 92/100\n",
      "164/164 - 3s - loss: 2.4526e-04 - val_loss: 1.2777e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 93/100\n",
      "164/164 - 3s - loss: 2.7691e-04 - val_loss: 1.9354e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 94/100\n",
      "164/164 - 3s - loss: 3.1131e-04 - val_loss: 2.0181e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 95/100\n",
      "164/164 - 3s - loss: 3.3687e-04 - val_loss: 1.6267e-04 - 3s/epoch - 21ms/step\n",
      "Epoch 96/100\n",
      "164/164 - 3s - loss: 3.2451e-04 - val_loss: 9.6617e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 97/100\n",
      "164/164 - 3s - loss: 2.9226e-04 - val_loss: 5.9586e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 98/100\n",
      "164/164 - 3s - loss: 2.6220e-04 - val_loss: 4.7388e-05 - 3s/epoch - 21ms/step\n",
      "Epoch 99/100\n",
      "164/164 - 4s - loss: 2.3216e-04 - val_loss: 4.3943e-05 - 4s/epoch - 21ms/step\n",
      "Epoch 100/100\n",
      "164/164 - 3s - loss: 2.0323e-04 - val_loss: 4.1891e-05 - 3s/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "lstms3 = []\n",
    "models3 = []\n",
    "for batch, epoch, neuron in hyperparam3:\n",
    "    model, lstm = LSTMUnit.train_lstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    lstms3.append(lstm)\n",
    "    models3.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "546cd3a7-bfcc-4077-9e56-6b8bfda87f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 25, 50)\n",
      "Epoch: 25\n",
      "Neurons: 50\n",
      "RMSE\n",
      "1917.6675942135876\n",
      "MAE\n",
      "1887.7540489313121\n",
      "MAPE\n",
      "9.342906599792848\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 25, 60)\n",
      "Epoch: 25\n",
      "Neurons: 60\n",
      "RMSE\n",
      "376.9132664458584\n",
      "MAE\n",
      "271.4766820365029\n",
      "MAPE\n",
      "1.267604081456063\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 25, 100)\n",
      "Epoch: 25\n",
      "Neurons: 100\n",
      "RMSE\n",
      "411.9831919896943\n",
      "MAE\n",
      "309.22101599273503\n",
      "MAPE\n",
      "1.4442471440496685\n",
      "163/163 [==============================] - 1s 7ms/step\n",
      "(128, 50, 50)\n",
      "Epoch: 50\n",
      "Neurons: 50\n",
      "RMSE\n",
      "855.2534042070652\n",
      "MAE\n",
      "766.4882541501574\n",
      "MAPE\n",
      "3.6767108383140954\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 50, 60)\n",
      "Epoch: 50\n",
      "Neurons: 60\n",
      "RMSE\n",
      "677.9095728784064\n",
      "MAE\n",
      "546.9495048931313\n",
      "MAPE\n",
      "2.785890832623101\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 50, 100)\n",
      "Epoch: 50\n",
      "Neurons: 100\n",
      "RMSE\n",
      "953.4043804656784\n",
      "MAE\n",
      "894.6014723297919\n",
      "MAPE\n",
      "4.371893581403059\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "RMSE\n",
      "573.8206221946621\n",
      "MAE\n",
      "515.1894213121399\n",
      "MAPE\n",
      "2.53730404914976\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "RMSE\n",
      "331.6646818276062\n",
      "MAE\n",
      "261.51374380103323\n",
      "MAPE\n",
      "1.259064186061658\n",
      "163/163 [==============================] - 1s 8ms/step\n",
      "(128, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "RMSE\n",
      "417.48540669429707\n",
      "MAE\n",
      "299.57004602695747\n",
      "MAPE\n",
      "1.4304477528764976\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "wb3 = Workbook()\n",
    "ws3 = wb3.active\n",
    "for m in models3:\n",
    "    # make a prediction\n",
    "    test_x2 = test_X\n",
    "    yhat = LSTMUnit.predict(test_x2, m)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparam3[i])\n",
    "    print(\"Epoch: \"+ str(lstms3[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].units))\n",
    "    i = i+1\n",
    "    ws3['A'+str(i)] = 'LSTM'\n",
    "    ws3['B'+str(i)] = hyperparam3[i-1][0]\n",
    "    ws3['C'+str(i)] = hyperparam3[i-1][1]\n",
    "    ws3['D'+str(i)] = hyperparam3[i-1][2]\n",
    "    print('RMSE')\n",
    "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
    "    ws3['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
    "    print('MAE')\n",
    "    print(Evaluation.mae(inv_y,inv_yhat))\n",
    "    ws3['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
    "    print('MAPE')\n",
    "    print(Evaluation.mape(inv_y,inv_yhat))\n",
    "    ws3['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
    "    LSTMUnit.save_model(m, 0, 'BTC',hyperparam3[i-1])\n",
    "    with open('LSTM_BTC'+str(hyperparam3[i-1])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(lstms3[i-1].history, f)\n",
    "wb3.save('LSTM_BTC_result3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d99b65f4-ade9-447a-9440-bab346a23910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.38669404, 0.3808301 , 0.38809703, 0.0406164 , 0.38493033],\n",
       "        [0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "        [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        ...,\n",
       "        [0.38602478, 0.37948967, 0.38949337, 0.00759075, 0.38563804],\n",
       "        [0.38562372, 0.37916835, 0.3884063 , 0.00906337, 0.38440368],\n",
       "        [0.38438953, 0.3776341 , 0.38746628, 0.01179253, 0.38406695]],\n",
       "\n",
       "       [[0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "        [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        [0.38584929, 0.38055428, 0.38798971, 0.02809654, 0.38442601],\n",
       "        ...,\n",
       "        [0.38562372, 0.37916835, 0.3884063 , 0.00906337, 0.38440368],\n",
       "        [0.38438953, 0.3776341 , 0.38746628, 0.01179253, 0.38406695],\n",
       "        [0.38405265, 0.3787422 , 0.38803641, 0.0069225 , 0.38531015]],\n",
       "\n",
       "       [[0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        [0.38584929, 0.38055428, 0.38798971, 0.02809654, 0.38442601],\n",
       "        [0.38441201, 0.37958689, 0.38444598, 0.06968765, 0.38245246],\n",
       "        ...,\n",
       "        [0.38438953, 0.3776341 , 0.38746628, 0.01179253, 0.38406695],\n",
       "        [0.38405265, 0.3787422 , 0.38803641, 0.0069225 , 0.38531015],\n",
       "        [0.38529583, 0.37854201, 0.38863763, 0.00440172, 0.38463995]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.19382552, 0.18686256, 0.1980652 , 0.03789924, 0.19350651],\n",
       "        [0.19349484, 0.18649837, 0.19752011, 0.05415432, 0.19330249],\n",
       "        [0.19329082, 0.18644013, 0.19806427, 0.02648407, 0.19330714],\n",
       "        ...,\n",
       "        [0.19301503, 0.1860438 , 0.19777108, 0.01842876, 0.19296994],\n",
       "        [0.19295813, 0.18605467, 0.19766748, 0.02230679, 0.19285135],\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747]],\n",
       "\n",
       "       [[0.19349484, 0.18649837, 0.19752011, 0.05415432, 0.19330249],\n",
       "        [0.19329082, 0.18644013, 0.19806427, 0.02648407, 0.19330714],\n",
       "        [0.19329532, 0.18681472, 0.19813122, 0.03206729, 0.19361751],\n",
       "        ...,\n",
       "        [0.19295813, 0.18605467, 0.19766748, 0.02230679, 0.19285135],\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747],\n",
       "        [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245]],\n",
       "\n",
       "       [[0.19329082, 0.18644013, 0.19806427, 0.02648407, 0.19330714],\n",
       "        [0.19329532, 0.18681472, 0.19813122, 0.03206729, 0.19361751],\n",
       "        [0.19360584, 0.1870556 , 0.19839874, 0.03923131, 0.19383316],\n",
       "        ...,\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747],\n",
       "        [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245],\n",
       "        [0.19250079, 0.18570415, 0.19619691, 0.03681983, 0.19208658]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
